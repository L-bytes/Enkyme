{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from hyperopt import fmin, rand, hp, Trials\n",
    "rstate = np.random.default_rng(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib as mpl\n",
    "\n",
    "datasets_dir = \"../../data\"\n",
    "# plt.style.use('CCB_plot_style_0v4.mplstyle')\n",
    "# c_styles      = mpl.rcParams['axes.prop_cycle'].by_key()['color']   # fetch the defined color styles\n",
    "# high_contrast = ['#004488', '#DDAA33', '#BB5566', '#000000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training, testing and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 52, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"secondary\"\n",
    "\n",
    "data_train = pd.read_pickle(join(datasets_dir, \"splits\", split, \"training_data.pkl\"))\n",
    "data_test = pd.read_pickle(join(datasets_dir, \"splits\", split, \"test_data.pkl\"))\n",
    "data_val = pd.read_pickle(join(datasets_dir, \"splits\", split, \"val_data.pkl\"))\n",
    "\n",
    "# data_train[\"geomean_Km\"] = np.log10(data_train[\"geomean_Km\"])\n",
    "# data_test[\"geomean_Km\"] = np.log10(data_test[\"geomean_Km\"])\n",
    "\n",
    "data_train[\"log10_Km\"] = np.log10(data_train[\"Km\"])\n",
    "data_test[\"log10_Km\"] = np.log10(data_test[\"Km\"])\n",
    "data_val[\"log10_Km\"] = np.log10(data_val[\"Km\"])\n",
    "\n",
    "data_train.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_test.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_val.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "\n",
    "data_train['Temperature'] = data_train['Temperature'].replace('-', np.nan)\n",
    "data_test['Temperature'] = data_test['Temperature'].replace('-', np.nan)\n",
    "data_val['Temperature'] = data_val['Temperature'].replace('-', np.nan)\n",
    "data_train['pH'] = data_train['pH'].replace('-', np.nan)\n",
    "data_test['pH'] = data_test['pH'].replace('-', np.nan)\n",
    "data_val['pH'] = data_val['pH'].replace('-', np.nan)\n",
    "data_train['Type'] = data_train['Type'].replace('wildtype', 1)\n",
    "data_train['Type'] = data_train['Type'].replace('mutant', 2)\n",
    "data_test['Type'] = data_test['Type'].replace('wildtype', 1)\n",
    "data_test['Type'] = data_test['Type'].replace('mutant', 2)\n",
    "data_val['Type'] = data_val['Type'].replace('wildtype', 1)\n",
    "data_val['Type'] = data_val['Type'].replace('mutant', 2)\n",
    "\n",
    "data_train['MACCS FP'] = data_train['MACCS FP'].astype(str)\n",
    "data_test['MACCS FP'] = data_test['MACCS FP'].astype(str)\n",
    "data_val['MACCS FP'] = data_val['MACCS FP'].astype(str)\n",
    "\n",
    "len(data_train), len(data_test), len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_train_indices_Seed plants.npy\"), allow_pickle = True))\n",
    "test_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_test_indices_Seed plants.npy\"), allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training a model with enzyme and main substrate information (ESM-2/MACCS) + Temperature + pH :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train['GNN FP'])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test['GNN FP'])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_mse_gradient_boosting(param):\n",
    "#     num_round = param[\"num_rounds\"]\n",
    "#     del param[\"num_rounds\"]\n",
    "#     param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "#     # param[\"device\"] = \"cuda\"\n",
    "#     param[\"tree_method\"] = \"hist\"\n",
    "#     param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "#     MSE = []\n",
    "#     R2 = []\n",
    "#     for i in range(5):\n",
    "#         train_index, test_index  = train_indices[i], test_indices[i]\n",
    "#         dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "#         dvalid = xgb.DMatrix(train_X[test_index])\n",
    "#         bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "#         y_valid_pred = bst.predict(dvalid)\n",
    "#         MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "#         R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "#     return(-np.mean(R2))\n",
    "\n",
    "# space_gradient_boosting = {\n",
    "#     \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "#     \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "#     #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "#     \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "#     \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "#     \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "#     \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "#     \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "#             algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == \"full\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 2, 'max_depth': 5, 'min_child_weight': 1, 'num_rounds': 200, 'reg_alpha': 0.6, 'reg_lambda': 0.4}\n",
    "elif split == \"Arabidopsis\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.05, 'max_delta_step': 5, 'max_depth': 3, 'min_child_weight': 6, 'num_rounds': 150, 'reg_alpha': 0.6, 'reg_lambda': 0.3}\n",
    "elif split == \"Brassicaceae\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.09, 'max_delta_step': 2, 'max_depth': 7, 'min_child_weight': 4, 'num_rounds': 100, 'reg_alpha': 0.4, 'reg_lambda': 0.4}\n",
    "elif split == \"wildtype\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.07, 'max_delta_step': 2, 'max_depth': 6, 'min_child_weight': 6, 'num_rounds': 150, 'reg_alpha': 0.9, 'reg_lambda': 0.6}\n",
    "else:\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 5, 'max_depth': 9, 'min_child_weight': 1, 'num_rounds': 150, 'reg_alpha': 0.9, 'reg_lambda': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.712259063877006, -0.13191058439126502, 0.013143524862279973, 0.2966060264071361, 0.9411982273425176]\n",
      "[0.0002204918446601779, 0.0005151062560342511, 0.00030529855312018086, 0.0008552835368452709, 0.00016442503507349933]\n",
      "[0.44016384769737815, -0.2574194978632032, -0.10336538466886336, 0.013228000526173789, 0.6880447764474957]\n",
      "[0.00011648343085550415, 0.000271149026878687, 0.00011975936486826634, 0.00023599212480105103, 8.282439042848223e-05]\n",
      "[4.402867855541495e-05, 6.585325998510999e-05, 3.2948771929013146e-05, 7.634454788779882e-05, 2.9763541238050823e-05]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"Pearson_CV_xgboost_ESM2_gnn_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"MSE_CV_xgboost_ESM2_gnn_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"R2_CV_xgboost_ESM2_gnn_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6936321746967223 0.0001270533 0.39 5.85843e-05 2.30231e-05\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate Km\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = np.corrcoef(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0,1],20) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_gnn_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", split,  \"y_test_true_xgboost_ESM2_gnn_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate Km\"] = [10**x for x in data_test[\"Estimate Km\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train['GNN FP'])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test['GNN FP'])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8716542655591116, 4.192884708598777e-17) 9.74660913959851e-05 0.6409367189975731\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "167\n",
      "f0: 43.0\n",
      "f1: 12.0\n",
      "f2: 31.0\n",
      "f3: 16.0\n",
      "f4: 19.0\n",
      "f5: 21.0\n",
      "f6: 16.0\n",
      "f7: 12.0\n",
      "f8: 5.0\n",
      "f9: 6.0\n",
      "f10: 7.0\n",
      "f11: 10.0\n",
      "f12: 1.0\n",
      "f13: 2.0\n",
      "f14: 2.0\n",
      "f15: 13.0\n",
      "f16: 5.0\n",
      "f17: 2.0\n",
      "f18: 3.0\n",
      "f19: 1.0\n",
      "f20: 4.0\n",
      "f21: 1.0\n",
      "f22: 22.0\n",
      "f23: 9.0\n",
      "f24: 9.0\n",
      "f26: 7.0\n",
      "f27: 15.0\n",
      "f29: 4.0\n",
      "f30: 15.0\n",
      "f31: 2.0\n",
      "f32: 7.0\n",
      "f34: 3.0\n",
      "f38: 1.0\n",
      "f39: 1.0\n",
      "f40: 3.0\n",
      "f41: 2.0\n",
      "f42: 2.0\n",
      "f43: 1.0\n",
      "f45: 6.0\n",
      "f46: 8.0\n",
      "f47: 4.0\n",
      "f48: 8.0\n",
      "f49: 1.0\n",
      "f51: 11.0\n",
      "f52: 13.0\n",
      "f54: 2.0\n",
      "f55: 14.0\n",
      "f56: 1.0\n",
      "f57: 4.0\n",
      "f62: 7.0\n",
      "f63: 10.0\n",
      "f64: 1.0\n",
      "f69: 10.0\n",
      "f70: 5.0\n",
      "f71: 2.0\n",
      "f72: 4.0\n",
      "f73: 2.0\n",
      "f74: 13.0\n",
      "f75: 1.0\n",
      "f76: 2.0\n",
      "f78: 1.0\n",
      "f80: 5.0\n",
      "f82: 1.0\n",
      "f83: 2.0\n",
      "f85: 2.0\n",
      "f86: 4.0\n",
      "f87: 1.0\n",
      "f89: 1.0\n",
      "f91: 1.0\n",
      "f93: 1.0\n",
      "f95: 1.0\n",
      "f97: 3.0\n",
      "f99: 3.0\n",
      "f100: 4.0\n",
      "f101: 1.0\n",
      "f106: 1.0\n",
      "f107: 2.0\n",
      "f110: 4.0\n",
      "f111: 2.0\n",
      "f114: 1.0\n",
      "f119: 1.0\n",
      "f122: 4.0\n",
      "f123: 3.0\n",
      "f125: 8.0\n",
      "f126: 1.0\n",
      "f127: 4.0\n",
      "f129: 1.0\n",
      "f131: 1.0\n",
      "f136: 14.0\n",
      "f137: 4.0\n",
      "f138: 1.0\n",
      "f139: 2.0\n",
      "f140: 1.0\n",
      "f141: 3.0\n",
      "f142: 1.0\n",
      "f145: 3.0\n",
      "f147: 4.0\n",
      "f148: 2.0\n",
      "f150: 1.0\n",
      "f154: 1.0\n",
      "f155: 6.0\n",
      "f158: 2.0\n",
      "f160: 1.0\n",
      "f161: 5.0\n",
      "f162: 1.0\n",
      "f163: 1.0\n",
      "f164: 2.0\n",
      "f165: 2.0\n",
      "f168: 1.0\n",
      "f170: 8.0\n",
      "f172: 9.0\n",
      "f173: 1.0\n",
      "f176: 1.0\n",
      "f180: 9.0\n",
      "f185: 1.0\n",
      "f190: 1.0\n",
      "f192: 5.0\n",
      "f194: 2.0\n",
      "f196: 3.0\n",
      "f200: 1.0\n",
      "f201: 1.0\n",
      "f202: 1.0\n",
      "f204: 11.0\n",
      "f208: 2.0\n",
      "f209: 2.0\n",
      "f214: 2.0\n",
      "f216: 3.0\n",
      "f221: 1.0\n",
      "f223: 2.0\n",
      "f224: 4.0\n",
      "f228: 7.0\n",
      "f232: 2.0\n",
      "f233: 6.0\n",
      "f238: 9.0\n",
      "f243: 3.0\n",
      "f244: 1.0\n",
      "f249: 1.0\n",
      "f251: 3.0\n",
      "f252: 1.0\n",
      "f254: 2.0\n",
      "f261: 1.0\n",
      "f267: 2.0\n",
      "f268: 2.0\n",
      "f269: 3.0\n",
      "f270: 1.0\n",
      "f273: 1.0\n",
      "f277: 2.0\n",
      "f278: 1.0\n",
      "f279: 5.0\n",
      "f281: 6.0\n",
      "f283: 1.0\n",
      "f286: 1.0\n",
      "f290: 9.0\n",
      "f291: 1.0\n",
      "f292: 1.0\n",
      "f301: 2.0\n",
      "f303: 2.0\n",
      "f304: 1.0\n",
      "f312: 4.0\n",
      "f314: 1.0\n",
      "f321: 3.0\n",
      "f323: 2.0\n",
      "f324: 1.0\n",
      "f326: 1.0\n",
      "f327: 1.0\n",
      "f330: 3.0\n",
      "f332: 2.0\n",
      "f336: 1.0\n",
      "f338: 2.0\n",
      "f339: 8.0\n",
      "f342: 3.0\n",
      "f347: 4.0\n",
      "f349: 8.0\n",
      "f350: 5.0\n",
      "f351: 1.0\n",
      "f356: 2.0\n",
      "f357: 1.0\n",
      "f362: 13.0\n",
      "f363: 2.0\n",
      "f364: 1.0\n",
      "f365: 2.0\n",
      "f368: 2.0\n",
      "f369: 1.0\n",
      "f370: 5.0\n",
      "f374: 1.0\n",
      "f380: 1.0\n",
      "f382: 1.0\n",
      "f391: 1.0\n",
      "f392: 2.0\n",
      "f397: 3.0\n",
      "f398: 3.0\n",
      "f399: 1.0\n",
      "f401: 2.0\n",
      "f407: 2.0\n",
      "f408: 2.0\n",
      "f410: 9.0\n",
      "f411: 16.0\n",
      "f412: 5.0\n",
      "f415: 20.0\n",
      "f419: 2.0\n",
      "f421: 1.0\n",
      "f423: 1.0\n",
      "f428: 1.0\n",
      "f433: 14.0\n",
      "f436: 2.0\n",
      "f438: 1.0\n",
      "f442: 7.0\n",
      "f447: 1.0\n",
      "f450: 1.0\n",
      "f451: 1.0\n",
      "f454: 3.0\n",
      "f459: 2.0\n",
      "f463: 1.0\n",
      "f466: 9.0\n",
      "f471: 3.0\n",
      "f477: 3.0\n",
      "f478: 5.0\n",
      "f486: 2.0\n",
      "f490: 1.0\n",
      "f492: 1.0\n",
      "f493: 11.0\n",
      "f495: 3.0\n",
      "f497: 3.0\n",
      "f500: 6.0\n",
      "f502: 2.0\n",
      "f503: 1.0\n",
      "f504: 1.0\n",
      "f506: 4.0\n",
      "f508: 2.0\n",
      "f510: 1.0\n",
      "f511: 1.0\n",
      "f522: 2.0\n",
      "f524: 1.0\n",
      "f525: 1.0\n",
      "f530: 3.0\n",
      "f531: 1.0\n",
      "f532: 2.0\n",
      "f550: 3.0\n",
      "f551: 4.0\n",
      "f553: 22.0\n",
      "f555: 1.0\n",
      "f562: 2.0\n",
      "f563: 1.0\n",
      "f567: 1.0\n",
      "f577: 1.0\n",
      "f582: 1.0\n",
      "f591: 2.0\n",
      "f594: 1.0\n",
      "f595: 2.0\n",
      "f599: 2.0\n",
      "f601: 2.0\n",
      "f603: 7.0\n",
      "f604: 2.0\n",
      "f605: 1.0\n",
      "f609: 8.0\n",
      "f612: 1.0\n",
      "f615: 2.0\n",
      "f617: 1.0\n",
      "f619: 1.0\n",
      "f622: 1.0\n",
      "f625: 1.0\n",
      "f629: 2.0\n",
      "f632: 1.0\n",
      "f637: 7.0\n",
      "f641: 2.0\n",
      "f646: 7.0\n",
      "f655: 1.0\n",
      "f657: 8.0\n",
      "f661: 8.0\n",
      "f663: 2.0\n",
      "f667: 3.0\n",
      "f683: 2.0\n",
      "f687: 1.0\n",
      "f688: 5.0\n",
      "f690: 3.0\n",
      "f691: 1.0\n",
      "f701: 1.0\n",
      "f702: 1.0\n",
      "f704: 1.0\n",
      "f705: 6.0\n",
      "f706: 2.0\n",
      "f708: 2.0\n",
      "f711: 4.0\n",
      "f712: 2.0\n",
      "f717: 1.0\n",
      "f718: 5.0\n",
      "f721: 1.0\n",
      "f722: 3.0\n",
      "f730: 3.0\n",
      "f731: 3.0\n",
      "f742: 4.0\n",
      "f745: 1.0\n",
      "f748: 2.0\n",
      "f749: 2.0\n",
      "f751: 2.0\n",
      "f753: 2.0\n",
      "f768: 1.0\n",
      "f769: 2.0\n",
      "f771: 1.0\n",
      "f778: 2.0\n",
      "f783: 3.0\n",
      "f794: 8.0\n",
      "f795: 5.0\n",
      "f801: 1.0\n",
      "f803: 4.0\n",
      "f805: 12.0\n",
      "f808: 1.0\n",
      "f810: 1.0\n",
      "f812: 1.0\n",
      "f821: 1.0\n",
      "f822: 2.0\n",
      "f830: 1.0\n",
      "f834: 1.0\n",
      "f837: 2.0\n",
      "f843: 33.0\n",
      "f847: 3.0\n",
      "f849: 1.0\n",
      "f850: 2.0\n",
      "f855: 1.0\n",
      "f860: 9.0\n",
      "f862: 1.0\n",
      "f863: 1.0\n",
      "f864: 1.0\n",
      "f865: 1.0\n",
      "f867: 1.0\n",
      "f869: 3.0\n",
      "f875: 1.0\n",
      "f880: 1.0\n",
      "f885: 2.0\n",
      "f887: 1.0\n",
      "f891: 1.0\n",
      "f892: 3.0\n",
      "f898: 1.0\n",
      "f900: 1.0\n",
      "f902: 1.0\n",
      "f909: 2.0\n",
      "f912: 1.0\n",
      "f916: 2.0\n",
      "f920: 1.0\n",
      "f922: 1.0\n",
      "f924: 2.0\n",
      "f925: 4.0\n",
      "f929: 1.0\n",
      "f930: 1.0\n",
      "f932: 4.0\n",
      "f941: 1.0\n",
      "f942: 26.0\n",
      "f943: 1.0\n",
      "f949: 1.0\n",
      "f951: 1.0\n",
      "f953: 3.0\n",
      "f957: 2.0\n",
      "f959: 1.0\n",
      "f974: 1.0\n",
      "f978: 6.0\n",
      "f982: 1.0\n",
      "f987: 1.0\n",
      "f991: 1.0\n",
      "f995: 2.0\n",
      "f997: 2.0\n",
      "f1003: 7.0\n",
      "f1009: 4.0\n",
      "f1019: 2.0\n",
      "f1021: 1.0\n",
      "f1023: 1.0\n",
      "f1025: 4.0\n",
      "f1028: 1.0\n",
      "f1033: 1.0\n",
      "f1038: 1.0\n",
      "f1040: 1.0\n",
      "f1048: 1.0\n",
      "f1053: 2.0\n",
      "f1054: 2.0\n",
      "f1057: 1.0\n",
      "f1061: 1.0\n",
      "f1068: 1.0\n",
      "f1078: 2.0\n",
      "f1083: 2.0\n",
      "f1086: 3.0\n",
      "f1088: 1.0\n",
      "f1094: 1.0\n",
      "f1096: 1.0\n",
      "f1097: 3.0\n",
      "f1103: 3.0\n",
      "f1105: 7.0\n",
      "f1108: 1.0\n",
      "f1109: 1.0\n",
      "f1110: 8.0\n",
      "f1111: 1.0\n",
      "f1112: 2.0\n",
      "f1122: 6.0\n",
      "f1124: 1.0\n",
      "f1126: 2.0\n",
      "f1128: 1.0\n",
      "f1131: 2.0\n",
      "f1133: 5.0\n",
      "f1142: 8.0\n",
      "f1143: 2.0\n",
      "f1148: 1.0\n",
      "f1149: 3.0\n",
      "f1159: 2.0\n",
      "f1161: 2.0\n",
      "f1163: 1.0\n",
      "f1164: 1.0\n",
      "f1169: 1.0\n",
      "f1171: 1.0\n",
      "f1172: 2.0\n",
      "f1174: 2.0\n",
      "f1176: 3.0\n",
      "f1178: 1.0\n",
      "f1182: 2.0\n",
      "f1184: 11.0\n",
      "f1185: 5.0\n",
      "f1186: 5.0\n",
      "f1187: 1.0\n",
      "f1188: 1.0\n",
      "f1193: 4.0\n",
      "f1199: 2.0\n",
      "f1204: 1.0\n",
      "f1207: 6.0\n",
      "f1208: 1.0\n",
      "f1209: 5.0\n",
      "f1210: 1.0\n",
      "f1212: 2.0\n",
      "f1214: 2.0\n",
      "f1215: 2.0\n",
      "f1216: 6.0\n",
      "f1219: 2.0\n",
      "f1222: 8.0\n",
      "f1226: 3.0\n",
      "f1232: 1.0\n",
      "f1233: 1.0\n",
      "f1239: 4.0\n",
      "f1240: 1.0\n",
      "f1241: 3.0\n",
      "f1243: 2.0\n",
      "f1250: 2.0\n",
      "f1253: 9.0\n",
      "f1255: 1.0\n",
      "f1257: 4.0\n",
      "f1262: 3.0\n",
      "f1266: 8.0\n",
      "f1268: 6.0\n",
      "f1272: 1.0\n",
      "f1274: 1.0\n",
      "f1280: 110.0\n",
      "f1281: 54.0\n",
      "f1282: 22.0\n",
      "f1283: 16.0\n",
      "f1284: 59.0\n",
      "f1285: 24.0\n",
      "f1286: 49.0\n",
      "f1287: 42.0\n",
      "f1288: 18.0\n",
      "f1289: 22.0\n",
      "f1291: 3.0\n",
      "f1293: 5.0\n",
      "f1294: 3.0\n",
      "f1295: 2.0\n",
      "f1296: 48.0\n",
      "f1297: 2.0\n",
      "f1298: 19.0\n",
      "f1299: 8.0\n",
      "f1302: 1.0\n",
      "f1303: 15.0\n",
      "f1304: 41.0\n",
      "f1305: 59.0\n",
      "f1306: 4.0\n",
      "f1308: 1.0\n",
      "f1309: 2.0\n",
      "f1310: 12.0\n",
      "f1311: 1.0\n",
      "f1312: 3.0\n",
      "f1313: 2.0\n",
      "f1314: 21.0\n",
      "f1316: 8.0\n",
      "f1317: 51.0\n",
      "f1319: 64.0\n",
      "f1322: 10.0\n",
      "f1323: 10.0\n",
      "f1324: 2.0\n",
      "f1325: 6.0\n",
      "f1327: 5.0\n",
      "f1330: 84.0\n",
      "f1331: 146.0\n"
     ]
    }
   ],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"GNN FP\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_Km\"]))\n",
    "\n",
    "val_X = val_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(list(chain(*data_val[\"Km_values\"]))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.05805174245274695, 0.8079253608401846) 0.002143757653247468 -0.13806254848111799 0.0007787960579227445 0.0001149550273877403\n"
     ]
    }
   ],
   "source": [
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate Km\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as colors\n",
    "# import matplotlib.cm as cmx\n",
    "\n",
    "# plt.scatter(val_Y,y_val_pred, c='blue', edgecolors='black',s=15)\n",
    "    \n",
    "# plt.xlim(-6,2)\n",
    "# plt.ylim(-6,2)\n",
    "# plt.xticks(fontsize=14)\n",
    "# plt.yticks(fontsize=14)\n",
    "# plt.xlabel('Real value', fontsize=15)\n",
    "# plt.ylabel('Estimated value', fontsize=15)\n",
    "# plt.title('Predictions', fontsize=15)\n",
    "# plt.axline((1, 1), slope=1, c='red')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined = pd.concat([data_train, data_test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_identity_ignore_gaps(seq1, seq2):\n",
    "#     identical_residues = sum([1 for x, y in zip(seq1, seq2) if x == y and x != \"-\"])\n",
    "#     pid = identical_residues / sum([1 for x in seq1 if x != \"-\"]) \n",
    "#     return pid\n",
    "\n",
    "# from Bio import Align\n",
    "# from Bio.Align import substitution_matrices\n",
    "\n",
    "# data_val[\"max_identity\"] = np.nan\n",
    "\n",
    "# aligner=Align.PairwiseAligner()\n",
    "# aligner.substitution_matrix = substitution_matrices.load(\"BLOSUM62\")\n",
    "# aligner.mode = \"global\"\n",
    "# aligner.extend_gap_score = -0.5\n",
    "# aligner.open_gap_score = -10\n",
    "\n",
    "# for i in data_val.index:\n",
    "#     identities = []\n",
    "#     for j in data_combined.index:\n",
    "#         seq1 = str(data_val[\"Sequence\"][i])\n",
    "#         seq2 = str(data_combined[\"Sequence\"][j])\n",
    "#         if 'U' in seq1:\n",
    "#             seq1 = seq1.replace('U', 'C')\n",
    "#         if 'U' in seq2:\n",
    "#             seq2 = seq2.replace('U', 'C')\n",
    "#         alignments = aligner.align(seq1, seq2)\n",
    "#         identities.append(calculate_identity_ignore_gaps(alignments[0][0], alignments[0][1]))\n",
    "#     data_val[\"max_identity\"][i] = max(identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_val[\"max_identity\"] = data_val[\"max_identity\"]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import sklearn.metrics as sk\n",
    "# import math\n",
    "\n",
    "# fig, ax = plt.subplots(figsize= (10,8))\n",
    "# plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "# splits = [\"0-40%\", \"40-80%\", \"80-99%\", \"99-100%\"]\n",
    "# lower_bounds = [0,40,80,99]\n",
    "# upper_bounds = [40,80,99,100]\n",
    "\n",
    "# points1 = []\n",
    "# points2 = []\n",
    "# n_points1, n_points2 = [], []\n",
    "\n",
    "# for i, split in enumerate(splits):\n",
    "\n",
    "#     lb, ub = lower_bounds[i], upper_bounds[i]\n",
    "    \n",
    "#     help_df = data_val.loc[data_val[\"max_identity\"]>= lb].loc[data_val[\"max_identity\"]<= ub]\n",
    "#     y_true = np.array([10**x for x in help_df[\"log10_Km\"]])\n",
    "#     y_pred = np.array([10**x for x in help_df[\"Estimate Km\"]])\n",
    "#     n_km = len(y_pred)\n",
    "#     R2 =  sk.r2_score(y_true, y_pred)\n",
    "#     abs_error = abs(y_true - y_pred)\n",
    "#     rmse = math.sqrt(np.mean(abs(y_true - y_pred)**2))\n",
    "#     print(len(y_true))\n",
    "#     print(split, R2, rmse)\n",
    "#     points1.append(R2)\n",
    "#     points2.append(rmse)\n",
    "#     n_points1.append(n_km)\n",
    "\n",
    "\n",
    "# ticks2 = np.array(range(len(splits)))\n",
    "# labs = splits\n",
    "# ax.set_xticks(ticks2)\n",
    "# ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "# ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# # plt.ylim((-0.1,2.5))\n",
    "# # plt.xlim((-0.2, 3.2))\n",
    "# plt.legend(loc = \"lower right\", fontsize=20)\n",
    "# plt.ylabel('RMSE')\n",
    "# plt.xlabel('Enzyme sequence identity')\n",
    "# ax.yaxis.set_label_coords(-0.15, 0.5)\n",
    "# ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "# plt.plot([-0.15,4], [0,0], color='grey', linestyle='dashed')\n",
    "\n",
    "\n",
    "# plt.plot([0,1,2,3], points2, c= \"black\", linewidth=2)\n",
    "\n",
    "# for i, split in enumerate(splits):\n",
    "#     points1.append(R2)\n",
    "    \n",
    "#     if i ==0:\n",
    "#         plt.scatter(i, points2[i], c='black', marker=\"o\", linewidths= 8)\n",
    "#         ax.annotate(n_points1[i], (i-0.08, points2[i]+0.08), fontsize=17, c= \"red\", weight = \"bold\")\n",
    "\n",
    "#     else:\n",
    "#         plt.scatter(i, points2[i], c='black', marker=\"o\", linewidths= 8)\n",
    "#         ax.annotate(n_points1[i], (i-0.08, points2[i]+0.08), fontsize=17, c= \"red\", weight = \"bold\")\n",
    "            \n",
    "     \n",
    "# plt.savefig(join(\"..\",\"..\", \"data\", split, \"sequence_identity.png\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC_km_pred =[[] for _ in range(6)]\n",
    "# EC_km =[[] for _ in range(6)]\n",
    "# for ind in data_val.index:\n",
    "#     try:\n",
    "#         EC = int(data_val[\"ECs\"][ind][0][0])\n",
    "#         EC_km[EC-1].append(data_val[\"log10_Km\"][ind])\n",
    "#         EC_km_pred[EC-1].append(data_val[\"Estimate Km\"][ind])\n",
    "#     except IndexError:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize= (8,8))\n",
    "# plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "# classes = [str(i) for i in range(1,7)]\n",
    "\n",
    "# for i in range(len(EC_km)):\n",
    "    \n",
    "#     circle = plt.Circle((np.mean(EC_km[i]), np.mean(EC_km_pred[i]) ),\n",
    "#                         np.sqrt(len(EC_km_pred[i]))/300, color='navy', fill = True)\n",
    "#     ax.add_artist(circle)\n",
    "#     if i ==5:\n",
    "#         ax.annotate(\"EC\"+ str(i+1), (np.mean(EC_km[i])+0.01, np.mean(EC_km_pred[i])-0.05), fontsize=17, c='red', weight = \"bold\")\n",
    "#     else:\n",
    "#         ax.annotate(\"EC\"+ str(i+1), (np.mean(EC_km[i])+0.03, np.mean(EC_km_pred[i])-0.01), fontsize=17, c='red', weight = \"bold\")\n",
    "    \n",
    "\n",
    "# # ticks2 = [0.2, 0.6,1,1.4,1.8]\n",
    "# # labs = ticks2\n",
    "# # ax.set_xticks(ticks2)\n",
    "# # ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "# # ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# # ax.set_yticks(ticks2)\n",
    "# # ax.set_yticklabels(labs,  y= -0.03, fontsize=26)\n",
    "# # ax.tick_params(axis='y', length=0, rotation = 0)\n",
    "\n",
    "# plt.ylim((-6,-1))\n",
    "# plt.xlim((-6, -1))\n",
    "# plt.legend(loc = \"upper left\", fontsize=20)\n",
    "# plt.xlabel('mean measured \\n $k_{m}$ value on $\\log_{10}$-scale')\n",
    "# plt.ylabel('mean predicted \\n $k_{m}$ value on $\\log_{10}$-scale')\n",
    "# ax.yaxis.set_label_coords(-0.15, 0.5)\n",
    "# ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "# plt.axline((1, 1), slope=1, c='grey', alpha = 0.3, linestyle='dashed')\n",
    "# plt.savefig(join(\"..\", \"..\", \"data\", split, \"EC_classes_mean_km.png\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "\n",
    "# train_fps = [np.array(list(data_combined[\"MACCS FP\"][ind])).reshape(1,-1) for ind in data_combined.index]\n",
    "# test_fps = [np.array(list(data_val[\"MACCS FP\"][ind])).reshape(1,-1) for ind in data_val.index]\n",
    "\n",
    "# max_sim = []\n",
    "\n",
    "# for fp in test_fps:\n",
    "#     jaccard_sim = np.array([1 - scipy.spatial.distance.cdist(fp,train_fp, metric='jaccard')[0][0] for train_fp in train_fps])\n",
    "#     max_sim.append(np.max(jaccard_sim))\n",
    "    \n",
    "# data_val[\"substrate_sim\"] = max_sim\n",
    "\n",
    "# data_val[\"substrate_sim\"]= (data_val[\"substrate_sim\"] - np.min(data_val[\"substrate_sim\"]))\n",
    "# data_val[\"substrate_sim\"] = data_val[\"substrate_sim\"]/np.max(data_val[\"substrate_sim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_val[\"global_sim\"] = (data_val[\"max_identity\"]/100)*data_val[\"substrate_sim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# import scipy as sci\n",
    "# help_df = data_val\n",
    "\n",
    "# sim_bins_lb = [0.0, 0.4, 0.8]\n",
    "# sim_bins_ub = [0.4, 0.8, 1]\n",
    "# r2_scores, n_points, pearson_r, rmse = [], [], [], []\n",
    "# for i in range(len(sim_bins_lb)):\n",
    "#     help_df2 = help_df.loc[help_df[\"global_sim\"] <= sim_bins_ub[i]].loc[help_df[\"global_sim\"] >= sim_bins_lb[i]]\n",
    "#     pred = np.array([10**x for x in help_df2[\"log10_Km\"]])\n",
    "#     true = np.array([10**x for x in help_df2[\"Estimate Km\"]])\n",
    "#     r2_scores.append(sk.r2_score(true, pred))\n",
    "#     pearson_r.append(sci.stats.pearsonr(true, pred)[0])\n",
    "#     rmse.append(math.sqrt(np.mean(abs(true - pred)**2)))\n",
    "#     n_points.append(len(pred))\n",
    "#     print(\"%s - %s\" % (sim_bins_lb[i], sim_bins_ub[i]), r2_scores[-1], pearson_r[-1], rmse[-1], len(pred))\n",
    "    \n",
    "\n",
    "# plt.rcParams.update({'font.size': 24})\n",
    "\n",
    "# fig, ax = plt.subplots(figsize= (8,6))\n",
    "\n",
    "# for i in range(len(sim_bins_lb)):    \n",
    "#     plt.scatter(i, rmse[i], c='navy', marker=\"o\", linewidths= 8)\n",
    "#     ax.annotate(n_points[i], (i-0.08, rmse[i]+0.05), fontsize=17, c= \"black\", weight = \"bold\")\n",
    "\n",
    "    \n",
    "# plt.xlabel('Reaction similarity score')\n",
    "# plt.ylabel('RMSE')\n",
    "# ax.yaxis.set_label_coords(-0.2, 0.5)\n",
    "# ax.xaxis.set_label_coords(0.5,-0.23)\n",
    "\n",
    "# ticks2 = np.array(range(len(sim_bins_lb)))\n",
    "# labs = [\"%s - %s\" % (sim_bins_lb[i], sim_bins_ub[i]) for i in range(len(sim_bins_lb))]\n",
    "# ax.set_xticks(ticks2)\n",
    "# ax.set_xticklabels(labs,  y= -0.03, fontsize=20)\n",
    "# ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# # plt.ylim((0.5,2))\n",
    "# #plt.xlim((-0.5, 3.2))\n",
    "\n",
    "# # plt.plot([-0.49, 4], [0,0], color='grey', linestyle='dashed')\n",
    "# #plt.savefig(join(\"..\",\"..\", \"data\", split, \"figures\", \"Reaction_Similarity_Score.eps\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a model with enzyme and reaction information (ESM-2/diff_fp) + Temperature + pH :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_mse_gradient_boosting(param):\n",
    "#     num_round = param[\"num_rounds\"]\n",
    "#     del param[\"num_rounds\"]\n",
    "#     param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "#     # param[\"device\"] = \"cuda\"\n",
    "#     param[\"tree_method\"] = \"hist\"\n",
    "#     param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "#     MSE = []\n",
    "#     R2 = []\n",
    "#     for i in range(5):\n",
    "#         train_index, test_index  = train_indices[i], test_indices[i]\n",
    "#         dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "#         dvalid = xgb.DMatrix(train_X[test_index])\n",
    "#         bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "#         y_valid_pred = bst.predict(dvalid)\n",
    "#         MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "#         R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "#     return(-np.mean(R2))\n",
    "\n",
    "# space_gradient_boosting = {\n",
    "#     \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "#     \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "#     #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "#     \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "#     \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "#     \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "#     \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "#     \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "#             algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == \"full\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 2, 'max_depth': 5, 'min_child_weight': 4, 'num_rounds': 150, 'reg_alpha': 0.3, 'reg_lambda': 0.4}\n",
    "elif split == \"Arabidopsis\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 4, 'max_depth': 5, 'min_child_weight': 2, 'num_rounds': 150, 'reg_alpha': 0.3, 'reg_lambda': 0.5}\n",
    "elif split == \"Brassicaceae\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 4, 'max_depth': 10, 'min_child_weight': 3, 'num_rounds': 150, 'reg_alpha': 0.3, 'reg_lambda': 0.5}\n",
    "elif split == \"wildtype\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 5, 'max_depth': 7, 'min_child_weight': 3, 'num_rounds': 100, 'reg_alpha': 0.6, 'reg_lambda': 0.6}\n",
    "else:\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 1, 'num_rounds': 150, 'reg_alpha': 0.6, 'reg_lambda': 0.7}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.526793055079571, 0.1700060767512365, -0.035479601756666465, 0.04593716802728603, 0.5929076452629232]\n",
      "[0.00027849678536720577, 0.00048341180068461355, 0.00030698051122754846, 0.0008803492229131115, 0.00026130780896042177]\n",
      "[0.10686676244024462, -0.10744211965482275, -0.11555624757061733, -0.04545793435846357, 0.21211804723762995]\n",
      "[0.00011890249884776927, 0.0002326959009884453, 0.00011732167361809171, 0.00023348257941770237, 9.291775109624213e-05]\n",
      "[4.3935911524319436e-05, 3.2126165230534316e-05, 2.7515805348083702e-05, 5.175251543612183e-05, 2.2740583653679436e-05]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"Pearson_CV_xgboost_ESM2_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"MSE_CV_xgboost_ESM2_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"R2_CV_xgboost_ESM2_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.476 0.0001459171 0.195 6.07771e-05 1.65204e-05\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate Km\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", split,  \"y_test_true_xgboost_ESM2_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.773257276835051, 1.8371108355474325e-11) 0.00011989066280565835 0.45670636527444297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"difference_fp\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_Km\"]))\n",
    "\n",
    "val_X = val_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(list(chain(*data_val[\"Km_values\"]))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.24531394760451494, 0.29719157397868873) 0.00215803361341994 -0.15327045440497122 0.0007761236496223211 7.097105572640298e-05\n"
     ]
    }
   ],
   "source": [
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate Km\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a model with enzyme, main substrate (MACCS fp) and reaction information (ESM-2/diff_fp) + Temperature + pH :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_mse_gradient_boosting(param):\n",
    "#     num_round = param[\"num_rounds\"]\n",
    "#     del param[\"num_rounds\"]\n",
    "#     param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "#     # param[\"device\"] = \"cuda\"\n",
    "#     param[\"tree_method\"] = \"hist\"\n",
    "#     param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "#     MSE = []\n",
    "#     R2 = []\n",
    "#     for i in range(5):\n",
    "#         train_index, test_index  = train_indices[i], test_indices[i]\n",
    "#         dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "#         dvalid = xgb.DMatrix(train_X[test_index])\n",
    "#         bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "#         y_valid_pred = bst.predict(dvalid)\n",
    "#         MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "#         R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "#     return(-np.mean(R2))\n",
    "\n",
    "\n",
    "# space_gradient_boosting = {\n",
    "#     \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "#     \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "#     #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "#     \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "#     \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "#     \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "#     \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "#     \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "#             algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == \"full\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.09, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 6, 'num_rounds': 200, 'reg_alpha': 0.8, 'reg_lambda': 0.3}\n",
    "elif split == \"Arabidopsis\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 4, 'max_depth': 5, 'min_child_weight': 2, 'num_rounds': 150, 'reg_alpha': 0.3, 'reg_lambda': 0.5}\n",
    "elif split == \"Brassicaceae\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.06, 'max_delta_step': 4, 'max_depth': 3, 'min_child_weight': 5, 'num_rounds': 200, 'reg_alpha': 0.2, 'reg_lambda': 0.2}\n",
    "elif split == \"wildtype\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 2, 'max_depth': 6, 'min_child_weight': 6, 'num_rounds': 200, 'reg_alpha': 0.8, 'reg_lambda': 0.9}\n",
    "else:\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.09, 'max_delta_step': 5, 'max_depth': 5, 'min_child_weight': 5, 'num_rounds': 150, 'reg_alpha': 0.2, 'reg_lambda': 0.6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5259810956879604, 0.1182954424011315, 0.030526978655547946, 0.32699084794134714, 0.8583641434896496]\n",
      "[0.0002658775297368224, 0.0004845023141852751, 0.0003055601319254288, 0.0008611018853330972, 0.0001822237828373374]\n",
      "[0.18597236492921754, -0.11244424316659263, -0.10525691438084372, -0.00024335008507492262, 0.6168520627064236]\n",
      "[0.00011573153159765395, 0.00024483091208398123, 0.00011723019837027846, 0.00022796808944951902, 8.093106167231557e-05]\n",
      "[2.482024871521398e-05, 7.246230959778643e-05, 2.244813253836015e-05, 5.5931376107187946e-05, 1.3045890398064937e-05]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"Pearson_CV_xgboost_ESM2_gnn_fp_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"MSE_CV_xgboost_ESM2_gnn_fp_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"R2_CV_xgboost_ESM2_gnn_fp_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.402 0.0001512587 0.135 5.95727e-05 1.59868e-05\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate Km\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_gnn_fp_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", split,  \"y_test_true_xgboost_ESM2_gnn_fp_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8905246210884016, 9.907260189585665e-19) 9.715656792969458e-05 0.6432136552787149\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"difference_fp\"])), np.array(list(data_val[\"GNN FP\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_Km\"]))\n",
    "\n",
    "val_X = val_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(list(chain(*data_val[\"Km_values\"]))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.13319509423793982, 0.5756047509489909) 0.0021499859463372556 -0.14468501703009284 0.0007889947968597419 0.00013918870256358882\n"
     ]
    }
   ],
   "source": [
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate Km\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training a model with enzyme information (ESM-2) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_mse_gradient_boosting(param):\n",
    "#     num_round = param[\"num_rounds\"]\n",
    "#     del param[\"num_rounds\"]\n",
    "#     param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "#     # param[\"device\"] = \"cuda\"\n",
    "#     param[\"tree_method\"] = \"hist\"\n",
    "#     param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "#     MSE = []\n",
    "#     R2 = []\n",
    "#     for i in range(5):\n",
    "#         train_index, test_index  = train_indices[i], test_indices[i]\n",
    "#         dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "#         dvalid = xgb.DMatrix(train_X[test_index])\n",
    "#         bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "#         y_valid_pred = bst.predict(dvalid)\n",
    "#         MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "#         R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "#     return(-np.mean(R2))\n",
    "\n",
    "\n",
    "# space_gradient_boosting = {\n",
    "#     \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "#     \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "#     #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "#     \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "#     \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "#     \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "#     \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "#     \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "#             algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == \"full\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 5, 'max_depth': 6, 'min_child_weight': 4, 'num_rounds': 150, 'reg_alpha': 0.6, 'reg_lambda': 0.4}\n",
    "elif split == \"Arabidopsis\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 2, 'max_depth': 5, 'min_child_weight': 1, 'num_rounds': 200, 'reg_alpha': 1, 'reg_lambda': 0.2}\n",
    "elif split == \"Brassicaceae\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.05, 'max_delta_step': 1, 'max_depth': 7, 'min_child_weight': 5, 'num_rounds': 200, 'reg_alpha': 0.6, 'reg_lambda': 0.4}\n",
    "elif split == \"wildtype\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 5, 'max_depth': 5, 'min_child_weight': 2, 'num_rounds': 150, 'reg_alpha': 0.9, 'reg_lambda': 0.4}\n",
    "else:\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.07, 'max_delta_step' : 1, 'max_depth': 6, 'min_child_weight': 6, 'num_rounds': 200, 'reg_alpha': 1, 'reg_lambda': 0.6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4871572408063976, 0.016835854409076506, -0.01475021139113114, 0.3096808741574828, 0.5963081863912776]\n",
      "[0.00028395539107088007, 0.000498812766476974, 0.0003082951533030138, 0.0008674991120977195, 0.00026954555123526923]\n",
      "[0.07151238411940575, -0.1791299258177914, -0.12513143158213347, -0.015160405304329716, 0.1616589882607088]\n",
      "[0.00011649575778439775, 0.00024454252664929404, 0.00012136759400365631, 0.00023197080156854493, 9.066298430823439e-05]\n",
      "[3.1485585508387895e-05, 3.7932510961464575e-05, 3.471700013218737e-05, 3.535732095490062e-05, 2.288702891838941e-05]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"Pearson_CV_xgboost_ESM2.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"MSE_CV_xgboost_ESM2.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"R2_CV_xgboost_ESM2.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524 0.0001456432 0.198 5.89234e-05 2.48737e-05\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate Km\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", split,  \"y_test_true_xgboost_ESM2.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate Km\"] = [10**x for x in data_test[\"Estimate Km\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6252710856791355, 7.212808717968775e-07) 0.00013162662318852612 0.3451356114449423\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "167\n",
      "f0: 4.0\n",
      "f1: 3.0\n",
      "f3: 3.0\n",
      "f4: 1.0\n",
      "f5: 2.0\n",
      "f7: 2.0\n",
      "f8: 4.0\n",
      "f9: 1.0\n",
      "f10: 5.0\n",
      "f11: 3.0\n",
      "f12: 2.0\n",
      "f14: 6.0\n",
      "f17: 2.0\n",
      "f19: 1.0\n",
      "f23: 1.0\n",
      "f24: 3.0\n",
      "f30: 3.0\n",
      "f31: 3.0\n",
      "f35: 2.0\n",
      "f36: 1.0\n",
      "f37: 1.0\n",
      "f38: 4.0\n",
      "f40: 2.0\n",
      "f42: 1.0\n",
      "f44: 5.0\n",
      "f45: 1.0\n",
      "f46: 4.0\n",
      "f47: 1.0\n",
      "f49: 3.0\n",
      "f51: 1.0\n",
      "f52: 4.0\n",
      "f54: 5.0\n",
      "f55: 2.0\n",
      "f56: 1.0\n",
      "f58: 1.0\n",
      "f60: 3.0\n",
      "f64: 2.0\n",
      "f66: 1.0\n",
      "f71: 1.0\n",
      "f72: 1.0\n",
      "f75: 3.0\n",
      "f83: 3.0\n",
      "f84: 1.0\n",
      "f91: 1.0\n",
      "f92: 1.0\n",
      "f93: 1.0\n",
      "f94: 1.0\n",
      "f95: 3.0\n",
      "f97: 2.0\n",
      "f99: 6.0\n",
      "f100: 1.0\n",
      "f106: 8.0\n",
      "f107: 3.0\n",
      "f108: 2.0\n",
      "f111: 1.0\n",
      "f112: 1.0\n",
      "f113: 1.0\n",
      "f119: 1.0\n",
      "f125: 3.0\n",
      "f127: 5.0\n",
      "f132: 2.0\n",
      "f135: 2.0\n",
      "f140: 2.0\n",
      "f141: 1.0\n",
      "f148: 2.0\n",
      "f149: 5.0\n",
      "f150: 12.0\n",
      "f156: 2.0\n",
      "f157: 1.0\n",
      "f162: 1.0\n",
      "f164: 4.0\n",
      "f169: 1.0\n",
      "f170: 13.0\n",
      "f172: 19.0\n",
      "f176: 1.0\n",
      "f177: 2.0\n",
      "f178: 1.0\n",
      "f180: 2.0\n",
      "f181: 2.0\n",
      "f185: 4.0\n",
      "f192: 7.0\n",
      "f195: 4.0\n",
      "f196: 2.0\n",
      "f197: 3.0\n",
      "f198: 1.0\n",
      "f199: 1.0\n",
      "f201: 6.0\n",
      "f205: 1.0\n",
      "f206: 1.0\n",
      "f209: 1.0\n",
      "f214: 2.0\n",
      "f217: 1.0\n",
      "f220: 1.0\n",
      "f221: 1.0\n",
      "f223: 2.0\n",
      "f225: 1.0\n",
      "f228: 10.0\n",
      "f235: 1.0\n",
      "f236: 1.0\n",
      "f238: 4.0\n",
      "f242: 2.0\n",
      "f243: 6.0\n",
      "f254: 1.0\n",
      "f260: 7.0\n",
      "f264: 1.0\n",
      "f267: 4.0\n",
      "f269: 5.0\n",
      "f270: 3.0\n",
      "f274: 1.0\n",
      "f279: 3.0\n",
      "f290: 10.0\n",
      "f292: 1.0\n",
      "f294: 1.0\n",
      "f297: 1.0\n",
      "f298: 1.0\n",
      "f305: 2.0\n",
      "f307: 3.0\n",
      "f312: 4.0\n",
      "f316: 2.0\n",
      "f320: 1.0\n",
      "f322: 2.0\n",
      "f325: 3.0\n",
      "f329: 2.0\n",
      "f330: 4.0\n",
      "f332: 3.0\n",
      "f335: 4.0\n",
      "f336: 4.0\n",
      "f337: 1.0\n",
      "f339: 4.0\n",
      "f346: 1.0\n",
      "f347: 1.0\n",
      "f348: 2.0\n",
      "f349: 1.0\n",
      "f355: 1.0\n",
      "f363: 2.0\n",
      "f364: 8.0\n",
      "f365: 1.0\n",
      "f366: 2.0\n",
      "f370: 1.0\n",
      "f371: 1.0\n",
      "f388: 2.0\n",
      "f391: 1.0\n",
      "f392: 1.0\n",
      "f394: 1.0\n",
      "f397: 2.0\n",
      "f398: 1.0\n",
      "f400: 2.0\n",
      "f403: 1.0\n",
      "f409: 1.0\n",
      "f414: 1.0\n",
      "f419: 3.0\n",
      "f431: 1.0\n",
      "f433: 12.0\n",
      "f434: 5.0\n",
      "f436: 1.0\n",
      "f437: 1.0\n",
      "f438: 1.0\n",
      "f440: 2.0\n",
      "f447: 1.0\n",
      "f451: 2.0\n",
      "f453: 1.0\n",
      "f454: 1.0\n",
      "f456: 2.0\n",
      "f458: 1.0\n",
      "f465: 1.0\n",
      "f471: 1.0\n",
      "f481: 1.0\n",
      "f483: 2.0\n",
      "f484: 5.0\n",
      "f486: 2.0\n",
      "f491: 1.0\n",
      "f492: 3.0\n",
      "f493: 1.0\n",
      "f494: 1.0\n",
      "f497: 1.0\n",
      "f499: 1.0\n",
      "f500: 6.0\n",
      "f506: 2.0\n",
      "f508: 1.0\n",
      "f511: 8.0\n",
      "f516: 3.0\n",
      "f517: 1.0\n",
      "f518: 1.0\n",
      "f524: 2.0\n",
      "f527: 10.0\n",
      "f529: 2.0\n",
      "f531: 2.0\n",
      "f539: 1.0\n",
      "f545: 1.0\n",
      "f547: 1.0\n",
      "f548: 3.0\n",
      "f550: 2.0\n",
      "f554: 1.0\n",
      "f557: 1.0\n",
      "f559: 3.0\n",
      "f561: 1.0\n",
      "f564: 1.0\n",
      "f566: 2.0\n",
      "f575: 13.0\n",
      "f577: 2.0\n",
      "f580: 4.0\n",
      "f584: 3.0\n",
      "f585: 2.0\n",
      "f587: 2.0\n",
      "f588: 2.0\n",
      "f596: 1.0\n",
      "f598: 4.0\n",
      "f600: 1.0\n",
      "f603: 2.0\n",
      "f604: 2.0\n",
      "f616: 1.0\n",
      "f625: 7.0\n",
      "f631: 7.0\n",
      "f632: 12.0\n",
      "f636: 1.0\n",
      "f646: 1.0\n",
      "f647: 2.0\n",
      "f650: 2.0\n",
      "f652: 1.0\n",
      "f657: 22.0\n",
      "f658: 2.0\n",
      "f659: 1.0\n",
      "f666: 6.0\n",
      "f670: 2.0\n",
      "f676: 3.0\n",
      "f683: 1.0\n",
      "f684: 1.0\n",
      "f686: 1.0\n",
      "f688: 3.0\n",
      "f692: 2.0\n",
      "f695: 1.0\n",
      "f699: 1.0\n",
      "f700: 1.0\n",
      "f701: 2.0\n",
      "f708: 5.0\n",
      "f711: 2.0\n",
      "f722: 5.0\n",
      "f723: 13.0\n",
      "f726: 3.0\n",
      "f729: 2.0\n",
      "f733: 1.0\n",
      "f737: 1.0\n",
      "f740: 5.0\n",
      "f742: 2.0\n",
      "f743: 4.0\n",
      "f748: 1.0\n",
      "f753: 3.0\n",
      "f755: 1.0\n",
      "f758: 1.0\n",
      "f759: 10.0\n",
      "f761: 2.0\n",
      "f763: 1.0\n",
      "f768: 1.0\n",
      "f771: 1.0\n",
      "f781: 3.0\n",
      "f782: 2.0\n",
      "f792: 4.0\n",
      "f793: 1.0\n",
      "f794: 11.0\n",
      "f800: 1.0\n",
      "f805: 9.0\n",
      "f808: 1.0\n",
      "f809: 2.0\n",
      "f813: 1.0\n",
      "f816: 3.0\n",
      "f818: 4.0\n",
      "f819: 2.0\n",
      "f820: 5.0\n",
      "f821: 4.0\n",
      "f822: 2.0\n",
      "f825: 13.0\n",
      "f838: 4.0\n",
      "f839: 1.0\n",
      "f841: 1.0\n",
      "f843: 31.0\n",
      "f844: 3.0\n",
      "f845: 1.0\n",
      "f848: 3.0\n",
      "f852: 2.0\n",
      "f856: 3.0\n",
      "f859: 1.0\n",
      "f860: 3.0\n",
      "f862: 1.0\n",
      "f864: 2.0\n",
      "f866: 1.0\n",
      "f867: 1.0\n",
      "f869: 7.0\n",
      "f875: 1.0\n",
      "f876: 16.0\n",
      "f879: 2.0\n",
      "f882: 2.0\n",
      "f887: 1.0\n",
      "f890: 1.0\n",
      "f892: 3.0\n",
      "f897: 2.0\n",
      "f899: 1.0\n",
      "f901: 3.0\n",
      "f902: 2.0\n",
      "f908: 3.0\n",
      "f909: 1.0\n",
      "f910: 2.0\n",
      "f914: 1.0\n",
      "f916: 8.0\n",
      "f920: 5.0\n",
      "f921: 1.0\n",
      "f924: 1.0\n",
      "f929: 2.0\n",
      "f940: 13.0\n",
      "f941: 1.0\n",
      "f945: 1.0\n",
      "f950: 1.0\n",
      "f957: 1.0\n",
      "f960: 5.0\n",
      "f962: 1.0\n",
      "f967: 8.0\n",
      "f969: 2.0\n",
      "f971: 1.0\n",
      "f977: 1.0\n",
      "f978: 6.0\n",
      "f982: 8.0\n",
      "f987: 2.0\n",
      "f991: 1.0\n",
      "f998: 3.0\n",
      "f1000: 1.0\n",
      "f1002: 2.0\n",
      "f1003: 1.0\n",
      "f1005: 1.0\n",
      "f1007: 1.0\n",
      "f1009: 4.0\n",
      "f1014: 2.0\n",
      "f1015: 1.0\n",
      "f1018: 4.0\n",
      "f1022: 1.0\n",
      "f1026: 2.0\n",
      "f1027: 3.0\n",
      "f1032: 4.0\n",
      "f1037: 5.0\n",
      "f1039: 1.0\n",
      "f1041: 2.0\n",
      "f1042: 2.0\n",
      "f1046: 1.0\n",
      "f1050: 6.0\n",
      "f1052: 18.0\n",
      "f1057: 2.0\n",
      "f1059: 1.0\n",
      "f1060: 1.0\n",
      "f1061: 4.0\n",
      "f1070: 2.0\n",
      "f1074: 2.0\n",
      "f1080: 1.0\n",
      "f1086: 1.0\n",
      "f1091: 1.0\n",
      "f1094: 2.0\n",
      "f1095: 2.0\n",
      "f1103: 5.0\n",
      "f1104: 2.0\n",
      "f1105: 4.0\n",
      "f1108: 3.0\n",
      "f1110: 3.0\n",
      "f1112: 2.0\n",
      "f1114: 2.0\n",
      "f1117: 1.0\n",
      "f1118: 1.0\n",
      "f1120: 1.0\n",
      "f1122: 10.0\n",
      "f1124: 1.0\n",
      "f1126: 6.0\n",
      "f1131: 1.0\n",
      "f1133: 5.0\n",
      "f1135: 4.0\n",
      "f1139: 12.0\n",
      "f1148: 3.0\n",
      "f1149: 2.0\n",
      "f1150: 7.0\n",
      "f1165: 5.0\n",
      "f1167: 6.0\n",
      "f1169: 1.0\n",
      "f1171: 5.0\n",
      "f1182: 3.0\n",
      "f1184: 1.0\n",
      "f1187: 1.0\n",
      "f1192: 3.0\n",
      "f1193: 1.0\n",
      "f1196: 4.0\n",
      "f1200: 3.0\n",
      "f1201: 2.0\n",
      "f1208: 1.0\n",
      "f1209: 1.0\n",
      "f1211: 4.0\n",
      "f1214: 2.0\n",
      "f1216: 5.0\n",
      "f1218: 3.0\n",
      "f1224: 2.0\n",
      "f1228: 1.0\n",
      "f1232: 2.0\n",
      "f1244: 2.0\n",
      "f1255: 2.0\n",
      "f1259: 1.0\n",
      "f1261: 1.0\n",
      "f1265: 1.0\n",
      "f1269: 3.0\n",
      "f1272: 2.0\n",
      "f1274: 1.0\n",
      "f1277: 2.0\n",
      "f1280: 95.0\n",
      "f1281: 145.0\n"
     ]
    }
   ],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.09092464081633021, 0.7030280294838331) 0.002152009102983408 -0.14684034900775544 0.0007743314806783118 9.068195324952755e-05\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_Km\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate Km\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "plt.scatter([10**x for x in val_Y],[10**x for x in y_val_pred],c='green', edgecolors='black',s=40)\n",
    "    \n",
    "plt.xlim(-0.0005,0.003)\n",
    "plt.ylim(-0.0005,0.0015)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Real value', fontsize=15)\n",
    "plt.ylabel('Estimated value', fontsize=15)\n",
    "plt.title('Predictions for Km', fontsize=15)\n",
    "plt.axline((1, 1), slope=1, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a model with main substrate information (MACCS) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train['GNN FP']))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test['GNN FP']))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_mse_gradient_boosting(param):\n",
    "#     num_round = param[\"num_rounds\"]\n",
    "#     del param[\"num_rounds\"]\n",
    "#     param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "#     # param[\"device\"] = \"cuda\"\n",
    "#     param[\"tree_method\"] = \"hist\"\n",
    "#     param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "#     MSE = []\n",
    "#     R2 = []\n",
    "#     for i in range(5):\n",
    "#         train_index, test_index  = train_indices[i], test_indices[i]\n",
    "#         dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "#         dvalid = xgb.DMatrix(train_X[test_index])\n",
    "#         bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "#         y_valid_pred = bst.predict(dvalid)\n",
    "#         MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "#         R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "#     return(-np.mean(R2))\n",
    "\n",
    "# space_gradient_boosting = {\n",
    "#     \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "#     \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "#     #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "#     \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "#     \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "#     \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "#     \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "#     \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "#             algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == \"full\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.05, 'max_delta_step': 2, 'max_depth': 6, 'min_child_weight': 3, 'num_rounds': 200, 'reg_alpha': 0.6, 'reg_lambda': 0.5}\n",
    "elif split == \"Arabidopsis\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 4, 'max_depth': 6, 'min_child_weight': 2, 'num_rounds': 50, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
    "elif split == \"Brassicaceae\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.06, 'max_delta_step': 1, 'max_depth': 9, 'min_child_weight': 5, 'num_rounds': 150, 'reg_alpha': 0.6, 'reg_lambda': 1}\n",
    "elif split == \"wildtype\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.03, 'max_delta_step': 1, 'max_depth': 7, 'min_child_weight': 3, 'num_rounds': 150, 'reg_alpha': 0.7, 'reg_lambda': 0.2}\n",
    "else:\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 4, 'max_depth': 3, 'min_child_weight': 6, 'num_rounds': 100, 'reg_alpha': 0.6, 'reg_lambda': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20048239669261325, 0.5896957456063747, 0.17002387343376374, 0.13419817815756577, 0.3169318241121194]\n",
      "[0.00030713075972670724, 0.0004257411832992769, 0.0002988482540867538, 0.0008726847651251482, 0.00027954421115631444]\n",
      "[-0.08623178461308822, 0.14103025502026567, -0.05723445613598144, -0.027333337077096287, 0.09830973215126171]\n",
      "[0.000146908466087426, 0.00019726729830796554, 0.00012025696246414877, 0.00023086136794220227, 0.00011688953376550764]\n",
      "[3.4838415880381776e-05, 3.5570255588528626e-05, 3.4602710780501275e-05, 6.987935032027305e-05, 3.6037959400479275e-05]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"Pearson_CV_xgboost_gnn_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"MSE_CV_xgboost_gnn_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"R2_CV_xgboost_gnn_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 0.0001802165 -0.228 9.15454e-05 2.53954e-05\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate Km\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_gnn_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", split,  \"y_test_true_xgboost_gnn_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate Km\"] = [10**x for x in data_test[\"Estimate Km\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"GNN FP\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"GNN FP\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6705559599866642, 5.3729708505681804e-08) 0.00014243048684974525 0.2332217029831215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "167\n",
      "f0: 22.0\n",
      "f1: 19.0\n",
      "f2: 4.0\n",
      "f4: 21.0\n",
      "f5: 10.0\n",
      "f6: 2.0\n",
      "f7: 12.0\n",
      "f8: 9.0\n",
      "f9: 13.0\n",
      "f12: 4.0\n",
      "f14: 9.0\n",
      "f16: 31.0\n",
      "f17: 11.0\n",
      "f18: 11.0\n",
      "f19: 12.0\n",
      "f21: 1.0\n",
      "f22: 18.0\n",
      "f24: 16.0\n",
      "f25: 11.0\n",
      "f26: 5.0\n",
      "f29: 2.0\n",
      "f34: 17.0\n",
      "f35: 7.0\n",
      "f37: 11.0\n",
      "f39: 24.0\n",
      "f41: 6.0\n",
      "f42: 12.0\n",
      "f43: 3.0\n",
      "f45: 2.0\n",
      "f46: 3.0\n",
      "f50: 45.0\n",
      "f51: 151.0\n"
     ]
    }
   ],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.21820862033578536, 0.3553667798264027) 0.00214596461765405 -0.14040698922700767 0.0007829129141430566 0.00010355857986449015\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"GNN FP\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_Km\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate Km\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE,MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training a model with reaction information (diff-fp) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_mse_gradient_boosting(param):\n",
    "#     num_round = param[\"num_rounds\"]\n",
    "#     del param[\"num_rounds\"]\n",
    "#     param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "#     # param[\"device\"] = \"cuda\"\n",
    "#     param[\"tree_method\"] = \"hist\"\n",
    "#     param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "#     MSE = []\n",
    "#     R2 = []\n",
    "#     for i in range(5):\n",
    "#         train_index, test_index  = train_indices[i], test_indices[i]\n",
    "#         dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "#         dvalid = xgb.DMatrix(train_X[test_index])\n",
    "#         bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "#         y_valid_pred = bst.predict(dvalid)\n",
    "#         MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "#         R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "#     return(-np.mean(R2))\n",
    "\n",
    "\n",
    "# space_gradient_boosting = {\n",
    "#     \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "#     \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "#     #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "#     \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "#     \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "#     \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "#     \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "#     \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "#             algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == \"full\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 9, 'min_child_weight': 4, 'num_rounds': 200, 'reg_alpha': 0.3, 'reg_lambda': 0.6}\n",
    "elif split == \"Arabidopsis\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.09, 'max_delta_step': 5, 'max_depth': 8, 'min_child_weight': 3, 'num_rounds': 150, 'reg_alpha': 0.8, 'reg_lambda': 0.2}\n",
    "elif split == \"Brassicaceae\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.03, 'max_delta_step': 5, 'max_depth': 7, 'min_child_weight': 4, 'num_rounds': 200, 'reg_alpha': 0.5, 'reg_lambda': 0.6}\n",
    "elif split == \"wildtype\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.05, 'max_delta_step': 5, 'max_depth': 7, 'min_child_weight': 4, 'num_rounds': 200, 'reg_alpha': 0.9, 'reg_lambda': 0.2}\n",
    "else:\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.06, 'max_delta_step': 3, 'max_depth': 3, 'min_child_weight': 3, 'num_rounds': 200, 'reg_alpha': 0.4, 'reg_lambda': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5677031774152325, 0.5508369215255029, 0.13034056237231872, 0.2542880115838869, 0.16611758160147166]\n",
      "[0.0002442398306063694, 0.00044698454409231703, 0.00030439257470662334, 0.0008684682485782389, 0.0002948660908243709]\n",
      "[0.31307573331819805, 0.05317099414302917, -0.096826591683842, -0.01742986821556336, -0.003242773477046823]\n",
      "[0.0001241997339462623, 0.00020076545888160198, 0.00011763127468796472, 0.00022278984839259466, 9.853350760043308e-05]\n",
      "[3.24616845626503e-05, 3.770670536476129e-05, 2.4052792021037533e-05, 3.12880914253343e-05, 2.787376233781662e-05]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"Pearson_CV_xgboost_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"MSE_CV_xgboost_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"R2_CV_xgboost_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.171 0.0001649833 -0.029 6.68308e-05 1.57636e-05\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate Km\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", split,  \"y_test_true_xgboost_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate Km\"] = [10**x for x in data_test[\"Estimate Km\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8008211225299675, 1.023382532076462e-12) 0.00013128122173974976 0.3485679616643709\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "167\n",
      "f7: 1.0\n",
      "f11: 1.0\n",
      "f28: 27.0\n",
      "f29: 18.0\n",
      "f60: 4.0\n",
      "f61: 3.0\n",
      "f75: 13.0\n",
      "f94: 6.0\n",
      "f95: 2.0\n",
      "f111: 1.0\n",
      "f115: 2.0\n",
      "f116: 22.0\n",
      "f124: 6.0\n",
      "f125: 7.0\n",
      "f137: 7.0\n",
      "f138: 1.0\n",
      "f157: 18.0\n",
      "f158: 3.0\n",
      "f159: 8.0\n",
      "f178: 5.0\n",
      "f190: 4.0\n",
      "f192: 4.0\n",
      "f200: 5.0\n",
      "f201: 4.0\n",
      "f212: 5.0\n",
      "f216: 2.0\n",
      "f223: 1.0\n",
      "f231: 2.0\n",
      "f246: 10.0\n",
      "f255: 3.0\n",
      "f270: 13.0\n",
      "f283: 1.0\n",
      "f334: 13.0\n",
      "f335: 3.0\n",
      "f377: 4.0\n",
      "f412: 4.0\n",
      "f563: 1.0\n",
      "f571: 3.0\n",
      "f584: 4.0\n",
      "f637: 4.0\n",
      "f682: 14.0\n",
      "f704: 4.0\n",
      "f776: 2.0\n",
      "f778: 4.0\n",
      "f798: 3.0\n",
      "f823: 14.0\n",
      "f837: 1.0\n",
      "f863: 13.0\n",
      "f883: 14.0\n",
      "f888: 1.0\n",
      "f909: 1.0\n",
      "f910: 3.0\n",
      "f938: 2.0\n",
      "f939: 9.0\n",
      "f944: 3.0\n",
      "f952: 13.0\n",
      "f953: 6.0\n",
      "f1005: 5.0\n",
      "f1009: 2.0\n",
      "f1018: 2.0\n",
      "f1019: 5.0\n",
      "f1032: 1.0\n",
      "f1040: 2.0\n",
      "f1048: 4.0\n",
      "f1049: 7.0\n",
      "f1050: 3.0\n",
      "f1051: 3.0\n",
      "f1077: 13.0\n",
      "f1088: 1.0\n",
      "f1096: 2.0\n",
      "f1097: 5.0\n",
      "f1099: 2.0\n",
      "f1104: 2.0\n",
      "f1105: 2.0\n",
      "f1113: 1.0\n",
      "f1115: 4.0\n",
      "f1162: 13.0\n",
      "f1206: 1.0\n",
      "f1208: 2.0\n",
      "f1214: 2.0\n",
      "f1221: 5.0\n",
      "f1277: 23.0\n",
      "f1290: 11.0\n",
      "f1293: 1.0\n",
      "f1302: 8.0\n",
      "f1309: 6.0\n",
      "f1318: 1.0\n",
      "f1350: 4.0\n",
      "f1353: 2.0\n",
      "f1358: 2.0\n",
      "f1372: 7.0\n",
      "f1373: 7.0\n",
      "f1410: 5.0\n",
      "f1426: 11.0\n",
      "f1440: 2.0\n",
      "f1490: 2.0\n",
      "f1498: 1.0\n",
      "f1499: 26.0\n",
      "f1615: 4.0\n",
      "f1657: 3.0\n",
      "f1669: 2.0\n",
      "f1670: 12.0\n",
      "f1684: 7.0\n",
      "f1692: 4.0\n",
      "f1697: 34.0\n",
      "f1731: 14.0\n",
      "f1732: 1.0\n",
      "f1735: 7.0\n",
      "f1741: 1.0\n",
      "f1749: 28.0\n",
      "f1816: 3.0\n",
      "f1847: 5.0\n",
      "f1851: 1.0\n",
      "f1852: 1.0\n",
      "f1869: 5.0\n",
      "f2001: 9.0\n",
      "f2048: 58.0\n",
      "f2049: 111.0\n"
     ]
    }
   ],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.026258404194839012, 0.9124980438885376) 0.0021378004747610578 -0.13174632899619887 0.0008448064218940633 0.0001306058927739701\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"difference_fp\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_Km\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate Km\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training a model with reaction and main substrate information (diff-fp/MACCS) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation_mse_gradient_boosting(param):\n",
    "#     num_round = param[\"num_rounds\"]\n",
    "#     del param[\"num_rounds\"]\n",
    "#     param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "#     # param[\"device\"] = \"cuda\"\n",
    "#     param[\"tree_method\"] = \"hist\"\n",
    "#     param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "#     MSE = []\n",
    "#     R2 = []\n",
    "#     for i in range(5):\n",
    "#         train_index, test_index  = train_indices[i], test_indices[i]\n",
    "#         dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "#         dvalid = xgb.DMatrix(train_X[test_index])\n",
    "#         bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "#         y_valid_pred = bst.predict(dvalid)\n",
    "#         MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "#         R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "#     return(-np.mean(R2))\n",
    "\n",
    "\n",
    "# space_gradient_boosting = {\n",
    "#     \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "#     \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "#     #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "#     \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "#     \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "#     \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "#     \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "#     \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "# trials = Trials()\n",
    "# best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "#             algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == \"full\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 4, 'max_depth': 7, 'min_child_weight': 2, 'num_rounds': 200, 'reg_alpha': 0.4, 'reg_lambda': 0.4}\n",
    "elif split == \"Arabidopsis\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.07, 'max_delta_step': 5, 'max_depth': 5, 'min_child_weight': 5, 'num_rounds': 200, 'reg_alpha': 0.8, 'reg_lambda': 0.4}\n",
    "elif split == \"Brassicaceae\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.06, 'max_delta_step': 5, 'max_depth': 6, 'min_child_weight': 4, 'num_rounds': 200, 'reg_alpha': 0.4, 'reg_lambda': 0.9}\n",
    "elif split == \"wildtype\":\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.09, 'max_delta_step': 5, 'max_depth': 6, 'min_child_weight': 5, 'num_rounds': 150, 'reg_alpha': 0.7, 'reg_lambda': 1}\n",
    "else:\n",
    "    param = {\"random_state\": 42, 'learning_rate': 0.07, 'max_delta_step': 2, 'max_depth': 9, 'min_child_weight': 3, 'num_rounds': 200, 'reg_alpha': 0.2, 'reg_lambda': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6125042450242191, 0.5351191773256632, 0.07097604662058227, 0.7364112800392792, 0.6033355868639574]\n",
      "[0.0002514592763138572, 0.00042457118709594355, 0.00030528517368467106, 0.0007867900738518901, 0.0002533465382157636]\n",
      "[0.2718661835417353, 0.1457449053830946, -0.10326867878943857, 0.1649464301134681, 0.2593955376044337]\n",
      "[0.00013709142503288486, 0.000191717500389625, 0.0001144420242018666, 0.00020835310206154307, 9.611312756633567e-05]\n",
      "[4.198833984851883e-05, 3.976653087950103e-05, 2.502658872099611e-05, 3.516790408571062e-05, 1.4317344946594623e-05]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"Pearson_CV_xgboost_gnn_fp_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"MSE_CV_xgboost_gnn_fp_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"R2_CV_xgboost_gnn_fp_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5176631383982937 0.0001415993 0.242 6.2332e-05 1.6074e-05\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate Km\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = np.corrcoef(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[1,0],20) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_gnn_fp_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", split,  \"y_test_true_xgboost_gnn_fp_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate Km\"] = [10**x for x in data_test[\"Estimate Km\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_Km\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_Km\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9355173621562881, 3.048212484990304e-24) 7.860996616570964e-05 0.7664288961493375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "167\n",
      "f4: 47.0\n",
      "f5: 9.0\n",
      "f6: 58.0\n",
      "f7: 9.0\n",
      "f11: 17.0\n",
      "f13: 7.0\n",
      "f22: 22.0\n",
      "f23: 1.0\n",
      "f28: 46.0\n",
      "f29: 8.0\n",
      "f31: 2.0\n",
      "f36: 1.0\n",
      "f43: 23.0\n",
      "f52: 3.0\n",
      "f60: 18.0\n",
      "f61: 31.0\n",
      "f71: 10.0\n",
      "f72: 3.0\n",
      "f74: 4.0\n",
      "f75: 54.0\n",
      "f77: 8.0\n",
      "f90: 1.0\n",
      "f94: 23.0\n",
      "f95: 53.0\n",
      "f97: 4.0\n",
      "f106: 1.0\n",
      "f115: 3.0\n",
      "f116: 16.0\n",
      "f119: 5.0\n",
      "f124: 37.0\n",
      "f125: 19.0\n",
      "f134: 7.0\n",
      "f137: 3.0\n",
      "f138: 55.0\n",
      "f146: 1.0\n",
      "f157: 15.0\n",
      "f158: 18.0\n",
      "f159: 1.0\n",
      "f161: 1.0\n",
      "f162: 1.0\n",
      "f169: 4.0\n",
      "f178: 10.0\n",
      "f181: 18.0\n",
      "f190: 24.0\n",
      "f192: 7.0\n",
      "f193: 3.0\n",
      "f194: 5.0\n",
      "f195: 5.0\n",
      "f200: 15.0\n",
      "f201: 39.0\n",
      "f202: 2.0\n",
      "f203: 1.0\n",
      "f207: 4.0\n",
      "f232: 1.0\n",
      "f241: 12.0\n",
      "f246: 12.0\n",
      "f254: 11.0\n",
      "f255: 14.0\n",
      "f283: 2.0\n",
      "f307: 1.0\n",
      "f311: 5.0\n",
      "f312: 7.0\n",
      "f314: 1.0\n",
      "f332: 4.0\n",
      "f334: 45.0\n",
      "f335: 1.0\n",
      "f374: 16.0\n",
      "f377: 10.0\n",
      "f412: 5.0\n",
      "f431: 3.0\n",
      "f443: 2.0\n",
      "f476: 11.0\n",
      "f477: 25.0\n",
      "f529: 4.0\n",
      "f563: 20.0\n",
      "f570: 3.0\n",
      "f571: 15.0\n",
      "f584: 5.0\n",
      "f585: 1.0\n",
      "f630: 7.0\n",
      "f648: 9.0\n",
      "f649: 1.0\n",
      "f682: 16.0\n",
      "f704: 2.0\n",
      "f706: 1.0\n",
      "f728: 15.0\n",
      "f754: 1.0\n",
      "f764: 11.0\n",
      "f776: 38.0\n",
      "f778: 2.0\n",
      "f780: 3.0\n",
      "f783: 3.0\n",
      "f786: 2.0\n",
      "f796: 6.0\n",
      "f798: 24.0\n",
      "f808: 34.0\n",
      "f823: 44.0\n",
      "f837: 1.0\n",
      "f844: 19.0\n",
      "f863: 1.0\n",
      "f880: 1.0\n",
      "f883: 20.0\n",
      "f888: 10.0\n",
      "f889: 3.0\n",
      "f901: 8.0\n",
      "f902: 4.0\n",
      "f909: 17.0\n",
      "f910: 22.0\n",
      "f926: 3.0\n",
      "f936: 38.0\n",
      "f938: 13.0\n",
      "f944: 6.0\n",
      "f951: 5.0\n",
      "f952: 5.0\n",
      "f953: 1.0\n",
      "f1009: 30.0\n",
      "f1018: 6.0\n",
      "f1019: 10.0\n",
      "f1024: 8.0\n",
      "f1032: 6.0\n",
      "f1033: 2.0\n",
      "f1035: 1.0\n",
      "f1040: 4.0\n",
      "f1041: 5.0\n",
      "f1048: 15.0\n",
      "f1049: 15.0\n",
      "f1050: 12.0\n",
      "f1051: 27.0\n",
      "f1058: 2.0\n",
      "f1072: 3.0\n",
      "f1074: 5.0\n",
      "f1077: 18.0\n",
      "f1082: 9.0\n",
      "f1089: 2.0\n",
      "f1091: 1.0\n",
      "f1093: 1.0\n",
      "f1096: 40.0\n",
      "f1097: 20.0\n",
      "f1099: 22.0\n",
      "f1104: 21.0\n",
      "f1112: 19.0\n",
      "f1113: 1.0\n",
      "f1115: 21.0\n",
      "f1139: 3.0\n",
      "f1145: 3.0\n",
      "f1162: 37.0\n",
      "f1206: 1.0\n",
      "f1214: 21.0\n",
      "f1215: 2.0\n",
      "f1230: 14.0\n",
      "f1241: 6.0\n",
      "f1266: 3.0\n",
      "f1276: 8.0\n",
      "f1277: 13.0\n",
      "f1284: 2.0\n",
      "f1290: 6.0\n",
      "f1292: 8.0\n",
      "f1293: 1.0\n",
      "f1295: 1.0\n",
      "f1302: 2.0\n",
      "f1307: 8.0\n",
      "f1310: 1.0\n",
      "f1333: 5.0\n",
      "f1342: 2.0\n",
      "f1345: 1.0\n",
      "f1349: 28.0\n",
      "f1350: 6.0\n",
      "f1352: 4.0\n",
      "f1353: 2.0\n",
      "f1357: 1.0\n",
      "f1372: 15.0\n",
      "f1373: 4.0\n",
      "f1402: 1.0\n",
      "f1410: 9.0\n",
      "f1411: 4.0\n",
      "f1416: 5.0\n",
      "f1417: 13.0\n",
      "f1424: 2.0\n",
      "f1426: 7.0\n",
      "f1427: 11.0\n",
      "f1432: 2.0\n",
      "f1433: 6.0\n",
      "f1434: 7.0\n",
      "f1456: 1.0\n",
      "f1457: 1.0\n",
      "f1467: 3.0\n",
      "f1472: 1.0\n",
      "f1482: 2.0\n",
      "f1490: 14.0\n",
      "f1491: 2.0\n",
      "f1498: 19.0\n",
      "f1499: 13.0\n",
      "f1520: 3.0\n",
      "f1521: 7.0\n",
      "f1529: 3.0\n",
      "f1531: 1.0\n",
      "f1551: 6.0\n",
      "f1604: 1.0\n",
      "f1612: 1.0\n",
      "f1615: 1.0\n",
      "f1656: 2.0\n",
      "f1657: 8.0\n",
      "f1669: 31.0\n",
      "f1677: 5.0\n",
      "f1678: 6.0\n",
      "f1684: 57.0\n",
      "f1687: 11.0\n",
      "f1695: 5.0\n",
      "f1697: 2.0\n",
      "f1720: 1.0\n",
      "f1724: 33.0\n",
      "f1731: 11.0\n",
      "f1732: 20.0\n",
      "f1735: 15.0\n",
      "f1740: 4.0\n",
      "f1741: 6.0\n",
      "f1743: 9.0\n",
      "f1749: 19.0\n",
      "f1757: 2.0\n",
      "f1758: 2.0\n",
      "f1795: 1.0\n",
      "f1809: 1.0\n",
      "f1816: 4.0\n",
      "f1817: 1.0\n",
      "f1823: 1.0\n",
      "f1844: 6.0\n",
      "f1847: 2.0\n",
      "f1852: 2.0\n",
      "f1853: 5.0\n",
      "f1869: 10.0\n",
      "f1881: 1.0\n",
      "f1886: 4.0\n",
      "f1910: 1.0\n",
      "f1970: 6.0\n",
      "f1974: 4.0\n",
      "f1983: 4.0\n",
      "f1997: 3.0\n",
      "f1998: 7.0\n",
      "f2001: 4.0\n",
      "f2009: 9.0\n",
      "f2044: 3.0\n",
      "f2048: 165.0\n",
      "f2049: 68.0\n",
      "f2050: 75.0\n",
      "f2051: 15.0\n",
      "f2052: 24.0\n",
      "f2053: 63.0\n",
      "f2054: 70.0\n",
      "f2055: 38.0\n",
      "f2056: 37.0\n",
      "f2057: 4.0\n",
      "f2059: 6.0\n",
      "f2061: 38.0\n",
      "f2062: 1.0\n",
      "f2063: 2.0\n",
      "f2064: 32.0\n",
      "f2065: 5.0\n",
      "f2066: 47.0\n",
      "f2067: 20.0\n",
      "f2068: 3.0\n",
      "f2071: 2.0\n",
      "f2072: 71.0\n",
      "f2073: 38.0\n",
      "f2077: 5.0\n",
      "f2078: 2.0\n",
      "f2080: 9.0\n",
      "f2081: 20.0\n",
      "f2082: 41.0\n",
      "f2083: 2.0\n",
      "f2084: 4.0\n",
      "f2085: 58.0\n",
      "f2087: 31.0\n",
      "f2089: 8.0\n",
      "f2090: 3.0\n",
      "f2091: 36.0\n",
      "f2095: 3.0\n",
      "f2098: 422.0\n",
      "f2099: 707.0\n"
     ]
    }
   ],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24604087691850682 0.0020885194594232226 -0.0801692463669359 0.0007810419505414868 0.0001501192949155606\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"difference_fp\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"GNN FP\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_Km\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate Km\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = np.corrcoef(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson[1,0], MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
