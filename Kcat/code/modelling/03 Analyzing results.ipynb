{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.stats import wilcoxon\n",
    "from plotnine import *\n",
    "\n",
    "datasets_dir = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 7, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"secondary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = pd.read_csv('../../results/Results_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(results_test, aes(x = \"Model\", y=\"Pearson correlation\"))\n",
    "    + geom_point(aes(fill=\"Dataset\"), size=6.5) \n",
    "    + scale_x_discrete(labels= [\"Enzyme\",\"Enzyme\\n+\\nreaction\", \"Enzyme\\n+\\nsubstrate\", \"Enzyme\\n+\\nsubstrate\\n+\\nreaction\", \"Reaction\", \"Substrate\", \"Substrate\\n+\\nreaction\"])\n",
    "    + labs(title=\"Pearson correlation of test set (Kcat)\", x=\"Model\", y=\"Pearson correlation\", fill=\"Dataset\")\n",
    "    + theme_classic(base_size=38)\n",
    "    + theme(figure_size=(20, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(results_test, aes(x = \"Model\", y=\"R^2\"))\n",
    "    + geom_point(aes(fill=\"Dataset\"), size=6.5) \n",
    "    + scale_x_discrete(labels= [\"Enzyme\",\"Enzyme\\n+\\nreaction\", \"Enzyme\\n+\\nsubstrate\", \"Enzyme\\n+\\nsubstrate\\n+\\nreaction\", \"Reaction\", \"Substrate\", \"Substrate\\n+\\nreaction\"])\n",
    "    + labs(title=\"R^2 of test set (Kcat)\", x=\"Model\", y=\"R^2\", fill=\"Dataset\")\n",
    "    + theme_classic(base_size=38)\n",
    "    + theme(figure_size=(20, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_val = pd.read_csv('../../results/Results_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(results_val, aes(x = \"Model\", y=\"MAE\"))\n",
    "    + geom_point(aes(fill=\"Dataset\"), size=6.5) \n",
    "    + scale_x_discrete(labels= [\"Enzyme\",\"Enzyme\\n+\\nreaction\", \"Enzyme\\n+\\nsubstrate\", \"Enzyme\\n+\\nsubstrate\\n+\\nreaction\", \"Reaction\", \"Substrate\", \"Substrate\\n+\\nreaction\"])\n",
    "    + labs(title=\"Mean Absolute Error of glucosinolates set (Kcat)\", x=\"Model\", y=\"Mean absolute error\", fill=\"Dataset\")\n",
    "    + theme_classic(base_size=38)\n",
    "    + theme(figure_size=(20, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(results_val, aes(x = \"Model\", y=\"MedAE\"))\n",
    "    + geom_point(aes(fill=\"Dataset\"), size=6.5) \n",
    "    + scale_x_discrete(labels= [\"Enzyme\",\"Enzyme\\n+\\nreaction\", \"Enzyme\\n+\\nsubstrate\", \"Enzyme\\n+\\nsubstrate\\n+\\nreaction\", \"Reaction\", \"Substrate\", \"Substrate\\n+\\nreaction\"])\n",
    "    + labs(title=\"Median Absolute Error of glucosinolates set (Kcat)\", x=\"Model\", y=\"Median absolute error\", fill=\"Dataset\")\n",
    "    + theme_classic(base_size=38)\n",
    "    + theme(figure_size=(20, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\data\\\\secondary\\\\y_val_pred_xgboost_ESM2_gnn_fp.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12760\\1430126167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_val_pred_xgboost_ESM2_gnn_fp.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvaly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_test_true_xgboost_ESM2_gnn_fp.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mesm2_gnn_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_test_pred_xgboost_ESM2_diff_fp.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\..\\\\data\\\\secondary\\\\y_val_pred_xgboost_ESM2_gnn_fp.npy'"
     ]
    }
   ],
   "source": [
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_val_pred_xgboost_ESM2_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_gnn_fp.npy\"))\n",
    "esm2_gnn_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_diff_fp.npy\"))\n",
    "esm2_diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_gnn_fp_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_gnn_fp_diff_fp.npy\"))\n",
    "esm2_gnn_fp_diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2.npy\"))\n",
    "esm2 = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_gnn_fp.npy\"))\n",
    "gnn_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp.npy\"))\n",
    "diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_diff_fp_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp_gnn_fp.npy\"))\n",
    "diff_fp_gnn_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_baseline.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp.npy\"))\n",
    "baseline = abs(10**pred_y-10**test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between predictions with enzyme+reaction and enzyme+substrate 0.53125\n",
      "Difference between predictions with enzyme+reaction and enzyme+substrate+reaction 0.2890625 10.0\n",
      "Difference between predictions with enzyme+reaction and enzyme 0.2890625 10.0\n",
      "Difference between predictions with enzyme+reaction and substrate 0.7109375\n",
      "Difference between predictions with enzyme+reaction and reaction 0.1875\n",
      "Difference between predictions with enzyme+reaction and reaction+substrate 0.65625\n"
     ]
    }
   ],
   "source": [
    "d = esm2_diff_fp - esm2_gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme+substrate\", p)\n",
    "\n",
    "d = esm2_diff_fp - esm2_gnn_fp_diff_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme+substrate+reaction\", p)\n",
    "\n",
    "d = esm2_diff_fp - esm2\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme\", p)\n",
    "\n",
    "d = esm2_diff_fp - gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and substrate\", p)\n",
    "\n",
    "d = esm2_diff_fp - diff_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and reaction\", p)\n",
    "\n",
    "d = esm2_diff_fp - diff_fp_gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and reaction+substrate\", p)\n",
    "\n",
    "\n",
    "d = esm2_diff_fp - baseline\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and baseline\", w, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_identity_ignore_gaps(seq1, seq2):\n",
    "#     identical_residues = sum([1 for x, y in zip(seq1, seq2) if x == y and x != \"-\"])\n",
    "#     pid = identical_residues / sum([1 for x in seq1 if x != \"-\"]) \n",
    "#     return pid\n",
    "\n",
    "# from Bio import Align\n",
    "# from Bio.Align import substitution_matrices\n",
    "\n",
    "# data_val[\"max_identity\"] = np.nan\n",
    "\n",
    "# aligner=Align.PairwiseAligner()\n",
    "# aligner.substitution_matrix = substitution_matrices.load(\"BLOSUM62\")\n",
    "# aligner.mode = \"global\"\n",
    "# aligner.extend_gap_score = -0.5\n",
    "# aligner.open_gap_score = -10\n",
    "\n",
    "# for i in data_val.index:\n",
    "#     identities = []\n",
    "#     for j in data_combined.index:\n",
    "#         seq1 = str(data_val[\"Sequence\"][i])\n",
    "#         seq2 = str(data_combined[\"Sequence\"][j])\n",
    "#         if 'U' in seq1:\n",
    "#             seq1 = seq1.replace('U', 'C')\n",
    "#         if 'U' in seq2:\n",
    "#             seq2 = seq2.replace('U', 'C')\n",
    "#         alignments = aligner.align(seq1, seq2)\n",
    "#         identities.append(calculate_identity_ignore_gaps(alignments[0][0], alignments[0][1]))\n",
    "#     data_val[\"max_identity\"][i] = max(identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_val[\"max_identity\"] = data_val[\"max_identity\"]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import sklearn.metrics as sk\n",
    "# import math\n",
    "\n",
    "# fig, ax = plt.subplots(figsize= (10,8))\n",
    "# plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "# splits = [\"0-40%\", \"40-80%\", \"80-99%\"]\n",
    "# lower_bounds = [0,40,80]\n",
    "# upper_bounds = [40,80,99]\n",
    "\n",
    "# points1 = []\n",
    "# points2 = []\n",
    "# n_points1, n_points2 = [], []\n",
    "\n",
    "# for i, split in enumerate(splits):\n",
    "\n",
    "#     lb, ub = lower_bounds[i], upper_bounds[i]\n",
    "    \n",
    "#     help_df = data_val.loc[data_val[\"max_identity\"]>= lb].loc[data_val[\"max_identity\"]<= ub]\n",
    "#     y_true = np.array([10**x for x in help_df[\"log10_kcat\"]])\n",
    "#     y_pred = np.array([10**x for x in help_df[\"Estimate kcat\"]])\n",
    "#     n_kcat = len(y_pred)\n",
    "#     R2 =  sk.r2_score(y_true, y_pred)\n",
    "#     abs_error = abs(y_true - y_pred)\n",
    "#     rmse = math.sqrt(np.mean(abs(y_true - y_pred)**2))\n",
    "#     print(len(y_true))\n",
    "#     print(split, R2, rmse)\n",
    "#     points1.append(R2)\n",
    "#     points2.append(rmse)\n",
    "#     n_points1.append(n_kcat)\n",
    "\n",
    "\n",
    "# ticks2 = np.array(range(len(splits)))\n",
    "# labs = splits\n",
    "# ax.set_xticks(ticks2)\n",
    "# ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "# ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# # plt.ylim((-0.1,2.5))\n",
    "# # plt.xlim((-0.2, 3.2))\n",
    "# plt.legend(loc = \"lower right\", fontsize=20)\n",
    "# plt.ylabel('RMSE')\n",
    "# plt.xlabel('Enzyme sequence identity')\n",
    "# # ax.yaxis.set_label_coords(-0.15, 0.5)\n",
    "# # ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "# plt.plot([-0.15,4], [0,0], color='grey', linestyle='dashed')\n",
    "\n",
    "\n",
    "# plt.plot([0,1,2], points2, c= \"black\", linewidth=2)\n",
    "\n",
    "# for i, split in enumerate(splits):\n",
    "#     points1.append(R2)\n",
    "    \n",
    "#     if i ==0:\n",
    "#         plt.scatter(i, points2[i], c='black', marker=\"o\", linewidths= 8)\n",
    "#         ax.annotate(n_points1[i], (i-0.08, points2[i]+0.08), fontsize=17, c= \"red\", weight = \"bold\")\n",
    "\n",
    "#     else:\n",
    "#         plt.scatter(i, points2[i], c='black', marker=\"o\", linewidths= 8)\n",
    "#         ax.annotate(n_points1[i], (i-0.08, points2[i]+0.08), fontsize=17, c= \"red\", weight = \"bold\")\n",
    "            \n",
    "     \n",
    "# plt.savefig(join(\"..\",\"..\", \"data\", \"sequence_identity.png\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC_kcat_pred =[[] for _ in range(6)]\n",
    "# EC_kcat =[[] for _ in range(6)]\n",
    "# for ind in data_val.index:\n",
    "#     try:\n",
    "#         EC = int(data_val[\"ECs\"][ind][0][0])\n",
    "#         EC_kcat[EC-1].append(data_val[\"log10_kcat\"][ind])\n",
    "#         EC_kcat_pred[EC-1].append(data_val[\"Estimate kcat\"][ind])\n",
    "#     except IndexError:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize= (8,8))\n",
    "# plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "# classes = [str(i) for i in range(1,7)]\n",
    "\n",
    "# for i in range(len(EC_kcat)):\n",
    "    \n",
    "#     circle = plt.Circle((np.mean(EC_kcat[i]), np.mean(EC_kcat_pred[i]) ),\n",
    "#                         np.sqrt(len(EC_kcat_pred[i]))/300, color='navy', fill = True)\n",
    "#     ax.add_artist(circle)\n",
    "#     if i ==5:\n",
    "#         ax.annotate(\"EC\"+ str(i+1), (np.mean(EC_kcat[i])+0.01, np.mean(EC_kcat_pred[i])-0.05), fontsize=17, c='red', weight = \"bold\")\n",
    "#     else:\n",
    "#         ax.annotate(\"EC\"+ str(i+1), (np.mean(EC_kcat[i])+0.03, np.mean(EC_kcat_pred[i])-0.01), fontsize=17, c='red', weight = \"bold\")\n",
    "    \n",
    "\n",
    "# ticks2 = [0.2, 0.6,1,1.4,1.8]\n",
    "# labs = ticks2\n",
    "# ax.set_xticks(ticks2)\n",
    "# ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "# ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# ax.set_yticks(ticks2)\n",
    "# ax.set_yticklabels(labs,  y= -0.03, fontsize=26)\n",
    "# ax.tick_params(axis='y', length=0, rotation = 0)\n",
    "\n",
    "# plt.ylim((0,2))\n",
    "# plt.xlim((0, 2))\n",
    "# plt.legend(loc = \"upper left\", fontsize=20)\n",
    "# plt.xlabel('mean measured \\n $k_{cat}$ value on $\\log_{10}$-scale')\n",
    "# plt.ylabel('mean predicted \\n $k_{cat}$ value on $\\log_{10}$-scale')\n",
    "# ax.yaxis.set_label_coords(-0.15, 0.5)\n",
    "# ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "# plt.plot([0,2], [0,2], color='grey', alpha = 0.3, linestyle='dashed')\n",
    "# plt.savefig(join(\"..\", \"..\", \"results\", split, \"EC_classes_mean_kcat.png\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "\n",
    "# train_fps = [data_combined[\"difference_fp\"][ind][:3276].reshape(1,-1).astype(int) for ind in data_combined.index]\n",
    "# test_fps = [data_val[\"difference_fp\"][ind][:3276].reshape(1,-1).astype(int) for ind in data_val.index]\n",
    "\n",
    "# max_sim = []\n",
    "\n",
    "# for fp in test_fps:\n",
    "#     jaccard_sim = np.array([1 - scipy.spatial.distance.cdist(fp,train_fp, metric='jaccard')[0][0] for train_fp in train_fps])\n",
    "#     max_sim.append(np.max(jaccard_sim))\n",
    "    \n",
    "# data_val[\"reaction_sim\"] = max_sim\n",
    "\n",
    "# data_val[\"reaction_sim\"]= (data_val[\"reaction_sim\"] - np.min(data_val[\"reaction_sim\"]))\n",
    "# data_val[\"reaction_sim\"] = data_val[\"reaction_sim\"]\\np.max(data_val[\"reaction_sim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fps = [np.array(list(data_combined[\"MACCS FP\"][ind])).reshape(1,-1) for ind in data_combined.index]\n",
    "# test_fps = [np.array(list(data_val[\"MACCS FP\"][ind])).reshape(1,-1) for ind in data_val.index]\n",
    "\n",
    "# max_sim = []\n",
    "\n",
    "# for fp in test_fps:\n",
    "#     jaccard_sim = np.array([1 - scipy.spatial.distance.cdist(fp,train_fp, metric='jaccard')[0][0] for train_fp in train_fps])\n",
    "#     max_sim.append(np.max(jaccard_sim))\n",
    "    \n",
    "# data_val[\"substrate_sim\"] = max_sim\n",
    "\n",
    "# data_val[\"substrate_sim\"]= (data_val[\"substrate_sim\"] - np.min(data_val[\"substrate_sim\"]))\n",
    "# data_val[\"substrate_sim\"] = data_val[\"substrate_sim\"]\\np.max(data_val[\"substrate_sim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_val[\"global_sim\"] = (data_val[\"max_identity\"]/100)*data_val[\"reaction_sim\"]*data_val[\"substrate_sim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# import scipy as sci\n",
    "# help_df = data_val\n",
    "\n",
    "# sim_bins_lb = [0.0, 0.4, 0.8]\n",
    "# sim_bins_ub = [0.4, 0.8, 1]\n",
    "# r2_scores, n_points, pearson_r, rmse = [], [], [], []\n",
    "# for i in range(len(sim_bins_lb)):\n",
    "#     help_df2 = help_df.loc[help_df[\"global_sim\"] <= sim_bins_ub[i]].loc[help_df[\"global_sim\"] >= sim_bins_lb[i]]\n",
    "#     pred = np.array([10**x for x in help_df2[\"log10_kcat\"]])\n",
    "#     true = np.array([10**x for x in help_df2[\"Estimate kcat\"]])\n",
    "#     r2_scores.append(sk.r2_score(true, pred))\n",
    "#     pearson_r.append(sci.stats.pearsonr(true, pred)[0])\n",
    "#     rmse.append(math.sqrt(np.mean(abs(true - pred)**2)))\n",
    "#     n_points.append(len(pred))\n",
    "#     print(\"%s - %s\" % (sim_bins_lb[i], sim_bins_ub[i]), r2_scores[-1], pearson_r[-1], rmse[-1], len(pred))\n",
    "    \n",
    "\n",
    "# plt.rcParams.update({'font.size': 24})\n",
    "\n",
    "# fig, ax = plt.subplots(figsize= (8,6))\n",
    "\n",
    "# for i in range(len(sim_bins_lb)):    \n",
    "#     plt.scatter(i, rmse[i], c='navy', marker=\"o\", linewidths= 8)\n",
    "#     ax.annotate(n_points[i], (i-0.08, rmse[i]+0.05), fontsize=17, c= \"black\", weight = \"bold\")\n",
    "\n",
    "    \n",
    "# plt.xlabel('Reaction similarity score')\n",
    "# plt.ylabel('RMSE')\n",
    "# ax.yaxis.set_label_coords(-0.2, 0.5)\n",
    "# ax.xaxis.set_label_coords(0.5,-0.23)\n",
    "\n",
    "# ticks2 = np.array(range(len(sim_bins_lb)))\n",
    "# labs = [\"%s - %s\" % (sim_bins_lb[i], sim_bins_ub[i]) for i in range(len(sim_bins_lb))]\n",
    "# ax.set_xticks(ticks2)\n",
    "# ax.set_xticklabels(labs,  y= -0.03, fontsize=20)\n",
    "# ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# # plt.ylim((0.5,2))\n",
    "# #plt.xlim((-0.5, 3.2))\n",
    "\n",
    "# # plt.plot([-0.49, 4], [0,0], color='grey', linestyle='dashed')\n",
    "# #plt.savefig(join(\"..\",\"..\", \"data\", \"figures\", \"Reaction_Similarity_Score.eps\"))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
