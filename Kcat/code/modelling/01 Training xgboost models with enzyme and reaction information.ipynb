{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, rand, hp, Trials,tpe\n",
    "# rstate = np.random.default_rng(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib as mpl\n",
    "\n",
    "datasets_dir = \"../../data\"\n",
    "# plt.style.use('CCB_plot_style_0v4.mplstyle')\n",
    "# c_styles      = mpl.rcParams['axes.prop_cycle'].by_key()['color']   # fetch the defined color styles\n",
    "# high_contrast = ['#004488', '#DDAA33', '#BB5566', '#000000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 41, 7)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"secondary\"\n",
    "\n",
    "data_train = pd.read_pickle(join(datasets_dir, \"splits\", split, \"training_data.pkl\"))\n",
    "data_test = pd.read_pickle(join(datasets_dir, \"splits\", split, \"test_data.pkl\"))\n",
    "data_val = pd.read_pickle(join(datasets_dir, \"splits\", split, \"val_data.pkl\"))\n",
    "\n",
    "# data_train[\"geomean_kcat\"] = np.log10(data_train[\"geomean_kcat\"])\n",
    "# data_test[\"geomean_kcat\"] = np.log10(data_test[\"geomean_kcat\"])\n",
    "\n",
    "data_train[\"log10_kcat\"] = np.log10(data_train[\"kcat\"])\n",
    "data_test[\"log10_kcat\"] = np.log10(data_test[\"kcat\"])\n",
    "data_val[\"log10_kcat\"] = np.log10(data_val[\"kcat\"])\n",
    "\n",
    "data_train.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_test.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_val.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "\n",
    "data_train['Temperature'] = data_train['Temperature'].replace('-', np.nan)\n",
    "data_test['Temperature'] = data_test['Temperature'].replace('-', np.nan)\n",
    "data_val['Temperature'] = data_val['Temperature'].replace('-', np.nan)\n",
    "data_train['pH'] = data_train['pH'].replace('-', np.nan)\n",
    "data_test['pH'] = data_test['pH'].replace('-', np.nan)\n",
    "data_val['pH'] = data_val['pH'].replace('-', np.nan)\n",
    "data_train['Type'] = data_train['Type'].replace('wildtype', 1)\n",
    "data_train['Type'] = data_train['Type'].replace('mutant', 2)\n",
    "data_test['Type'] = data_test['Type'].replace('wildtype', 1)\n",
    "data_test['Type'] = data_test['Type'].replace('mutant', 2)\n",
    "data_val['Type'] = data_val['Type'].replace('wildtype', 1)\n",
    "data_val['Type'] = data_val['Type'].replace('mutant', 2)\n",
    "\n",
    "data_train['MACCS FP'] = data_train['MACCS FP'].astype(str)\n",
    "data_test['MACCS FP'] = data_test['MACCS FP'].astype(str)\n",
    "data_val['MACCS FP'] = data_val['MACCS FP'].astype(str)\n",
    "\n",
    "len(data_train), len(data_test), len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_train_indices_Seed plants.npy\"), allow_pickle = True))\n",
    "test_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_test_indices_Seed plants.npy\"), allow_pickle = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[~data_test['GNN FP'].isnull()]\n",
    "\n",
    "nan_rows = data_train[data_train['GNN FP'].apply(lambda x: not isinstance(x, np.ndarray))]\n",
    "\n",
    "# Get the indices of these rows\n",
    "indices_with_nan = nan_rows.index.tolist()\n",
    "indices_with_nan.reverse()\n",
    "\n",
    "for ind, sub_list in enumerate(train_indices):\n",
    "    for elem in sub_list:\n",
    "        if elem in indices_with_nan:\n",
    "            sub_list.remove(elem)\n",
    "\n",
    "for ind, sub_list in enumerate(train_indices):\n",
    "    for num in indices_with_nan:\n",
    "        train_indices[ind] = [elem - 1 if elem > num else elem for elem in sub_list]\n",
    "\n",
    "removed = {}\n",
    "\n",
    "for ind, sub_list in enumerate(test_indices):\n",
    "    for elem in sub_list:\n",
    "        if elem in indices_with_nan:\n",
    "            sub_list.remove(elem)\n",
    "\n",
    "for ind, sub_list in enumerate(test_indices):\n",
    "    for num in indices_with_nan:\n",
    "        test_indices[ind] = [elem - 1 if elem > num else elem for elem in sub_list]      \n",
    "\n",
    "\n",
    "data_train = data_train[data_train['GNN FP'].apply(lambda x: isinstance(x, np.ndarray))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training a model with enzyme and substrate information (ESM-2/MACCS) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:38<00:00, 15.84s/trial, best loss: -0.2838098859786674]\n"
     ]
    }
   ],
   "source": [
    "def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    # param[\"device\"] = \"cuda\"\n",
    "    param[\"tree_method\"] = \"hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "    #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "    \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "    \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "    \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "    \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=tpe.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 3, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 2, 'num_rounds': 3, 'reg_alpha': 5, 'reg_lambda': 3}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full dataset : {'learning_rate': 0.1, 'max_delta_step': 4, 'max_depth': 5, 'min_child_weight': 2, 'num_rounds': 50, 'reg_alpha': 0.2, 'reg_lambda': 0.7}\n",
    "arabidopsis : {'learning_rate': 0.04, 'max_delta_step': 3, 'max_depth': 4, 'min_child_weight': 6, 'num_rounds': 150, 'reg_alpha': 0.6, 'reg_lambda': 0.6}\n",
    "brassicaceae: {'learning_rate': 0.05, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 2, 'num_rounds': 150, 'reg_alpha': 0.7, 'reg_lambda': 1}\n",
    "wildtype: {'learning_rate': 0.02, 'max_delta_step': 1, 'max_depth': 3, 'min_child_weight': 5, 'num_rounds': 150, 'reg_alpha': 0, 'reg_lambda': 0.2}\n",
    "secondary :  {'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 6, 'min_child_weight': 3, 'num_rounds': 200, 'reg_alpha': 0.5, 'reg_lambda': 0.3}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 6, 'min_child_weight': 3, 'num_rounds': 200, 'reg_alpha': 0.5, 'reg_lambda': 0.3}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9549682730098475, 0.8665204290191941, -0.0004793815576467353, 0.22187936914288434, 0.10937408040903962]\n",
      "[296.34664442322253, 210.70731390292693, 38.820949388225905, 456.26849387471776, 264.90013002062676]\n",
      "[0.3048510355181896, 0.3078385472272138, -0.08342153215147974, -0.08489093698589922, -0.39337097568335566]\n",
      "[110.09616139688562, 48.935431621255525, 13.626220331125737, 157.2264987742258, 104.03896373893444]\n",
      "[2.7796247548855213, 2.3373559963537036, 3.1907352723147993, 5.11487668278909, 9.161913214330005]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.276 7.5607783744 -0.05 4.0788607804 1.8155674102\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "# MedAE = np.median(abs(np.array(test_Y) - np.array(y_test_pred)))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9632730548484367, 7.069402835994646e-24) 2.349353823456906 0.8986050755958163\n"
     ]
    }
   ],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 6, 'min_child_weight': 3, 'num_rounds': 200, 'reg_alpha': 0.5, 'reg_lambda': 0.3}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"GNN FP\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_kcat\"]))\n",
    "\n",
    "val_X = val_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.020936658220535087, 0.9644646146424217) 4.739643691233274 -0.21675115092024488 3.8262573668453994 2.2965234484510084\n"
     ]
    }
   ],
   "source": [
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a model with enzyme and reaction information (ESM-2/diff_fp) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:25<00:00, 38.51s/trial, best loss: -0.25442200327097875]\n"
     ]
    }
   ],
   "source": [
    "def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    # param[\"device\"] = \"cuda\"\n",
    "    param[\"tree_method\"] = \"hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "    #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "    \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "    \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "    \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "    \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 3, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 5, 'num_rounds': 0, 'reg_alpha': 8, 'reg_lambda': 10}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full dataset : {'learning_rate': 0.08, 'max_delta_step': 3, 'max_depth': 5, 'min_child_weight': 2, 'num_rounds': 100, 'reg_alpha': 0.4, 'reg_lambda': 0.5}\n",
    "arabidopsis : {'learning_rate': 0.07, 'max_delta_step': 1, 'max_depth': 6, 'min_child_weight': 4, 'num_rounds': 200, 'reg_alpha': 0.2, 'reg_lambda': 0.3}\n",
    "brassicaceae: {'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 4, 'min_child_weight': 1, 'num_rounds': 150, 'reg_alpha': 0.7, 'reg_lambda': 0.3}\n",
    "wildtype : {'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 5, 'min_child_weight': 1, 'num_rounds': 100, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
    "secondary : {'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 10, 'min_child_weight': 6, 'num_rounds': 50, 'reg_alpha': 0.8, 'reg_lambda': 1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 10, 'min_child_weight': 6, 'num_rounds': 50, 'reg_alpha': 0.8, 'reg_lambda': 1}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.289 7.4535830029 -0.021 3.8798632011 1.51693407\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8508432729662725, 1.8602184364322034e-12) 4.831085600224142 0.5712453687235945\n"
     ]
    }
   ],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 10, 'min_child_weight': 6, 'num_rounds': 50, 'reg_alpha': 0.8, 'reg_lambda': 1}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"difference_fp\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_kcat\"]))\n",
    "\n",
    "val_X = val_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.17661330571408634, 0.7048261364345066) 4.911656389613935 -0.3066712351334755 4.202070930470204 4.11909089299639\n"
     ]
    }
   ],
   "source": [
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a model with enzyme, substrate (MACCS fp) and reaction information (ESM-2/diff_fp) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:04<00:00, 60.44s/trial, best loss: -0.2754425240015691]\n"
     ]
    }
   ],
   "source": [
    "def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    # param[\"device\"] = \"cuda\"\n",
    "    param[\"tree_method\"] = \"hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "    #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "    \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "    \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "    \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "    \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 2, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 5, 'num_rounds': 2, 'reg_alpha': 2, 'reg_lambda': 4}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full dataset : {'learning_rate': 0.06, 'max_delta_step': 1, 'max_depth': 6, 'min_child_weight': 3, 'num_rounds': 200, 'reg_alpha': 1, 'reg_lambda': 0.7}\n",
    "arabidopsis : {'learning_rate': 0.1, 'max_delta_step': 4, 'max_depth': 3, 'min_child_weight': 5, 'num_rounds': 150, 'reg_alpha': 0.5, 'reg_lambda': 0.8}\n",
    "brassicaceae : {'learning_rate': 0.07, 'max_delta_step': 1, 'max_depth': 3, 'min_child_weight': 5, 'num_rounds': 100, 'reg_alpha': 0.6, 'reg_lambda': 0.5}\n",
    "wildtype : {'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 5, 'num_rounds': 100, 'reg_alpha': 0.5, 'reg_lambda': 0.4}\n",
    "secondary: {'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 7, 'min_child_weight': 6, 'num_rounds': 150, 'reg_alpha': 0.2, 'reg_lambda': 0.4}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 7, 'min_child_weight': 6, 'num_rounds': 150, 'reg_alpha': 0.2, 'reg_lambda': 0.4}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "    MedAE.append(np.median(abs(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred]))))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.276 7.5374599199 -0.044 4.0228655844 1.7430006546\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"difference_fp\"])), np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"difference_fp\"])), np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9423876118246268, 3.807843097539318e-20) 3.0306484173186985 0.8312707122440833\n"
     ]
    }
   ],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 7, 'min_child_weight': 6, 'num_rounds': 150, 'reg_alpha': 0.2, 'reg_lambda': 0.4}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = bst.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"difference_fp\"])), np.array(list(data_val[\"GNN FP\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_kcat\"]))\n",
    "\n",
    "val_X = val_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.06843302369950485, 0.8840963290779402) 4.784775973130257 -0.2400340037120734 3.867034784726086 2.2903475639917956\n"
     ]
    }
   ],
   "source": [
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val[\"Estimate kcat\"] = y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "plt.scatter(val_Y,y_val_pred,c='blue', edgecolors='black',s=15)\n",
    "    \n",
    "plt.xlim(-4,4)\n",
    "plt.ylim(-4,4)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Real value', fontsize=15)\n",
    "plt.ylabel('Estimated value', fontsize=15)\n",
    "plt.title('Predictions', fontsize=15)\n",
    "plt.axline((1, 1), slope=1, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(val_Y, np.zeros_like(val_Y), c='blue', edgecolors='black',s=15)\n",
    "plt.scatter(np.mean(val_Y), 0, c='red', edgecolors='black',s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = bst.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"difference_fp\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([10**x for x in data_combined[\"log10_kcat\"]], bins=50, color='skyblue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([10**x for x in data_val[\"log10_kcat\"]], bins=50, color='skyblue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.concat([data_train, data_test],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_identity_ignore_gaps(seq1, seq2):\n",
    "    identical_residues = sum([1 for x, y in zip(seq1, seq2) if x == y and x != \"-\"])\n",
    "    pid = identical_residues / sum([1 for x in seq1 if x != \"-\"]) \n",
    "    return pid\n",
    "\n",
    "from Bio import Align\n",
    "from Bio.Align import substitution_matrices\n",
    "\n",
    "data_val[\"max_identity\"] = np.nan\n",
    "\n",
    "aligner=Align.PairwiseAligner()\n",
    "aligner.substitution_matrix = substitution_matrices.load(\"BLOSUM62\")\n",
    "aligner.mode = \"global\"\n",
    "aligner.extend_gap_score = -0.5\n",
    "aligner.open_gap_score = -10\n",
    "\n",
    "for i in data_val.index:\n",
    "    identities = []\n",
    "    for j in data_combined.index:\n",
    "        seq1 = str(data_val[\"Sequence\"][i])\n",
    "        seq2 = str(data_combined[\"Sequence\"][j])\n",
    "        if 'U' in seq1:\n",
    "            seq1 = seq1.replace('U', 'C')\n",
    "        if 'U' in seq2:\n",
    "            seq2 = seq2.replace('U', 'C')\n",
    "        alignments = aligner.align(seq1, seq2)\n",
    "        identities.append(calculate_identity_ignore_gaps(alignments[0][0], alignments[0][1]))\n",
    "    data_val[\"max_identity\"][i] = max(identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val[\"max_identity\"] = data_val[\"max_identity\"]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as sk\n",
    "import math\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (10,8))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "splits = [\"0-40%\", \"40-80%\", \"80-99%\"]\n",
    "lower_bounds = [0,40,80]\n",
    "upper_bounds = [40,80,99]\n",
    "\n",
    "points1 = []\n",
    "points2 = []\n",
    "n_points1, n_points2 = [], []\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "\n",
    "    lb, ub = lower_bounds[i], upper_bounds[i]\n",
    "    \n",
    "    help_df = data_val.loc[data_val[\"max_identity\"]>= lb].loc[data_val[\"max_identity\"]<= ub]\n",
    "    y_true = np.array([10**x for x in help_df[\"log10_kcat\"]])\n",
    "    y_pred = np.array([10**x for x in help_df[\"Estimate kcat\"]])\n",
    "    n_kcat = len(y_pred)\n",
    "    R2 =  sk.r2_score(y_true, y_pred)\n",
    "    abs_error = abs(y_true - y_pred)\n",
    "    rmse = math.sqrt(np.mean(abs(y_true - y_pred)**2))\n",
    "    print(len(y_true))\n",
    "    print(split, R2, rmse)\n",
    "    points1.append(R2)\n",
    "    points2.append(rmse)\n",
    "    n_points1.append(n_kcat)\n",
    "\n",
    "\n",
    "ticks2 = np.array(range(len(splits)))\n",
    "labs = splits\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# plt.ylim((-0.1,2.5))\n",
    "# plt.xlim((-0.2, 3.2))\n",
    "plt.legend(loc = \"lower right\", fontsize=20)\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Enzyme sequence identity')\n",
    "# ax.yaxis.set_label_coords(-0.15, 0.5)\n",
    "# ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "plt.plot([-0.15,4], [0,0], color='grey', linestyle='dashed')\n",
    "\n",
    "\n",
    "plt.plot([0,1,2], points2, c= \"black\", linewidth=2)\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    points1.append(R2)\n",
    "    \n",
    "    if i ==0:\n",
    "        plt.scatter(i, points2[i], c='black', marker=\"o\", linewidths= 8)\n",
    "        ax.annotate(n_points1[i], (i-0.08, points2[i]+0.08), fontsize=17, c= \"red\", weight = \"bold\")\n",
    "\n",
    "    else:\n",
    "        plt.scatter(i, points2[i], c='black', marker=\"o\", linewidths= 8)\n",
    "        ax.annotate(n_points1[i], (i-0.08, points2[i]+0.08), fontsize=17, c= \"red\", weight = \"bold\")\n",
    "            \n",
    "     \n",
    "plt.savefig(join(\"..\",\"..\", \"data\", \"sequence_identity.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_kcat_pred =[[] for _ in range(6)]\n",
    "EC_kcat =[[] for _ in range(6)]\n",
    "for ind in data_val.index:\n",
    "    try:\n",
    "        EC = int(data_val[\"ECs\"][ind][0][0])\n",
    "        EC_kcat[EC-1].append(data_val[\"log10_kcat\"][ind])\n",
    "        EC_kcat_pred[EC-1].append(data_val[\"Estimate kcat\"][ind])\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (8,8))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "classes = [str(i) for i in range(1,7)]\n",
    "\n",
    "for i in range(len(EC_kcat)):\n",
    "    \n",
    "    circle = plt.Circle((np.mean(EC_kcat[i]), np.mean(EC_kcat_pred[i]) ),\n",
    "                        np.sqrt(len(EC_kcat_pred[i]))/300, color='navy', fill = True)\n",
    "    ax.add_artist(circle)\n",
    "    if i ==5:\n",
    "        ax.annotate(\"EC\"+ str(i+1), (np.mean(EC_kcat[i])+0.01, np.mean(EC_kcat_pred[i])-0.05), fontsize=17, c='red', weight = \"bold\")\n",
    "    else:\n",
    "        ax.annotate(\"EC\"+ str(i+1), (np.mean(EC_kcat[i])+0.03, np.mean(EC_kcat_pred[i])-0.01), fontsize=17, c='red', weight = \"bold\")\n",
    "    \n",
    "\n",
    "ticks2 = [0.2, 0.6,1,1.4,1.8]\n",
    "labs = ticks2\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "ax.set_yticks(ticks2)\n",
    "ax.set_yticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='y', length=0, rotation = 0)\n",
    "\n",
    "plt.ylim((0,2))\n",
    "plt.xlim((0, 2))\n",
    "plt.legend(loc = \"upper left\", fontsize=20)\n",
    "plt.xlabel('mean measured \\n $k_{cat}$ value on $\\log_{10}$-scale')\n",
    "plt.ylabel('mean predicted \\n $k_{cat}$ value on $\\log_{10}$-scale')\n",
    "ax.yaxis.set_label_coords(-0.15, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "plt.plot([0,2], [0,2], color='grey', alpha = 0.3, linestyle='dashed')\n",
    "plt.savefig(join(\"..\", \"..\", \"data\", \"EC_classes_mean_kcat.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "train_fps = [data_combined[\"difference_fp\"][ind][:3276].reshape(1,-1).astype(int) for ind in data_combined.index]\n",
    "test_fps = [data_val[\"difference_fp\"][ind][:3276].reshape(1,-1).astype(int) for ind in data_val.index]\n",
    "\n",
    "max_sim = []\n",
    "\n",
    "for fp in test_fps:\n",
    "    jaccard_sim = np.array([1 - scipy.spatial.distance.cdist(fp,train_fp, metric='jaccard')[0][0] for train_fp in train_fps])\n",
    "    max_sim.append(np.max(jaccard_sim))\n",
    "    \n",
    "data_val[\"reaction_sim\"] = max_sim\n",
    "\n",
    "data_val[\"reaction_sim\"]= (data_val[\"reaction_sim\"] - np.min(data_val[\"reaction_sim\"]))\n",
    "data_val[\"reaction_sim\"] = data_val[\"reaction_sim\"]/np.max(data_val[\"reaction_sim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fps = [np.array(list(data_combined[\"MACCS FP\"][ind])).reshape(1,-1) for ind in data_combined.index]\n",
    "test_fps = [np.array(list(data_val[\"MACCS FP\"][ind])).reshape(1,-1) for ind in data_val.index]\n",
    "\n",
    "max_sim = []\n",
    "\n",
    "for fp in test_fps:\n",
    "    jaccard_sim = np.array([1 - scipy.spatial.distance.cdist(fp,train_fp, metric='jaccard')[0][0] for train_fp in train_fps])\n",
    "    max_sim.append(np.max(jaccard_sim))\n",
    "    \n",
    "data_val[\"substrate_sim\"] = max_sim\n",
    "\n",
    "data_val[\"substrate_sim\"]= (data_val[\"substrate_sim\"] - np.min(data_val[\"substrate_sim\"]))\n",
    "data_val[\"substrate_sim\"] = data_val[\"substrate_sim\"]/np.max(data_val[\"substrate_sim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val[\"global_sim\"] = (data_val[\"max_identity\"]/100)*data_val[\"reaction_sim\"]*data_val[\"substrate_sim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sci\n",
    "help_df = data_val\n",
    "\n",
    "sim_bins_lb = [0.0, 0.4, 0.8]\n",
    "sim_bins_ub = [0.4, 0.8, 1]\n",
    "r2_scores, n_points, pearson_r, rmse = [], [], [], []\n",
    "for i in range(len(sim_bins_lb)):\n",
    "    help_df2 = help_df.loc[help_df[\"global_sim\"] <= sim_bins_ub[i]].loc[help_df[\"global_sim\"] >= sim_bins_lb[i]]\n",
    "    pred = np.array([10**x for x in help_df2[\"log10_kcat\"]])\n",
    "    true = np.array([10**x for x in help_df2[\"Estimate kcat\"]])\n",
    "    r2_scores.append(sk.r2_score(true, pred))\n",
    "    pearson_r.append(sci.stats.pearsonr(true, pred)[0])\n",
    "    rmse.append(math.sqrt(np.mean(abs(true - pred)**2)))\n",
    "    n_points.append(len(pred))\n",
    "    print(\"%s - %s\" % (sim_bins_lb[i], sim_bins_ub[i]), r2_scores[-1], pearson_r[-1], rmse[-1], len(pred))\n",
    "    \n",
    "\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (8,6))\n",
    "\n",
    "for i in range(len(sim_bins_lb)):    \n",
    "    plt.scatter(i, rmse[i], c='navy', marker=\"o\", linewidths= 8)\n",
    "    ax.annotate(n_points[i], (i-0.08, rmse[i]+0.05), fontsize=17, c= \"black\", weight = \"bold\")\n",
    "\n",
    "    \n",
    "plt.xlabel('Reaction similarity score')\n",
    "plt.ylabel('RMSE')\n",
    "ax.yaxis.set_label_coords(-0.2, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.23)\n",
    "\n",
    "ticks2 = np.array(range(len(sim_bins_lb)))\n",
    "labs = [\"%s - %s\" % (sim_bins_lb[i], sim_bins_ub[i]) for i in range(len(sim_bins_lb))]\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=20)\n",
    "ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "# plt.ylim((0.5,2))\n",
    "#plt.xlim((-0.5, 3.2))\n",
    "\n",
    "# plt.plot([-0.49, 4], [0,0], color='grey', linestyle='dashed')\n",
    "#plt.savefig(join(\"..\",\"..\", \"data\", \"figures\", \"Reaction_Similarity_Score.eps\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training a model with enzyme information (ESM-2) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:29<00:00, 14.92s/trial, best loss: -0.29550576965324]  \n"
     ]
    }
   ],
   "source": [
    "def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    # param[\"device\"] = \"cuda\"\n",
    "    param[\"tree_method\"] = \"hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "    #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "    \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "    \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "    \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "    \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 7, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 3, 'num_rounds': 1, 'reg_alpha': 6, 'reg_lambda': 6}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full dataset: {'learning_rate': 0.09, 'max_delta_step': 1, 'max_depth': 3, 'min_child_weight': 2, 'num_rounds': 200, 'reg_alpha': 0.6, 'reg_lambda': 0.6}\n",
    "arabidopsis : {'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 5, 'min_child_weight': 1, 'num_rounds': 100, 'reg_alpha': 0.5, 'reg_lambda': 0.4}\n",
    "brassicaceae: {'learning_rate': 0.05, 'max_delta_step': 5, 'max_depth': 3, 'min_child_weight': 1, 'num_rounds': 100, 'reg_alpha': 0.3, 'reg_lambda': 0.3}\n",
    "wildtype : {'learning_rate': 0.09, 'max_delta_step': 4, 'max_depth': 4, 'min_child_weight': 1, 'num_rounds': 50, 'reg_alpha': 0.4, 'reg_lambda': 0.1}\n",
    "secondary : {'learning_rate': 0.08, 'max_delta_step': 1, 'max_depth': 5, 'min_child_weight': 4, 'num_rounds': 100, 'reg_alpha': 0.6, 'reg_lambda': 0.6}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 1, 'max_depth': 5, 'min_child_weight': 4, 'num_rounds': 100, 'reg_alpha': 0.6, 'reg_lambda': 0.6}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "    MedAE.append(np.median(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.161 8.0063217023 -0.178 4.1605399766 1.2373718834\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate kcat\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate kcat\"] = [10**x for x in data_test[\"Estimate kcat\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"ESM2\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"ESM2\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8629129476709316, 4.020489233895027e-13) 3.9394831555978342 0.7148995816328725\n"
     ]
    }
   ],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 1, 'max_depth': 5, 'min_child_weight': 4, 'num_rounds': 100, 'reg_alpha': 0.6, 'reg_lambda': 0.6}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.3084717773607397, 0.5008775257058903) 5.05046239132191 -0.3815692552294503 3.9406524724691283 3.9406524724691283\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"ESM2\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_kcat\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate kcat\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a model with main substrate information (MACCS) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train['GNN FP']))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test['GNN FP']))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.36s/trial, best loss: -0.16075486463243954]\n"
     ]
    }
   ],
   "source": [
    "def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    # param[\"device\"] = \"cuda\"\n",
    "    param[\"tree_method\"] = \"hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "    #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "    \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "    \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "    \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "    \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 9, 'max_delta_step': 2, 'max_depth': 5, 'min_child_weight': 1, 'num_rounds': 0, 'reg_alpha': 1, 'reg_lambda': 8}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full dataset: {'learning_rate': 0.06, 'max_delta_step': 4, 'max_depth': 6, 'min_child_weight': 2, 'num_rounds': 100, 'reg_alpha': 0.9, 'reg_lambda': 0.8}\n",
    "arabidopsis : {'learning_rate': 0.02, 'max_delta_step': 1, 'max_depth': 9, 'min_child_weight': 6, 'num_rounds': 100, 'reg_alpha': 0.4, 'reg_lambda': 0.2}\n",
    "brassicaceae: {'learning_rate': 0.08, 'max_delta_step': 4, 'max_depth': 4, 'min_child_weight': 1, 'num_rounds': 100, 'reg_alpha': 0.7, 'reg_lambda': 0.8}\n",
    "wildtype : {'learning_rate': 0.03, 'max_delta_step': 4, 'max_depth': 4, 'min_child_weight': 5, 'num_rounds': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.7}\n",
    "secondary : {'learning_rate': 0.1, 'max_delta_step': 3, 'max_depth': 8, 'min_child_weight': 2, 'num_rounds': 50, 'reg_alpha': 0.1, 'reg_lambda': 0.8}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 3, 'max_depth': 8, 'min_child_weight': 2, 'num_rounds': 50, 'reg_alpha': 0.1, 'reg_lambda': 0.8}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "    MedAE.append(np.median(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.032 8.1993334683 -0.235 4.3414290322 2.4237628991\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate kcat\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate kcat\"] = [10**x for x in data_test[\"Estimate kcat\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"GNN FP\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"GNN FP\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2878006818214538, 0.06805320430618847) 7.315206166848599 0.016957034335548182\n"
     ]
    }
   ],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.1, 'max_delta_step': 3, 'max_depth': 8, 'min_child_weight': 2, 'num_rounds': 50, 'reg_alpha': 0.1, 'reg_lambda': 0.8}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.29890305731279215, 0.5149271386587163) 5.684169302105633 -0.7500255400881854 3.884592884086939 2.4237628991439295\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"GNN FP\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_kcat\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate kcat\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training a model with reaction information (diff-fp) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:54<00:00,  5.48s/trial, best loss: -0.2073035608619033]\n"
     ]
    }
   ],
   "source": [
    "def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    # param[\"device\"] = \"cuda\"\n",
    "    param[\"tree_method\"] = \"hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "    #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "    \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "    \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "    \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "    \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 3, 'max_delta_step': 2, 'max_depth': 4, 'min_child_weight': 4, 'num_rounds': 0, 'reg_alpha': 0, 'reg_lambda': 5}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full dataset : {'learning_rate': 1, 'max_delta_step': 1, 'max_depth': 5, 'min_child_weight': 5, 'num_rounds': 200, 'reg_alpha': 0.8, 'reg_lambda': 0.1}\n",
    "arabidopsis : {'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 3, 'min_child_weight': 4, 'num_rounds': 150, 'reg_alpha': 0.8, 'reg_lambda': 0.3}\n",
    "brassicaceae: {'learning_rate': 0.07, 'max_delta_step': 4, 'max_depth': 3, 'min_child_weight': 2, 'num_rounds': 100, 'reg_alpha': 0.4, 'reg_lambda': 0.8}\n",
    "wildtype : {'learning_rate': 0.03, 'max_delta_step': 2, 'max_depth': 3, 'min_child_weight': 6, 'num_rounds': 100, 'reg_alpha': 0.6, 'reg_lambda': 0.9}\n",
    "secondary: {'learning_rate': 0.04, 'max_delta_step': 3, 'max_depth': 7, 'min_child_weight': 5, 'num_rounds': 50, 'reg_alpha': 0, 'reg_lambda': 0.5}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 3, 'max_depth': 7, 'min_child_weight': 5, 'num_rounds': 50, 'reg_alpha': 0, 'reg_lambda': 0.5}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "    MedAE.append(np.median(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.218 7.5189473237 -0.039 3.7970614583 1.0766219836\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate kcat\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate kcat\"] = [10**x for x in data_test[\"Estimate kcat\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3777400606049306, 0.014896471875306991) 7.101321370000791 0.07360182032129803\n"
     ]
    }
   ],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.04, 'max_delta_step': 3, 'max_depth': 7, 'min_child_weight': 5, 'num_rounds': 50, 'reg_alpha': 0, 'reg_lambda': 0.5}\n",
    "\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.8281260668987445, 0.021393058987110764) 5.240168261583343 -0.4873077534839545 3.79483260380288 3.79483260380288\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"difference_fp\"]))\n",
    "val_X = np.concatenate([val_X, np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_kcat\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate kcat\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training a model with reaction and main substrate information (diff-fp/MACCS) + Temperature + pH:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:17<00:00,  7.79s/trial, best loss: -0.3921343321661367]\n"
     ]
    }
   ],
   "source": [
    "def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    # param[\"device\"] = \"cuda\"\n",
    "    param[\"tree_method\"] = \"hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.choice(\"learning_rate\", np.linspace(0.01, 0.1, 10)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", np.linspace(3,10,8)),\n",
    "    #\"subsample\": hp.quniform(\"subsample\", 0.5, 1),\n",
    "    \"reg_lambda\": hp.choice(\"reg_lambda\", np.linspace(0, 1, 11)),\n",
    "    \"reg_alpha\": hp.choice(\"reg_alpha\", np.linspace(0, 1, 11)),\n",
    "    \"max_delta_step\": hp.choice(\"max_delta_step\", np.linspace(1, 5, 5)),\n",
    "    \"min_child_weight\": hp.choice(\"min_child_weight\", np.linspace(1, 6, 6)),\n",
    "    \"num_rounds\":  hp.choice(\"num_rounds\", np.linspace(50, 200, 4))}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 7, 'max_delta_step': 4, 'max_depth': 7, 'min_child_weight': 2, 'num_rounds': 2, 'reg_alpha': 10, 'reg_lambda': 3}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full dataset : {'learning_rate': 0.08, 'max_delta_step': 2, 'max_depth': 5, 'min_child_weight': 6, 'num_rounds': 200, 'reg_alpha': 0, 'reg_lambda': 0.1}\n",
    "arabidopsis : {'learning_rate': 0.03, 'max_delta_step': 3, 'max_depth': 5, 'min_child_weight': 6, 'num_rounds': 100, 'reg_alpha': 1, 'reg_lambda': 0}\n",
    "brassicaceae: {'learning_rate': 0.04, 'max_delta_step': 1, 'max_depth': 6, 'min_child_weight': 5, 'num_rounds': 150, 'reg_alpha': 0.5, 'reg_lambda': 0.4}\n",
    "wildtype : {'learning_rate': 0.05, 'max_delta_step': 5, 'max_depth': 5, 'min_child_weight': 1, 'num_rounds': 50, 'reg_alpha': 0.9, 'reg_lambda': 0.9}\n",
    "secondary : {'learning_rate': 0.08, 'max_delta_step': 5, 'max_depth': 10, 'min_child_weight': 3, 'num_rounds': 150, 'reg_alpha': 1, 'reg_lambda': 0.3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"random_state\": 42, 'learning_rate': 0.08, 'max_delta_step': 5, 'max_depth': 10, 'min_child_weight': 3, 'num_rounds': 150, 'reg_alpha': 1, 'reg_lambda': 0.3}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "MAE = []\n",
    "MedAE = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(train_Y[test_index], (-1))]) - np.array([10**x for x in y_valid_pred]))**2)))\n",
    "    R2.append(r2_score([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred]))\n",
    "    Pearson.append(stats.pearsonr([10**x for x in np.reshape(train_Y[test_index], (-1))], [10**x for x in y_valid_pred])[0])\n",
    "    MAE.append(np.mean(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "    MedAE.append(np.median(np.array([10**x for x in train_Y[test_index]]) - np.array([10**x for x in y_valid_pred])))\n",
    "\n",
    "    # MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    # R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    # Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "print(MAE)\n",
    "print(MedAE)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.108 7.8031544126 -0.119 4.0597457136 1.3300479813\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "data_test[\"Estimate kcat\"] = y_test_pred\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in test_Y]), np.array([10**x for x in y_test_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "MedAE = np.median(abs(np.array([10**x for x in test_Y]) - np.array([10**x for x in y_test_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# MAE = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred))\n",
    "\n",
    "print(np.round(Pearson[0],3) , np.round(MSE_dif_fp_test, 10), np.round(R2_dif_fp_test,3), np.round(MAE, 10), np.round(MedAE, 10))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ts_drfp = y_test_pred\n",
    "# data_test[\"Estimate kcat\"] = [10**x for x in data_test[\"Estimate kcat\"]]\n",
    "# filtered_df = data_test[data_test['Uniprot IDs'].apply(lambda x: \"Q9LE06\" in x)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"GNN FP\"])), np.array(list(data_train[\"Temperature\"]))[:, np.newaxis], np.array(list(data_train[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X,  np.array(list(data_test[\"GNN FP\"])), np.array(list(data_test[\"Temperature\"]))[:, np.newaxis], np.array(list(data_test[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])\n",
    "\n",
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.42649045556179577, 0.00542589127203545) 6.906658633766827 0.12369489574301618\n"
     ]
    }
   ],
   "source": [
    "param = {\"random_state\": 42,  'learning_rate': 0.08, 'max_delta_step': 5, 'max_depth': 10, 'min_child_weight': 3, 'num_rounds': 150, 'reg_alpha': 1, 'reg_lambda': 0.3}\n",
    "\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "\n",
    "MSE_dif_fp_test = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(test_Y, (-1))]) - np.array([10**x for x in y_test_pred]))**2))\n",
    "R2_dif_fp_test = r2_score(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(test_Y, (-1))]), np.array([10**x for x in y_test_pred]))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = bst.get_score()\n",
    "print(len(data_train[\"ESM2\"][1]))\n",
    "print(len(data_train[\"MACCS FP\"][1]))\n",
    "for key, value in importances.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5434616148229964, 0.20736826410395937) 4.480616666528345 -0.08739155838640311 2.7392305731704583 2.7392305731704583\n"
     ]
    }
   ],
   "source": [
    "val_X = np.array(list(data_val[\"difference_fp\"]))\n",
    "val_X = np.concatenate([val_X,  np.array(list(data_val[\"GNN FP\"])), np.array(list(data_val[\"Temperature\"]))[:, np.newaxis], np.array(list(data_val[\"pH\"]))[:, np.newaxis]], axis = 1)\n",
    "val_Y = np.array(list(data_val[\"log10_kcat\"]))\n",
    "\n",
    "val_X = val_X.astype(float)\n",
    "\n",
    "dval = xgb.DMatrix(val_X)\n",
    "\n",
    "y_val_pred = bst.predict(dval)\n",
    "data_val[\"Estimate kcat\"] = y_val_pred\n",
    "\n",
    "MSE_dif_fp_val = np.sqrt(np.mean(abs(np.array([10**x for x in np.reshape(val_Y, (-1))]) - np.array([10**x for x in y_val_pred]))**2))\n",
    "R2_dif_fp_val = r2_score(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "Pearson = stats.pearsonr(np.array([10**x for x in np.reshape(val_Y, (-1))]), np.array([10**x for x in y_val_pred]))\n",
    "MAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "MedAE = np.mean(abs(np.array([10**x for x in val_Y]) - np.array([10**x for x in y_val_pred])))\n",
    "\n",
    "# MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "# R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "# Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_val, R2_dif_fp_val, MAE, MedAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
