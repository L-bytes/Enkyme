{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "datasets_dir = \"../../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 36, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"secondary\"\n",
    "\n",
    "data_train = pd.read_pickle(join(datasets_dir, \"splits\", split, \"training_data.pkl\"))\n",
    "data_test = pd.read_pickle(join(datasets_dir, \"splits\", split, \"test_data.pkl\"))\n",
    "data_val = pd.read_pickle(join(datasets_dir, \"splits\", split, \"val_data.pkl\"))\n",
    "\n",
    "# data_train[\"geomean_kcat\"] = np.log10(data_train[\"geomean_kcat\"])\n",
    "# data_test[\"geomean_kcat\"] = np.log10(data_test[\"geomean_kcat\"])\n",
    "\n",
    "data_train[\"log10_kcat\"] = np.log10(data_train[\"kcat\"])\n",
    "data_test[\"log10_kcat\"] = np.log10(data_test[\"kcat\"])\n",
    "data_val[\"log10_kcat\"] = np.log10(data_val[\"kcat\"])\n",
    "\n",
    "data_train.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_test.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_val.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "\n",
    "data_train['Temperature'] = data_train['Temperature'].replace('-', np.nan)\n",
    "data_test['Temperature'] = data_test['Temperature'].replace('-', np.nan)\n",
    "data_val['Temperature'] = data_val['Temperature'].replace('-', np.nan)\n",
    "data_train['pH'] = data_train['pH'].replace('-', np.nan)\n",
    "data_test['pH'] = data_test['pH'].replace('-', np.nan)\n",
    "data_val['pH'] = data_val['pH'].replace('-', np.nan)\n",
    "data_train['Type'] = data_train['Type'].replace('wildtype', 1)\n",
    "data_train['Type'] = data_train['Type'].replace('mutant', 2)\n",
    "data_test['Type'] = data_test['Type'].replace('wildtype', 1)\n",
    "data_test['Type'] = data_test['Type'].replace('mutant', 2)\n",
    "data_val['Type'] = data_val['Type'].replace('wildtype', 1)\n",
    "data_val['Type'] = data_val['Type'].replace('mutant', 2)\n",
    "\n",
    "data_train['MACCS FP'] = data_train['MACCS FP'].astype(str)\n",
    "data_test['MACCS FP'] = data_test['MACCS FP'].astype(str)\n",
    "data_val['MACCS FP'] = data_val['MACCS FP'].astype(str)\n",
    "\n",
    "len(data_train), len(data_test), len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_train_indices_Seed plants.npy\"), allow_pickle = True))\n",
    "test_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_test_indices_Seed plants.npy\"), allow_pickle = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "data_test = data_test[~data_test['GNN FP'].isnull()]\n",
    "\n",
    "nan_rows = data_train[data_train['GNN FP'].apply(lambda x: not isinstance(x, np.ndarray))]\n",
    "\n",
    "# Get the indices of these rows\n",
    "indices_with_nan = nan_rows.index.tolist()\n",
    "# indices_with_nan.reverse()\n",
    "print(indices_with_nan)\n",
    "\n",
    "for ind, sub_list in enumerate(train_indices):\n",
    "    for elem in sub_list:\n",
    "        if elem in indices_with_nan:\n",
    "            sub_list.remove(elem)\n",
    "\n",
    "for ind, sub_list in enumerate(train_indices):\n",
    "    for num in indices_with_nan:\n",
    "        for i, elem in enumerate(sub_list):\n",
    "            if elem > num:\n",
    "                train_indices[ind][i] = elem-1\n",
    "\n",
    "for ind, sub_list in enumerate(test_indices):\n",
    "    for elem in sub_list:\n",
    "        if elem in indices_with_nan:\n",
    "            sub_list.remove(elem)\n",
    "\n",
    "for ind, sub_list in enumerate(test_indices):\n",
    "    for num in indices_with_nan:\n",
    "        for i, elem in enumerate(sub_list):\n",
    "            if elem > num:\n",
    "                test_indices[ind][i] = elem-1  \n",
    "\n",
    "\n",
    "data_train = data_train[data_train['GNN FP'].apply(lambda x: isinstance(x, np.ndarray))]\n",
    "data_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_gnn_fp.npy\"))\n",
    "esm2_gnn_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_diff_fp.npy\"))\n",
    "esm2_diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_gnn_fp_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_gnn_fp_diff_fp.npy\"))\n",
    "esm2_gnn_fp_diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2.npy\"))\n",
    "esm2 = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_gnn_fp.npy\"))\n",
    "gnn_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp.npy\"))\n",
    "diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_diff_fp_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp_gnn_fp.npy\"))\n",
    "diff_fp_gnn_fp = abs(10**pred_y-10**test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between predictions with enzyme+reaction and enzyme+substrate 0.53125\n",
      "Difference between predictions with enzyme+reaction and enzyme+substrate+reaction 0.2890625 10.0\n",
      "Difference between predictions with enzyme+reaction and enzyme 0.2890625 10.0\n",
      "Difference between predictions with enzyme+reaction and substrate 0.7109375\n",
      "Difference between predictions with enzyme+reaction and reaction 0.1875\n",
      "Difference between predictions with enzyme+reaction and reaction+substrate 0.65625\n"
     ]
    }
   ],
   "source": [
    "d = esm2_diff_fp - esm2_gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme+substrate\", p)\n",
    "\n",
    "d = esm2_diff_fp - esm2_gnn_fp_diff_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme+substrate+reaction\", p)\n",
    "\n",
    "d = esm2_diff_fp - esm2\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme\", p)\n",
    "\n",
    "d = esm2_diff_fp - gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and substrate\", p)\n",
    "\n",
    "d = esm2_diff_fp - diff_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and reaction\", p)\n",
    "\n",
    "d = esm2_diff_fp - diff_fp_gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and reaction+substrate\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between predictions with enzyme+reaction and baseline 0.0390625\n"
     ]
    }
   ],
   "source": [
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_baseline.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp.npy\"))\n",
    "baseline = abs(10**pred_y-10**test_y)\n",
    "\n",
    "d = esm2_diff_fp - baseline\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and baseline\", p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
