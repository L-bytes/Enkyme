{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "datasets_dir = \"../../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 7, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"secondary\"\n",
    "\n",
    "data_train = pd.read_pickle(join(datasets_dir, \"splits\", split, \"training_data.pkl\"))\n",
    "data_test = pd.read_pickle(join(datasets_dir, \"splits\", split, \"test_data.pkl\"))\n",
    "data_val = pd.read_pickle(join(datasets_dir, \"splits\", split, \"val_data.pkl\"))\n",
    "\n",
    "# data_train[\"geomean_kcat\"] = np.log10(data_train[\"geomean_kcat\"])\n",
    "# data_val[\"geomean_kcat\"] = np.log10(data_val[\"geomean_kcat\"])\n",
    "\n",
    "data_train[\"log10_kcat\"] = np.log10(data_train[\"kcat\"])\n",
    "data_val[\"log10_kcat\"] = np.log10(data_val[\"kcat\"])\n",
    "data_val[\"log10_kcat\"] = np.log10(data_val[\"kcat\"])\n",
    "\n",
    "data_train.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_val.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "data_val.rename(columns = {\"Enzyme rep\" : \"ESM2\"}, inplace = True)\n",
    "\n",
    "data_train['Temperature'] = data_train['Temperature'].replace('-', np.nan)\n",
    "data_val['Temperature'] = data_val['Temperature'].replace('-', np.nan)\n",
    "data_val['Temperature'] = data_val['Temperature'].replace('-', np.nan)\n",
    "data_train['pH'] = data_train['pH'].replace('-', np.nan)\n",
    "data_val['pH'] = data_val['pH'].replace('-', np.nan)\n",
    "data_val['pH'] = data_val['pH'].replace('-', np.nan)\n",
    "data_train['Type'] = data_train['Type'].replace('wildtype', 1)\n",
    "data_train['Type'] = data_train['Type'].replace('mutant', 2)\n",
    "data_val['Type'] = data_val['Type'].replace('wildtype', 1)\n",
    "data_val['Type'] = data_val['Type'].replace('mutant', 2)\n",
    "data_val['Type'] = data_val['Type'].replace('wildtype', 1)\n",
    "data_val['Type'] = data_val['Type'].replace('mutant', 2)\n",
    "\n",
    "data_train['MACCS FP'] = data_train['MACCS FP'].astype(str)\n",
    "data_val['MACCS FP'] = data_val['MACCS FP'].astype(str)\n",
    "data_val['MACCS FP'] = data_val['MACCS FP'].astype(str)\n",
    "\n",
    "len(data_train), len(data_val), len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_train_indices_Seed plants.npy\"), allow_pickle = True))\n",
    "test_indices = list(np.load(join(datasets_dir, \"splits\", split, \"CV_test_indices_Seed plants.npy\"), allow_pickle = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "data_val = data_val[~data_val['GNN FP'].isnull()]\n",
    "\n",
    "nan_rows = data_train[data_train['GNN FP'].apply(lambda x: not isinstance(x, np.ndarray))]\n",
    "\n",
    "# Get the indices of these rows\n",
    "indices_with_nan = nan_rows.index.tolist()\n",
    "# indices_with_nan.reverse()\n",
    "print(indices_with_nan)\n",
    "\n",
    "for ind, sub_list in enumerate(train_indices):\n",
    "    for elem in sub_list:\n",
    "        if elem in indices_with_nan:\n",
    "            sub_list.remove(elem)\n",
    "\n",
    "for ind, sub_list in enumerate(train_indices):\n",
    "    for num in indices_with_nan:\n",
    "        for i, elem in enumerate(sub_list):\n",
    "            if elem > num:\n",
    "                train_indices[ind][i] = elem-1\n",
    "\n",
    "for ind, sub_list in enumerate(val_indices):\n",
    "    for elem in sub_list:\n",
    "        if elem in indices_with_nan:\n",
    "            sub_list.remove(elem)\n",
    "\n",
    "for ind, sub_list in enumerate(val_indices):\n",
    "    for num in indices_with_nan:\n",
    "        for i, elem in enumerate(sub_list):\n",
    "            if elem > num:\n",
    "                val_indices[ind][i] = elem-1  \n",
    "\n",
    "\n",
    "data_train = data_train[data_train['GNN FP'].apply(lambda x: isinstance(x, np.ndarray))]\n",
    "data_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\data\\\\secondary\\\\y_val_pred_xgboost_ESM2_gnn_fp.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12760\\1430126167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_val_pred_xgboost_ESM2_gnn_fp.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvaly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_test_true_xgboost_ESM2_gnn_fp.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mesm2_gnn_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_test_pred_xgboost_ESM2_diff_fp.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\..\\\\data\\\\secondary\\\\y_val_pred_xgboost_ESM2_gnn_fp.npy'"
     ]
    }
   ],
   "source": [
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_val_pred_xgboost_ESM2_gnn_fp.npy\"))\n",
    "valy = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_gnn_fp.npy\"))\n",
    "esm2_gnn_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_diff_fp.npy\"))\n",
    "esm2_diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2_gnn_fp_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2_gnn_fp_diff_fp.npy\"))\n",
    "esm2_gnn_fp_diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_ESM2.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_ESM2.npy\"))\n",
    "esm2 = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_gnn_fp.npy\"))\n",
    "gnn_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_diff_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp.npy\"))\n",
    "diff_fp = abs(10**pred_y-10**test_y)\n",
    "\n",
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_diff_fp_gnn_fp.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp_gnn_fp.npy\"))\n",
    "diff_fp_gnn_fp = abs(10**pred_y-10**test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between predictions with enzyme+reaction and enzyme+substrate 0.53125\n",
      "Difference between predictions with enzyme+reaction and enzyme+substrate+reaction 0.2890625 10.0\n",
      "Difference between predictions with enzyme+reaction and enzyme 0.2890625 10.0\n",
      "Difference between predictions with enzyme+reaction and substrate 0.7109375\n",
      "Difference between predictions with enzyme+reaction and reaction 0.1875\n",
      "Difference between predictions with enzyme+reaction and reaction+substrate 0.65625\n"
     ]
    }
   ],
   "source": [
    "d = esm2_diff_fp - esm2_gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme+substrate\", p)\n",
    "\n",
    "d = esm2_diff_fp - esm2_gnn_fp_diff_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme+substrate+reaction\", p)\n",
    "\n",
    "d = esm2_diff_fp - esm2\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and enzyme\", p)\n",
    "\n",
    "d = esm2_diff_fp - gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and substrate\", p)\n",
    "\n",
    "d = esm2_diff_fp - diff_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and reaction\", p)\n",
    "\n",
    "d = esm2_diff_fp - diff_fp_gnn_fp\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and reaction+substrate\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12760\\2703340653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_test_pred_xgboost_baseline.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_test_true_xgboost_diff_fp.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mesm2_diff_fp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "pred_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_pred_xgboost_baseline.npy\"))\n",
    "test_y = np.load(join(\"..\", \"..\", \"data\", split, \"y_test_true_xgboost_diff_fp.npy\"))\n",
    "baseline = abs(10**pred_y-10**test_y)\n",
    "\n",
    "d = esm2_diff_fp - baseline\n",
    "w, p = wilcoxon(d, alternative='less')\n",
    "print(\"Difference between predictions with enzyme+reaction and baseline\", w, p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
