{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from ete3 import NCBITaxa\n",
    "import torch\n",
    "import esm\n",
    "from bioservices import *\n",
    "from data_preprocessing import *\n",
    "from functions_and_dicts_data_preprocessing_GNN import *\n",
    "from build_GNN import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "datasets_dir = \"../../data\"\n",
    "\n",
    "CURRENT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading in Sabio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Sabio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 1660\n",
      "Number of UniProt IDs: 413\n"
     ]
    }
   ],
   "source": [
    "organism = \"Seed plants\"\n",
    "\n",
    "df_Sabio = pd.read_table(join(datasets_dir, \"kcat_model_\" + organism + \".tsv\"))\n",
    "\n",
    "df_Sabio[\"kcat\"] = df_Sabio[\"kcat\"].astype('float')\n",
    "df_Sabio[\"PMID\"] = df_Sabio[\"PMID\"].astype('Int64')\n",
    "\n",
    "df_Sabio[\"substrate_IDs\"] = df_Sabio[\"substrate_IDs\"].str.split('#')\n",
    "df_Sabio[\"product_IDs\"] = df_Sabio[\"product_IDs\"].str.split('#')\n",
    "\n",
    "df_Sabio[\"Type\"][df_Sabio['Type'].str.contains(\"wildtype\")] = \"wildtype\"\n",
    "df_Sabio[\"Type\"][df_Sabio['Type'].str.contains(\"mutant\")] = \"mutant\"\n",
    "\n",
    "print(\"Number of data points: %s\" % len(df_Sabio))\n",
    "print(\"Number of UniProt IDs: %s\" % len(set(df_Sabio[\"Uniprot IDs\"])))\n",
    "\n",
    "df_kcat = df_Sabio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist = []\n",
    "\n",
    "for ind in df_kcat.index:\n",
    "    UID, kcat = df_kcat[\"Uniprot IDs\"][ind], df_kcat[\"kcat\"][ind]\n",
    "    help_df = df_kcat.loc[df_kcat[\"Uniprot IDs\"] == UID].loc[df_kcat[\"kcat\"] == kcat]\n",
    "    \n",
    "    if len(help_df) > 1:\n",
    "        droplist = droplist + list(help_df.index)[1:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat.drop(list(set(droplist)), inplace = True)\n",
    "print(\"Dropping %s data points, because they are duplicated.\" % len(set(droplist)))\n",
    "df_kcat.reset_index(inplace = True, drop = True)\n",
    "df_kcat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing top and bottom 3% of kcat values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_IQR(df):\n",
    "\n",
    "   q1=df.quantile(0.25)\n",
    "\n",
    "   q3=df.quantile(0.75)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "\n",
    "   return outliers\n",
    "\n",
    "find_outliers_IQR(df_kcat[\"kcat\"])\n",
    "\n",
    "print(df_kcat['kcat'].quantile(0.03),  df_kcat['kcat'].quantile(0.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat = df_kcat[(df_kcat['kcat'] > df_kcat['kcat'].quantile(0.03)) & (df_kcat['kcat'] < df_kcat['kcat'].quantile(0.97))]\n",
    "df_kcat.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop= []\n",
    "\n",
    "for ind in df_kcat.index:\n",
    "    UID = df_kcat[\"Uniprot IDs\"][ind]\n",
    "    if len(UID.split(';')) > 1:\n",
    "        todrop.append(ind)\n",
    "        print(df_kcat[\"Uniprot IDs\"][ind])\n",
    "        print(todrop)\n",
    "        \n",
    "df_kcat.drop(todrop, inplace=True)\n",
    "df_kcat.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat[\"substrate_IDs\"] = df_kcat[\"substrate_IDs\"].apply(lambda x: (set(x)))\n",
    "df_kcat[\"product_IDs\"] = df_kcat[\"product_IDs\"].apply(lambda x: (set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat.to_pickle(join(datasets_dir, \"kcat_data_merged.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assigning IDs to every unique sequence and to every unique reaction in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating DataFrames for all sequences and for all reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions = pd.DataFrame({\"substrates\": df_kcat[\"substrate_IDs\"],\n",
    "                            \"products\" : df_kcat[\"product_IDs\"]})\n",
    "\n",
    "df_reactions = df_reactions.loc[df_reactions[\"substrates\"] != set([])]\n",
    "df_reactions = df_reactions.loc[df_reactions[\"products\"] != set([])]\n",
    "\n",
    "\n",
    "droplist = []\n",
    "for ind in df_reactions.index:\n",
    "    sub_IDs, pro_IDs = df_reactions[\"substrates\"][ind], df_reactions[\"products\"][ind]\n",
    "    help_df = df_reactions.loc[df_reactions[\"substrates\"] == sub_IDs].loc[df_reactions[\"products\"] == pro_IDs]\n",
    "    if len(help_df):\n",
    "        for ind in list(help_df.index)[1:]:\n",
    "            droplist.append(ind)\n",
    "            \n",
    "df_reactions.drop(list(set(droplist)), inplace = True)\n",
    "df_reactions.reset_index(inplace = True, drop =True)\n",
    "\n",
    "df_reactions[\"Reaction ID\"] = [\"Reaction_\" + str(ind) for ind in df_reactions.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequences = pd.DataFrame(data = {\"Sequence\" : df_kcat[\"Sequence\"].unique()})\n",
    "df_sequences = df_sequences.loc[~pd.isnull(df_sequences[\"Sequence\"])]\n",
    "df_sequences.reset_index(inplace = True, drop = True)\n",
    "df_sequences[\"Sequence ID\"] = [\"Sequence_\" + str(ind) for ind in df_sequences.index]\n",
    "\n",
    "df_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating maximal kcat value for each reaction and sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions[\"max_kcat_for_RID\"] = np.nan\n",
    "for ind in df_reactions.index:\n",
    "    df_reactions[\"max_kcat_for_RID\"][ind] = max(df_kcat.loc[df_kcat[\"substrate_IDs\"] == df_reactions[\"substrates\"][ind]].loc[df_kcat[\"product_IDs\"] == df_reactions[\"products\"][ind]][\"kcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequences[\"max_kcat_for_UID\"] = np.nan\n",
    "for ind in df_sequences.index:\n",
    "    df_sequences[\"max_kcat_for_UID\"][ind] = max(df_kcat.loc[df_kcat[\"Sequence\"] == df_sequences['Sequence'][ind]][\"kcat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the sum of the molecular weights of all substrates and of all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions[\"MW_frac\"] = np.nan\n",
    "\n",
    "for ind in df_reactions.index:\n",
    "    substrates = list(df_reactions[\"substrates\"][ind])\n",
    "    products = list(df_reactions[\"products\"][ind])\n",
    "    \n",
    "    mw_subs = mw_mets(metabolites = substrates)\n",
    "    mw_pros = mw_mets(metabolites = products)\n",
    "    \n",
    "    if mw_subs == np.nan or mw_pros == np.nan:\n",
    "        df_reactions[\"MW_frac\"][ind] = np.inf\n",
    "    if mw_pros != 0:\n",
    "        df_reactions[\"MW_frac\"][ind] = mw_subs/mw_pros\n",
    "    else:\n",
    "        df_reactions[\"MW_frac\"][ind] = np.inf\n",
    "        \n",
    "df_reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating enzyme, reaction and substrate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t33_650M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating model input:\n",
    "df_sequences[\"model_input\"] = [seq[:1022] for seq in df_sequences[\"Sequence\"]]\n",
    "model_input = [(df_sequences[\"Sequence ID\"][ind], df_sequences[\"model_input\"][ind]) for ind in df_sequences.index]\n",
    "seqs = [model_input[i][1] for i in range(len(model_input))]\n",
    "#loading ESM-2 model:\n",
    "print(\".....2(a) Loading ESM-2 model.\")\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "#convert input into batches:\n",
    "\n",
    "#Calculate ESM-2 representations\n",
    "print(\".....2(b) Calculating enzyme representations.\")\n",
    "df_sequences[\"Enzyme rep\"] = \"\"\n",
    "\n",
    "for ind in df_sequences.index:\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter([(df_sequences[\"Sequence ID\"][ind], df_sequences[\"model_input\"][ind])])\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33])\n",
    "    df_sequences[\"Enzyme rep\"][ind] = results[\"representations\"][33][0, 1 : len(df_sequences[\"model_input\"][ind]) + 1].mean(0).numpy()\n",
    "    \n",
    "df_sequences.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metabolite_type(met):\n",
    "    if is_KEGG_ID(met):\n",
    "        return(\"KEGG\")\n",
    "    elif is_InChI(met):\n",
    "        return(\"InChI\")\n",
    "    else:\n",
    "        return(\"invalid\")\n",
    "\n",
    "def get_reaction_site_smarts(metabolites):\n",
    "    reaction_site = \"\"\n",
    "    for met in metabolites:\n",
    "        met_type = get_metabolite_type(met)\n",
    "        if met_type == \"KEGG\":\n",
    "            try:\n",
    "                Smarts = Chem.MolToSmarts(Chem.MolFromMolFile(join(CURRENT_DIR, \"data\", \"mol-files\",  met + \".mol\")))\n",
    "            except OSError:\n",
    "                return(np.nan)\n",
    "        elif met_type == \"InChI\":\n",
    "            Smarts = Chem.MolToSmarts(Chem.inchi.MolFromInchi(met))\n",
    "        else:\n",
    "            Smarts = \"invalid\"\n",
    "        reaction_site = reaction_site + \".\" + Smarts\n",
    "    return(reaction_site[1:])\n",
    "\n",
    "\n",
    "def is_KEGG_ID(met):\n",
    "    #a valid KEGG ID starts with a \"C\" or \"D\" followed by a 5 digit number:\n",
    "    if len(met) == 6 and met[0] in [\"C\", \"D\"]:\n",
    "        try:\n",
    "            int(met[1:])\n",
    "            return(True)\n",
    "        except: \n",
    "            pass\n",
    "    return(False)\n",
    "\n",
    "def is_InChI(met):\n",
    "    m = Chem.inchi.MolFromInchi(met,sanitize=False)\n",
    "    if m is None:\n",
    "      return(False)\n",
    "    else:\n",
    "      try:\n",
    "        Chem.SanitizeMol(m)\n",
    "      except:\n",
    "        print('.......Metabolite string \"%s\" is in InChI format but has invalid chemistry' % met)\n",
    "        return(False)\n",
    "    return(True)\n",
    "\n",
    "def convert_fp_to_array(difference_fp_dict):\n",
    "    fp = np.zeros(2048)\n",
    "    for key in difference_fp_dict.keys():\n",
    "        fp[key] = difference_fp_dict[key]\n",
    "    return(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions[\"difference_fp\"], df_reactions[\"structural_fp\"],  = \"\", \"\"\n",
    "#each metabolite should be either a KEGG ID, InChI string, or a SMILES:\n",
    "for ind in df_reactions.index:\n",
    "    left_site = get_reaction_site_smarts(df_reactions[\"substrates\"][ind])\n",
    "    right_site = get_reaction_site_smarts(df_reactions[\"products\"][ind])\n",
    "    if not pd.isnull(left_site) and not pd.isnull(right_site):\n",
    "        rxn_forward = AllChem.ReactionFromSmarts(left_site + \">>\" + right_site)\n",
    "        difference_fp = Chem.rdChemReactions.CreateDifferenceFingerprintForReaction(rxn_forward)\n",
    "        difference_fp = convert_fp_to_array(difference_fp.GetNonzeroElements())\n",
    "        df_reactions[\"difference_fp\"][ind] = difference_fp\n",
    "        df_reactions[\"structural_fp\"][ind] = Chem.rdChemReactions.CreateStructuralFingerprintForReaction(rxn_forward).ToBitString()\n",
    "\n",
    "df_reactions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequences.to_pickle(join(datasets_dir, \"all_sequences_with_IDs.pkl\"))\n",
    "df_reactions.to_pickle(join(datasets_dir, \"all_reactions_with_IDs.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping Sequence and Reaction IDs to kcat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat = df_kcat.merge(df_sequences, on = \"Sequence\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions.rename(columns = {\"substrates\" : \"substrate_IDs\",\n",
    "                              \"products\" : \"product_IDs\"}, inplace = True)\n",
    "\n",
    "df_kcat[\"Reaction ID\"] = np.nan\n",
    "df_kcat[\"MW_frac\"] = np.nan\n",
    "df_kcat[\"max_kcat_for_RID\"] = np.nan\n",
    "df_kcat[\"difference_fp\"] = \"\"\n",
    "df_kcat[\"structural_fp\"] = \"\"\n",
    "\n",
    "for ind in df_kcat.index:\n",
    "    sub_set, pro_set = df_kcat[\"substrate_IDs\"][ind], df_kcat[\"product_IDs\"][ind]\n",
    "    \n",
    "    help_df = df_reactions.loc[df_reactions[\"substrate_IDs\"] == sub_set].loc[df_reactions[\"product_IDs\"] == pro_set]\n",
    "    if len(help_df) == 1:\n",
    "        df_kcat[\"Reaction ID\"][ind] = list(help_df[\"Reaction ID\"])[0]\n",
    "        df_kcat[\"max_kcat_for_RID\"][ind] = list(help_df[\"max_kcat_for_RID\"])[0]\n",
    "        df_kcat[\"MW_frac\"][ind] = list(help_df[\"MW_frac\"])[0]\n",
    "        df_kcat[\"difference_fp\"][ind] = list(help_df[\"difference_fp\"])[0]\n",
    "        df_kcat[\"structural_fp\"][ind] = list(help_df[\"structural_fp\"])[0]\n",
    "df_kcat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat[\"MACCS FP\"] = \"\"\n",
    "\n",
    "for ind in df_kcat.index:\n",
    "    substrate = df_kcat[\"Main substrate\"][ind]\n",
    "    try:\n",
    "        id = df_kcat['Substrate_IDs'][ind][df_kcat[\"Substrates\"][ind].split(';').index(substrate)]\n",
    "    except:\n",
    "        for i,s in enumerate(df_kcat[\"Substrates\"][ind].split(';')[:-1]):\n",
    "            if substrate in s or s in substrate:\n",
    "                id = list(df_kcat['Substrate_IDs'][ind])[i]\n",
    "    if id[0] == \"C\":\n",
    "        try:\n",
    "            mol = Chem.MolFromMolFile(join(datasets_dir,\"mol-files\", id + '.mol'))\n",
    "        except OSError:\n",
    "            None\n",
    "    else:\n",
    "        try:\n",
    "            mol = Chem.inchi.MolFromInchi(id,sanitize=False)\n",
    "        except OSError:\n",
    "            None\n",
    "    if mol is not None:\n",
    "        maccs_fp = MACCSkeys.GenMACCSKeys(mol).ToBitString()\n",
    "        df_kcat[\"MACCS FP\"][ind] = maccs_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the maximal kcat value for every EC number in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EC_kcat = pd.read_csv(join(datasets_dir, \"max_EC_\" + organism + \".tsv\"), sep = \"\\t\", header=0)\n",
    "# df_EC_kcat = df_EC_kcat.rename(columns={0: \"EC\", 1: \"max_kcat\"})\n",
    "\n",
    "for ind in df_EC_kcat.index:\n",
    "    try:\n",
    "        kcat_max = df_EC_kcat[df_EC_kcat[\"EC\"] == df_kcat[\"ECs\"]][\"max_kcat\"]\n",
    "        df_EC_kcat[\"max_kcat\"][ind] = kcat_max\n",
    "        print(ind, kcat_max)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "df_EC_kcat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EC_kcat = pd.read_csv(join(datasets_dir, \"max_EC_\" + organism + \".tsv\"), sep = \"\\t\", header=0)\n",
    "\n",
    "df_EC_kcat.head(5)\n",
    "df_kcat[\"max_kcat_for_EC\"] = np.nan\n",
    "\n",
    "for ind in df_kcat.index:\n",
    "    EC = df_kcat[\"ECs\"][ind]\n",
    "    max_kcat = 0\n",
    "    try:\n",
    "        print(EC)\n",
    "        max_kcat = df_EC_kcat.loc[df_EC_kcat[\"EC\"] == EC, \"max_kcat\"].iloc[0]\n",
    "        print(max_kcat)\n",
    "    except:\n",
    "        pass\n",
    "    if max_kcat != 0:\n",
    "        df_kcat[\"max_kcat_for_EC\"][ind] = max_kcat\n",
    "df_kcat.to_pickle(join(datasets_dir, \"merged_and_grouped_kcat_dataset.pkl\"))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing non-optimally measured values\n",
    "\n",
    "To ignore $kcat$ values that were obtained under non-optimal conditions, we exclude values lower than 0.1\\% than the maximal $kcat$ value for the same enzyme, reaction or EC number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat[\"frac_of_max_UID\"] = np.nan\n",
    "df_kcat[\"frac_of_max_RID\"] = np.nan\n",
    "df_kcat[\"frac_of_max_EC\"] = np.nan\n",
    "\n",
    "for ind in df_kcat.index:\n",
    "    df_kcat[\"frac_of_max_UID\"][ind] =  df_kcat[\"kcat\"][ind]/df_kcat[\"max_kcat_for_UID\"][ind]\n",
    "    df_kcat[\"frac_of_max_RID\"][ind] =  df_kcat[\"kcat\"][ind]/df_kcat[\"max_kcat_for_RID\"][ind]\n",
    "    df_kcat[\"frac_of_max_EC\"][ind] = df_kcat[\"kcat\"][ind]/df_kcat[\"max_kcat_for_EC\"][ind]\n",
    "\n",
    "len(df_kcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_kcat)\n",
    "\n",
    "df_kcat = df_kcat.loc[df_kcat[\"frac_of_max_UID\"] >= 0.01]\n",
    "df_kcat = df_kcat.loc[df_kcat[\"frac_of_max_RID\"] >= 0.01]\n",
    "\n",
    "df_kcat[\"frac_of_max_EC\"].loc[pd.isnull(df_kcat[\"frac_of_max_EC\"])] = 1\n",
    "df_kcat = df_kcat.loc[df_kcat[\"frac_of_max_EC\"] <= 10]\n",
    "df_kcat = df_kcat.loc[df_kcat[\"frac_of_max_EC\"] >= 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We remove %s data points, because we suspect that these kcat values were not measure for the natural reaction \" \\\n",
    "    \"of an enzyme or under non-optimal conditions.\" % (n-len(df_kcat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing data points with reaction queations with uneven fraction of molecular weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_kcat)\n",
    "\n",
    "df_kcat = df_kcat.loc[df_kcat[\"MW_frac\"] < 3]\n",
    "df_kcat = df_kcat.loc[df_kcat[\"MW_frac\"] > 1/3]\n",
    "\n",
    "print(\"We remove %s data points because the sum of molecular weights of substrates does not match the sum of molecular\" \\\n",
    "      \"weights of the products.\" % (n-len(df_kcat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of final kcat dataset: %s\" % len(df_kcat))\n",
    "df_kcat.to_pickle(join(datasets_dir, \"final_kcat_dataset_\" + organism + \".pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing dataset and splitting into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcat = pd.read_pickle(join(datasets_dir, \"final_kcat_dataset_\" + organism + \".pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting glucosinolates into validation dataset\n",
    "\n",
    "Search UniProt for GO term related to glucosionalte metabolic process, download file as .tsv and filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glucosinolates = pd.read_table(join(datasets_dir,\"glucosinolates.tsv\"))[\"Entry\"].tolist()\n",
    "# df_kcat = df_kcat[~df_kcat[\"Uniprot IDs\"].isin(glucosinolates)]\n",
    "# df_validation = df_kcat[df_kcat[\"Uniprot IDs\"].isin(glucosinolates)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If training-testing with only Arabidopsis data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kcat = df_kcat[df_kcat[\"Organism\"] == 'Arabidopsis thaliana']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If training-testing with only Brassicaceae data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncbi = NCBITaxa()\n",
    "\n",
    "# organisms = {}\n",
    "\n",
    "# def is_brassicaceae(org):\n",
    "#     try:\n",
    "#         tax_id = ncbi.get_name_translator([org])[org][0]\n",
    "#         lineage = ncbi.get_lineage(tax_id)\n",
    "#         if 3700 not in lineage:\n",
    "#             return(False)\n",
    "#         else:\n",
    "#             return(True)\n",
    "#     except KeyError:\n",
    "#         return(False)\n",
    "    \n",
    "# for org in df_kcat[\"Organism\"].tolist():\n",
    "#     if org not in organisms.keys():\n",
    "#         organisms[org] = is_brassicaceae(org)\n",
    "\n",
    "# df_kcat = df_kcat[df_kcat[\"Organism\"].isin([key for key, value in organisms.items() if value is True])]\n",
    "# df_kcat.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If training-testing only with wildtype data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kcat = df_kcat[df_kcat[\"Type\"] == \"wildtype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating arithmetic mean for kcat values of same enzyme-reaction-substrate combination-pH-temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.DataFrame(data = {\"Reaction ID\" : df_kcat[\"Reaction ID\"],\n",
    "#                                   \"Sequence ID\" : df_kcat[\"Sequence ID\"],\n",
    "#                                   \"Temperature\" : df_kcat[\"Temperature\"],\n",
    "#                                     \"pH\" : df_kcat[\"pH\"],\n",
    "#                                  \"Type\": df_kcat[\"Type\"],\n",
    "#                              \"MACCS FP\" : df_kcat[\"MACCS FP\"]})\n",
    "\n",
    "# df_new.drop_duplicates(inplace = True)\n",
    "# df_new.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# df_new[\"kcat_values\"], df_new[\"Uniprot IDs\"], df_new[\"ECs\"], df_new[\"Substrates\"], df_new[\"Products\"], df_new[\"ESM2\"], df_new[\"Sequence\"], df_new[\"difference_fp\"], df_new[\"structural_fp\"] = \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "\n",
    "# for ind in df_new.index:\n",
    "#     RID, SID, Temp, pH, Type, MSubstrate = df_new[\"Reaction ID\"][ind], df_new[\"Sequence ID\"][ind], df_new[\"Temperature\"][ind], df_new[\"pH\"][ind], df_new[\"Type\"][ind], df_new[\"MACCS FP\"][ind]\n",
    "#     help_df = df_kcat.loc[df_kcat[\"Reaction ID\"] \n",
    "#                                  == RID].loc[df_kcat[\"Sequence ID\"] \n",
    "#                                              == SID].loc[df_kcat[\"Temperature\"] \n",
    "#                                                          == Temp].loc[df_kcat[\"pH\"] \n",
    "#                                                                       == pH].loc[df_kcat[\"Type\"] \n",
    "#                                                                                  == Type].loc[df_kcat[\"MACCS FP\"] \n",
    "#                                                                                               == MSubstrate]\n",
    "#     print(help_df)\n",
    "#     df_new[\"ECs\"][ind] = list(help_df[\"ECs\"])\n",
    "#     df_new[\"kcat_values\"][ind] = list(help_df[\"kcat\"])\n",
    "#     df_new[\"Uniprot IDs\"][ind] = list(help_df[\"Uniprot IDs\"])\n",
    "#     df_new[\"Sequence\"][ind] = help_df[\"Sequence\"].values[0]\n",
    "#     df_new[\"ESM2\"][ind] = help_df[\"Enzyme rep\"].values[0]\n",
    "#     df_new[\"difference_fp\"][ind], df_new[\"structural_fp\"][ind] = help_df[\"difference_fp\"].values[0], help_df[\"structural_fp\"].values[0]\n",
    "#     df_new[\"Substrates\"][ind], df_new[\"Products\"][ind] = help_df[\"Substrates\"].values[0], help_df[\"Products\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new2 = pd.DataFrame(data = {\"Reaction ID\" : df_validation[\"Reaction ID\"],\n",
    "#                                   \"Sequence ID\" : df_validation[\"Sequence ID\"],\n",
    "#                                   \"Temperature\" : df_validation[\"Temperature\"],\n",
    "#                                     \"pH\" : df_validation[\"pH\"],\n",
    "#                                   \"Type\" : df_validation[\"Type\"],\n",
    "#                                   \"MACCS FP\" : df_validation[\"MACCS FP\"]})\n",
    "\n",
    "# df_new2.drop_duplicates(inplace = True)\n",
    "# df_new2.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# df_new2[\"kcat_values\"], df_new2[\"Uniprot IDs\"], df_new2[\"ECs\"], df_new2[\"Organisms\"], df_new2[\"Substrates\"], df_new2[\"Products\"], df_new2[\"ESM2\"], df_new2[\"Sequence\"], df_new2[\"difference_fp\"], df_new2[\"structural_fp\"] = \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "\n",
    "# for ind in df_new2.index:\n",
    "#     RID, SID, Temp, pH, Type, MSubstrate = df_new2[\"Reaction ID\"][ind], df_new2[\"Sequence ID\"][ind], df_new2[\"Temperature\"][ind], df_new2[\"pH\"][ind], df_new2[\"Type\"][ind], df_new2[\"MACCS FP\"][ind]\n",
    "#     help_df = df_validation.loc[df_validation[\"Reaction ID\"] \n",
    "#                               == RID].loc[df_validation[\"Sequence ID\"] \n",
    "#                                           == SID].loc[df_validation[\"Temperature\"] \n",
    "#                                                       == Temp].loc[df_validation[\"pH\"] \n",
    "#                                                                     == pH].loc[df_validation[\"Type\"] \n",
    "#                                                                               == Type].loc[df_validation[\"MACCS FP\"] \n",
    "#                                                                                                             == MSubstrate]\n",
    "#     df_new2[\"ECs\"][ind] = list(help_df[\"ECs\"])\n",
    "#     df_new2[\"kcat_values\"][ind] = list(help_df[\"kcat\"])\n",
    "#     df_new2[\"Uniprot IDs\"][ind] = list(help_df[\"Uniprot IDs\"])\n",
    "#     df_new2[\"Organisms\"][ind] = list(help_df[\"Organism\"])\n",
    "#     df_new2[\"Type\"][ind]\n",
    "#     df_new2[\"Sequence\"][ind] = help_df[\"Sequence\"].values[0]\n",
    "#     df_new2[\"ESM2\"][ind] = help_df[\"Enzyme rep\"].values[0]\n",
    "#     df_new2[\"difference_fp\"][ind], df_new2[\"structural_fp\"][ind] = help_df[\"difference_fp\"].values[0], help_df[\"structural_fp\"].values[0]\n",
    "#     df_new2[\"Substrates\"][ind], df_new2[\"Products\"][ind] = help_df[\"Substrates\"].values[0], help_df[\"Products\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kcat = df_new\n",
    "# df_validation = df_new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kcat[\"geomean_kcat\"] = np.nan\n",
    "# for ind in df_kcat.index:\n",
    "#     all_kcat = np.array(df_kcat[\"kcat_values\"][ind]).astype(float)\n",
    "#     max_kcat = max(all_kcat)\n",
    "#     all_kcat_top = [kcat for kcat in all_kcat  if kcat/max_kcat >= 0.01]\n",
    "#     df_kcat[\"geomean_kcat\"][ind] = np.mean((all_kcat_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_validation[\"geomean_kcat\"] = np.nan\n",
    "# for ind in df_validation.index:\n",
    "#     all_kcat = np.array(df_validation[\"kcat_values\"][ind]).astype(float)\n",
    "#     max_kcat = max(all_kcat)\n",
    "#     all_kcat_top = [kcat for kcat in all_kcat  if kcat/max_kcat >= 0.01]\n",
    "#     df_validation[\"geomean_kcat\"][ind] = np.mean((all_kcat_top))\n",
    "\n",
    "# df_validation.to_pickle(join(datasets_dir, \"validation_%s.pkl\" %organism))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making input for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df_kcat.index:\n",
    "    substrate = df_kcat[\"Main Substrate\"][ind]\n",
    "    try:\n",
    "        id = list(df_kcat['substrate_IDs'][ind])[df_kcat[\"Substrates\"][ind].split(';').index(substrate)]\n",
    "    except:\n",
    "        for i,s in enumerate(df_kcat[\"Substrates\"][ind].split(';')[:-1]):\n",
    "            if substrate in s or s in substrate:\n",
    "                id = list(df_kcat['substrate_IDs'][ind])[i]\n",
    "    df_kcat[\"Main Substrate\"][ind] = id\n",
    "\n",
    "inchi_ids = {}\n",
    "for i, element in enumerate(df_kcat[\"Main Substrate\"]):\n",
    "    if element[0] != 'C' and element not in inchi_ids.keys():\n",
    "        inchi_ids[element] = str(i)\n",
    "        mol = Chem.inchi.MolFromInchi(element)\n",
    "        if not mol is None:\n",
    "            calculate_atom_and_bond_feature_vectors(mol, str(i))\n",
    "        # Chem.rdmolfiles.MolToMolFile(Chem.inchi.MolFromInchi(element), join(datasets_dir,\"mol-files\", str(i) + \".mol\")  )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 245\n",
      "Training set size: 774\n",
      "Size of test set in percent: 24.0\n"
     ]
    }
   ],
   "source": [
    "df = df_kcat.copy()\n",
    "df = df.sample(frac = 1, random_state = 123)\n",
    "df.reset_index(drop= True, inplace = True)\n",
    "\n",
    "train_df, test_df = split_dataframe_enzyme(frac = 5, df = df.copy())\n",
    "print(\"Test set size: %s\" % len(test_df))\n",
    "print(\"Training set size: %s\" % len(train_df))\n",
    "print(\"Size of test set in percent: %s\" % np.round(100*len(test_df)/ (len(test_df) + len(train_df))))\n",
    "\n",
    "train_df.reset_index(inplace = True, drop = True)\n",
    "test_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "train_df.to_pickle(join(datasets_dir, \"train_df_kcat_%s.pkl\" %organism))\n",
    "test_df.to_pickle(join(datasets_dir, \"test_df_kcat_%s.pkl\" %organism))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597 177\n",
      "458 139\n",
      "322 136\n",
      "147 175\n"
     ]
    }
   ],
   "source": [
    "data_train2 = train_df.copy()\n",
    "data_train2[\"index\"] = list(data_train2.index)\n",
    "\n",
    "data_train2, df_fold = split_dataframe_enzyme(df = data_train2, frac=5)\n",
    "indices_fold1 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold1))#\n",
    "\n",
    "data_train2, df_fold = split_dataframe_enzyme(df = data_train2, frac=4)\n",
    "indices_fold2 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold2))\n",
    "\n",
    "data_train2, df_fold = split_dataframe_enzyme(df = data_train2, frac=3)\n",
    "indices_fold3 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold3))\n",
    "\n",
    "data_train2, df_fold = split_dataframe_enzyme(df = data_train2, frac=2)\n",
    "indices_fold4 = list(df_fold[\"index\"])\n",
    "indices_fold5 = list(data_train2[\"index\"])\n",
    "print(len(data_train2), len(indices_fold4))\n",
    "\n",
    "\n",
    "fold_indices = [indices_fold1, indices_fold2, indices_fold3, indices_fold4, indices_fold5]\n",
    "\n",
    "CV_train_indices = [[], [], [], [], []]\n",
    "CV_test_indices = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j:\n",
    "            CV_train_indices[i] = CV_train_indices[i] + fold_indices[j]\n",
    "    CV_test_indices[i] = fold_indices[i]\n",
    "    \n",
    "    \n",
    "np.save(join(datasets_dir, \"CV_train_indices_%s\" %organism), CV_train_indices)\n",
    "np.save(join(datasets_dir, \"CV_test_indices_%s\" %organism), CV_test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building GNN for substrate representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in train_df.index:\n",
    "    calculate_and_save_input_matrixes(inchi_ids, sample_ID = \"train_\" + str(ind), df = train_df,\n",
    "                                      save_folder = join(datasets_dir, \"GNN_input_data\"))\n",
    "    \n",
    "for ind in test_df.index:\n",
    "    calculate_and_save_input_matrixes(inchi_ids, sample_ID = \"test_\" + str(ind), df = test_df,\n",
    "                                      save_folder = join(datasets_dir, \"GNN_input_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = os.listdir(join(datasets_dir, \"GNN_input_data\"))\n",
    "train_indices = [index[:index.rfind(\"_\")] for index in train_indices]\n",
    "train_indices = list(set([index for index in train_indices if \"train\" in index]))\n",
    "\n",
    "test_indices = os.listdir(join(datasets_dir, \"GNN_input_data\"))\n",
    "test_indices = [index[:index.rfind(\"_\")] for index in test_indices]\n",
    "test_indices = list(set([index for index in test_indices if \"test\" in index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter optimization with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization = pd.DataFrame()\n",
    "\n",
    "param_grid = {'batch_size': [32,64,96],\n",
    "                'D': [50,100],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'epochs': [30,50,80],\n",
    "                'l2_reg_fc' : [0.02, 0.05, 0.08],\n",
    "                'l2_reg_conv': [0.02, 0.05, 0.08],\n",
    "                'rho': [0.9, 0.95, 0.99]}\n",
    "\n",
    "params_list = [(batch_size, D, learning_rate, epochs, l2_reg_fc, l2_reg_conv, rho) for batch_size in param_grid['batch_size'] for learning_rate in param_grid['learning_rate']\n",
    "                for epochs in param_grid['epochs'] for l2_reg_fc in param_grid['l2_reg_conv'] for l2_reg_fc in param_grid['l2_reg_conv'] for rho in param_grid[\"rho\"]]\n",
    "\n",
    "params_list = random.sample(params_list, 100)\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "  results = pool.map(hyperparameter_tuning, params_list)\n",
    "  optimization = pd.concat(optimization, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 34s 2s/step - loss: 66548.7344 - mse: 66548.3906 - mae: 64.9070\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 18s 1s/step - loss: 66968.2734 - mse: 66967.9297 - mae: 65.4721\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 18s 1s/step - loss: 60585.9375 - mse: 60585.6016 - mae: 62.6286\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 23s 2s/step - loss: 67530.5000 - mse: 67530.1562 - mae: 66.5444\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 20s 2s/step - loss: 64472.5078 - mse: 64472.1719 - mae: 63.2740\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 20s 1s/step - loss: 65127.6680 - mse: 65127.3320 - mae: 63.2235\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 65210.1250 - mse: 65209.7773 - mae: 64.2190\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 67533.8750 - mse: 67533.5469 - mae: 66.8398\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 67596.4531 - mse: 67596.1172 - mae: 67.1894\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 67219.0547 - mse: 67218.7266 - mae: 65.8063\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 66355.1641 - mse: 66354.8281 - mae: 64.1609\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 66407.8906 - mse: 66407.5547 - mae: 65.1837\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 56344.7148 - mse: 56344.3750 - mae: 61.8744\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 66841.9531 - mse: 66841.6172 - mae: 64.5810\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 67276.9531 - mse: 67276.6250 - mae: 65.7229\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 38802.7656 - mse: 38802.4219 - mae: 54.9610\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 67220.8828 - mse: 67220.5391 - mae: 65.7977\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 20s 2s/step - loss: 66382.6094 - mse: 66382.2812 - mae: 64.7979\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 21s 2s/step - loss: 67588.0000 - mse: 67587.6641 - mae: 67.0370\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 23s 2s/step - loss: 50046.5703 - mse: 50046.2344 - mae: 60.5158\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 22s 2s/step - loss: 67518.3828 - mse: 67518.0391 - mae: 66.8658\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 23s 2s/step - loss: 67213.0781 - mse: 67212.7344 - mae: 66.2467\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 22s 2s/step - loss: 67529.2188 - mse: 67528.8828 - mae: 66.6347\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 20s 2s/step - loss: 50040.5234 - mse: 50040.1875 - mae: 60.3905\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 61861.8047 - mse: 61861.4609 - mae: 61.4857\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 20s 2s/step - loss: 67601.1094 - mse: 67600.7656 - mae: 67.3853\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 20s 2s/step - loss: 38844.7773 - mse: 38844.4414 - mae: 55.4218\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 64718.8320 - mse: 64718.4844 - mae: 63.9735\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 20s 1s/step - loss: 66334.2109 - mse: 66333.8672 - mae: 64.7231\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 19s 1s/step - loss: 64530.5898 - mse: 64530.2461 - mae: 63.2919\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "147495.69597759124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 29s 2s/step - loss: 95866.9453 - mse: 95866.6094 - mae: 77.7538\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 85973.2344 - mse: 85972.8828 - mae: 73.4214\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 96118.1094 - mse: 96117.7734 - mae: 77.7900\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 95988.4922 - mse: 95988.1328 - mae: 77.4647\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 80006.1250 - mse: 80005.7891 - mae: 72.2636\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 95152.5078 - mse: 95152.1719 - mae: 75.5773\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 96275.8125 - mse: 96275.4844 - mae: 78.4256\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 96190.6250 - mse: 96190.2891 - mae: 77.7141\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 95396.3516 - mse: 95396.0078 - mae: 76.7188\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 24s 2s/step - loss: 96210.7734 - mse: 96210.4297 - mae: 77.9116\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 21s 1s/step - loss: 85435.9219 - mse: 85435.5781 - mae: 73.4173\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 85517.3203 - mse: 85516.9844 - mae: 73.7141\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 96249.1797 - mse: 96248.8594 - mae: 78.3454\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 96371.1406 - mse: 96370.7969 - mae: 78.8843\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 26s 2s/step - loss: 95615.8047 - mse: 95615.4609 - mae: 77.3655\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 27s 2s/step - loss: 96345.0547 - mse: 96344.7031 - mae: 78.7394\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 94289.8594 - mse: 94289.5234 - mae: 76.3232\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 13s 935ms/step - loss: 93711.5469 - mse: 93711.1875 - mae: 75.8277\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 20s 1s/step - loss: 96313.9297 - mse: 96313.5859 - mae: 78.4856\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 92886.1172 - mse: 92885.7656 - mae: 74.5975\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 86086.0547 - mse: 86085.7266 - mae: 74.0301\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 13s 926ms/step - loss: 95368.1328 - mse: 95367.7969 - mae: 77.4037\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 96303.0625 - mse: 96302.7344 - mae: 78.2208\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 14s 966ms/step - loss: 96345.3281 - mse: 96344.9844 - mae: 78.6182\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 95828.7109 - mse: 95828.3750 - mae: 77.6481\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 95889.0859 - mse: 95888.7656 - mae: 77.4072\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 94157.2578 - mse: 94156.9141 - mae: 75.6622\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 95637.2891 - mse: 95636.9531 - mae: 76.8888\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 92261.6250 - mse: 92261.2891 - mae: 74.2200\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 85528.2031 - mse: 85527.8828 - mae: 73.5420\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "46888.867204080874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 88874.6953 - mse: 88874.3594 - mae: 75.7232\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 94195.8984 - mse: 94195.5547 - mae: 79.1909\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 13s 924ms/step - loss: 94492.4297 - mse: 94492.0859 - mae: 80.4199\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 92557.8672 - mse: 92557.5078 - mae: 78.3299\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 29s 2s/step - loss: 92026.9297 - mse: 92026.5703 - mae: 77.3672\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 26s 2s/step - loss: 81837.8594 - mse: 81837.5078 - mae: 74.1323\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 94656.2656 - mse: 94655.9219 - mae: 81.2032\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 13s 926ms/step - loss: 91997.5156 - mse: 91997.1641 - mae: 78.3244\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 82978.6328 - mse: 82978.2969 - mae: 73.0991\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 93880.4141 - mse: 93880.0547 - mae: 79.8638\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91472.7656 - mse: 91472.4219 - mae: 77.3797\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 14s 991ms/step - loss: 93139.8750 - mse: 93139.5391 - mae: 77.8937\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 61583.9102 - mse: 61583.5664 - mae: 66.3934\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 93736.4141 - mse: 93736.0547 - mae: 79.2465\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 20s 1s/step - loss: 93465.8984 - mse: 93465.5625 - mae: 79.0654\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 94143.8047 - mse: 94143.4453 - mae: 80.0570\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91757.9453 - mse: 91757.6016 - mae: 77.7208\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 14s 969ms/step - loss: 94441.1250 - mse: 94440.7656 - mae: 80.4543\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 13s 899ms/step - loss: 94057.7344 - mse: 94057.3906 - mae: 79.6191\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 14s 973ms/step - loss: 94518.7266 - mse: 94518.3750 - mae: 80.8220\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 14s 978ms/step - loss: 87400.4531 - mse: 87400.1016 - mae: 75.7254\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 93475.1797 - mse: 93474.8281 - mae: 79.1648\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 24s 2s/step - loss: 91518.3125 - mse: 91517.9609 - mae: 76.9691\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 31s 2s/step - loss: 94133.8594 - mse: 94133.5078 - mae: 79.6391\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 27s 2s/step - loss: 94556.0078 - mse: 94555.6641 - mae: 80.6115\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 26s 2s/step - loss: 94674.1406 - mse: 94673.7969 - mae: 81.0260\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 94281.9609 - mse: 94281.6094 - mae: 80.3732\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 94635.0547 - mse: 94634.7109 - mae: 80.9704\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 94533.2344 - mse: 94532.9141 - mae: 80.4352\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 94591.9531 - mse: 94591.6094 - mae: 80.6939\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "54955.85142404316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 83912.6797 - mse: 83912.3516 - mae: 75.1453\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 81324.6016 - mse: 81324.2500 - mae: 72.2731\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 15s 995ms/step - loss: 83173.9297 - mse: 83173.5859 - mae: 73.7304\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 13s 953ms/step - loss: 83918.3906 - mse: 83918.0625 - mae: 75.2221\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 14s 979ms/step - loss: 83856.2500 - mse: 83855.9297 - mae: 74.6035\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 20s 1s/step - loss: 72618.2656 - mse: 72617.9375 - mae: 68.4366\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 83902.5703 - mse: 83902.2344 - mae: 75.0224\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 14s 1s/step - loss: 83858.4297 - mse: 83858.0859 - mae: 74.8217\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 14s 997ms/step - loss: 79818.1250 - mse: 79817.7891 - mae: 70.6641\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 83743.2422 - mse: 83742.9219 - mae: 74.5561\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 14s 1s/step - loss: 83916.2031 - mse: 83915.8750 - mae: 75.1202\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 14s 991ms/step - loss: 83860.2891 - mse: 83859.9531 - mae: 74.6439\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 14s 983ms/step - loss: 83886.3359 - mse: 83886.0078 - mae: 74.9524\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 14s 994ms/step - loss: 83318.3828 - mse: 83318.0469 - mae: 73.5960\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 14s 988ms/step - loss: 83852.3672 - mse: 83852.0469 - mae: 74.7479\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 71254.4844 - mse: 71254.1406 - mae: 67.4557\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 14s 1s/step - loss: 83748.6406 - mse: 83748.3047 - mae: 74.2711\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 14s 990ms/step - loss: 83313.7422 - mse: 83313.4219 - mae: 74.1035\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 14s 982ms/step - loss: 83827.3047 - mse: 83826.9766 - mae: 74.7721\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 14s 986ms/step - loss: 83620.1719 - mse: 83619.8516 - mae: 73.9519\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 14s 956ms/step - loss: 83670.5391 - mse: 83670.2031 - mae: 74.0771\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 14s 981ms/step - loss: 83880.5078 - mse: 83880.1719 - mae: 74.9235\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 13s 947ms/step - loss: 72801.8750 - mse: 72801.5391 - mae: 68.4803\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 13s 910ms/step - loss: 83695.2656 - mse: 83694.9297 - mae: 74.0107\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 13s 911ms/step - loss: 83158.0703 - mse: 83157.7422 - mae: 73.9097\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 13s 910ms/step - loss: 81892.6953 - mse: 81892.3594 - mae: 73.0021\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 13s 914ms/step - loss: 83551.6641 - mse: 83551.3203 - mae: 74.1473\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 13s 910ms/step - loss: 83791.6094 - mse: 83791.2656 - mae: 74.4430\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 13s 914ms/step - loss: 83782.0859 - mse: 83781.7578 - mae: 74.5610\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 13s 909ms/step - loss: 83916.0469 - mse: 83915.7109 - mae: 75.2620\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "95780.42446047982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 18s 942ms/step - loss: 91128.3047 - mse: 91127.9844 - mae: 79.7819\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 13s 948ms/step - loss: 91103.1797 - mse: 91102.8203 - mae: 79.6150\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 13s 954ms/step - loss: 91133.7656 - mse: 91133.4219 - mae: 79.8584\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 91132.7500 - mse: 91132.4297 - mae: 79.8563\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 13s 943ms/step - loss: 91132.3984 - mse: 91132.0703 - mae: 79.8811\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 13s 939ms/step - loss: 91040.5859 - mse: 91040.2500 - mae: 79.4065\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 91133.5625 - mse: 91133.2344 - mae: 79.8839\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 91131.2656 - mse: 91130.9219 - mae: 79.8244\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 14s 966ms/step - loss: 91052.1250 - mse: 91051.7891 - mae: 79.4624\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 13s 937ms/step - loss: 91136.3047 - mse: 91135.9531 - mae: 79.8899\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 13s 937ms/step - loss: 91132.1094 - mse: 91131.7656 - mae: 79.8838\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 13s 929ms/step - loss: 91132.9141 - mse: 91132.5625 - mae: 79.8826\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 13s 935ms/step - loss: 91135.0156 - mse: 91134.6875 - mae: 79.8892\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 13s 934ms/step - loss: 91051.6875 - mse: 91051.3516 - mae: 79.4651\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 14s 963ms/step - loss: 90377.3984 - mse: 90377.0859 - mae: 78.5903\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 13s 954ms/step - loss: 91133.0078 - mse: 91132.6641 - mae: 79.8700\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 13s 938ms/step - loss: 91135.3125 - mse: 91134.9531 - mae: 79.8871\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 14s 970ms/step - loss: 91134.1484 - mse: 91133.8125 - mae: 79.8884\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 14s 961ms/step - loss: 91089.1953 - mse: 91088.8750 - mae: 79.5764\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 13s 935ms/step - loss: 91122.3828 - mse: 91122.0391 - mae: 79.7449\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 13s 951ms/step - loss: 91132.0234 - mse: 91131.6797 - mae: 79.8876\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 13s 947ms/step - loss: 91133.0859 - mse: 91132.7500 - mae: 79.8877\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 90358.1250 - mse: 90357.7891 - mae: 78.3178\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 13s 942ms/step - loss: 91133.3281 - mse: 91133.0000 - mae: 79.8760\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 91132.3125 - mse: 91131.9922 - mae: 79.8645\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 13s 943ms/step - loss: 91131.7031 - mse: 91131.3672 - mae: 79.8922\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 13s 940ms/step - loss: 91132.5781 - mse: 91132.2422 - mae: 79.8801\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 13s 939ms/step - loss: 81127.1406 - mse: 81126.8125 - mae: 74.8107\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 13s 943ms/step - loss: 91132.1484 - mse: 91131.8047 - mae: 79.8813\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 13s 943ms/step - loss: 91131.8828 - mse: 91131.5547 - mae: 79.8784\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023684D62828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023684D62828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "61638.16206359735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 15s 927ms/step - loss: 67591.0234 - mse: 67590.6953 - mae: 67.0374\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 12s 922ms/step - loss: 67580.1953 - mse: 67579.8438 - mae: 67.1018\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 12s 923ms/step - loss: 63613.4570 - mse: 63613.1172 - mae: 62.8579\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 12s 926ms/step - loss: 67607.7188 - mse: 67607.3750 - mae: 67.1549\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 12s 933ms/step - loss: 66786.7578 - mse: 66786.4141 - mae: 65.7119\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 12s 920ms/step - loss: 67585.5234 - mse: 67585.1797 - mae: 67.0506\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 12s 928ms/step - loss: 59727.1172 - mse: 59726.7734 - mae: 60.9395\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 12s 950ms/step - loss: 65427.7969 - mse: 65427.4570 - mae: 65.1464\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 12s 928ms/step - loss: 66912.8203 - mse: 66912.4844 - mae: 64.4859\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 12s 926ms/step - loss: 66434.8438 - mse: 66434.5078 - mae: 65.2411\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 12s 919ms/step - loss: 67421.9141 - mse: 67421.5625 - mae: 66.1716\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 12s 927ms/step - loss: 66492.2031 - mse: 66491.8750 - mae: 65.3826\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 12s 937ms/step - loss: 67485.3906 - mse: 67485.0547 - mae: 66.5458\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 12s 924ms/step - loss: 67537.2578 - mse: 67536.9219 - mae: 66.3388\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 12s 923ms/step - loss: 57483.4375 - mse: 57483.1055 - mae: 61.2588\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 12s 928ms/step - loss: 67524.1328 - mse: 67523.7969 - mae: 66.7554\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 12s 927ms/step - loss: 67545.9922 - mse: 67545.6562 - mae: 66.9076\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 12s 941ms/step - loss: 67517.6328 - mse: 67517.2969 - mae: 66.6213\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 12s 918ms/step - loss: 67394.8438 - mse: 67394.5078 - mae: 66.3934\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 12s 925ms/step - loss: 65166.0859 - mse: 65165.7422 - mae: 64.0947\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 12s 926ms/step - loss: 67604.9922 - mse: 67604.6562 - mae: 67.1861\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 12s 924ms/step - loss: 56770.7656 - mse: 56770.4219 - mae: 60.4254\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 12s 932ms/step - loss: 67553.8750 - mse: 67553.5312 - mae: 66.7621\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 12s 928ms/step - loss: 65245.6602 - mse: 65245.3164 - mae: 64.0589\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 12s 933ms/step - loss: 60555.4023 - mse: 60555.0664 - mae: 62.6921\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 12s 923ms/step - loss: 56656.8125 - mse: 56656.4727 - mae: 60.8803\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 12s 927ms/step - loss: 67526.1328 - mse: 67525.7969 - mae: 66.6194\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 12s 946ms/step - loss: 56222.0039 - mse: 56221.6719 - mae: 60.9289\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 12s 929ms/step - loss: 67466.2188 - mse: 67465.8828 - mae: 66.5985\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 12s 928ms/step - loss: 67524.8750 - mse: 67524.5469 - mae: 66.7991\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000236800EE9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000236800EE9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "147488.7765917129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 16s 932ms/step - loss: 95564.1016 - mse: 95563.7734 - mae: 77.0102\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 13s 943ms/step - loss: 95824.0000 - mse: 95823.6484 - mae: 77.2037\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 13s 933ms/step - loss: 96313.8906 - mse: 96313.5547 - mae: 78.3442\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 13s 935ms/step - loss: 96338.3203 - mse: 96337.9844 - mae: 78.4994\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 13s 930ms/step - loss: 85607.7734 - mse: 85607.4531 - mae: 72.2677\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 13s 952ms/step - loss: 96325.8203 - mse: 96325.4766 - mae: 78.4773\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 13s 934ms/step - loss: 94311.7109 - mse: 94311.3828 - mae: 76.4233\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 13s 931ms/step - loss: 96344.6250 - mse: 96344.3125 - mae: 78.4843\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 13s 932ms/step - loss: 96133.1719 - mse: 96132.8203 - mae: 78.0414\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 13s 933ms/step - loss: 85739.1719 - mse: 85738.8203 - mae: 73.0434\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 13s 935ms/step - loss: 94880.1953 - mse: 94879.8359 - mae: 75.7833\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 13s 930ms/step - loss: 95513.5078 - mse: 95513.1797 - mae: 76.9617\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 13s 943ms/step - loss: 83897.6641 - mse: 83897.3516 - mae: 71.4644\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 13s 940ms/step - loss: 95325.4922 - mse: 95325.1719 - mae: 76.5117\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 96352.4531 - mse: 96352.1328 - mae: 78.6460\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 13s 944ms/step - loss: 96196.5625 - mse: 96196.2109 - mae: 77.9936\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 13s 942ms/step - loss: 96338.8516 - mse: 96338.5078 - mae: 78.5741\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 13s 942ms/step - loss: 96264.3906 - mse: 96264.0547 - mae: 78.1756\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 13s 940ms/step - loss: 94833.4219 - mse: 94833.0781 - mae: 76.0386\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 13s 944ms/step - loss: 96263.4844 - mse: 96263.1328 - mae: 78.3576\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 13s 937ms/step - loss: 96009.4766 - mse: 96009.1250 - mae: 77.5031\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 13s 936ms/step - loss: 95294.2422 - mse: 95293.8984 - mae: 75.9212\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 13s 938ms/step - loss: 95959.9141 - mse: 95959.5625 - mae: 77.1953\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 13s 938ms/step - loss: 96253.7266 - mse: 96253.3906 - mae: 77.9265\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 14s 967ms/step - loss: 96123.5703 - mse: 96123.2500 - mae: 77.3324\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 13s 946ms/step - loss: 96195.8984 - mse: 96195.5625 - mae: 77.9479\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 13s 949ms/step - loss: 95625.4297 - mse: 95625.0859 - mae: 77.4424\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 13s 946ms/step - loss: 95612.9453 - mse: 95612.6172 - mae: 77.0622\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 85949.5391 - mse: 85949.2031 - mae: 74.0382\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 13s 947ms/step - loss: 94547.4531 - mse: 94547.1094 - mae: 75.3157\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "46823.72293919919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 16s 961ms/step - loss: 94579.1406 - mse: 94578.7891 - mae: 80.1850\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 14s 995ms/step - loss: 83468.7969 - mse: 83468.4531 - mae: 74.6777\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 13s 952ms/step - loss: 94359.4609 - mse: 94359.1328 - mae: 80.5648\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 13s 945ms/step - loss: 92952.5078 - mse: 92952.1797 - mae: 77.7976\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 13s 944ms/step - loss: 94494.9531 - mse: 94494.6250 - mae: 79.9782\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 13s 945ms/step - loss: 94566.6250 - mse: 94566.2891 - mae: 80.6952\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 13s 941ms/step - loss: 84177.8047 - mse: 84177.4531 - mae: 75.4355\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 13s 948ms/step - loss: 92343.4375 - mse: 92343.1094 - mae: 78.1612\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 13s 938ms/step - loss: 94623.8047 - mse: 94623.4531 - mae: 80.7824\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 14s 961ms/step - loss: 84318.1641 - mse: 84317.8359 - mae: 76.3083\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 13s 951ms/step - loss: 93724.0078 - mse: 93723.6641 - mae: 79.1516\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 13s 955ms/step - loss: 94585.8516 - mse: 94585.5078 - mae: 80.3108\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 13s 946ms/step - loss: 94624.7344 - mse: 94624.3906 - mae: 81.0020\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 13s 948ms/step - loss: 94426.7109 - mse: 94426.3672 - mae: 79.9193\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 13s 953ms/step - loss: 93946.6875 - mse: 93946.3359 - mae: 79.8078\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 14s 958ms/step - loss: 94534.1875 - mse: 94533.8516 - mae: 80.1750\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 14s 961ms/step - loss: 92474.7578 - mse: 92474.4219 - mae: 78.7051\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 13s 944ms/step - loss: 94541.9844 - mse: 94541.6250 - mae: 80.6412\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 14s 948ms/step - loss: 88262.5078 - mse: 88262.1641 - mae: 77.6963\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 13s 954ms/step - loss: 94187.8125 - mse: 94187.4766 - mae: 79.7873\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 13s 955ms/step - loss: 92671.7344 - mse: 92671.3906 - mae: 79.0665\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 13s 953ms/step - loss: 94504.6797 - mse: 94504.3281 - mae: 80.2553\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 14s 956ms/step - loss: 82640.4844 - mse: 82640.1406 - mae: 73.6613\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 10817s 832s/step - loss: 91171.8984 - mse: 91171.5703 - mae: 77.1888\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 2254s 173s/step - loss: 94704.5625 - mse: 94704.2422 - mae: 81.2811\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 30s 2s/step - loss: 94538.6953 - mse: 94538.3594 - mae: 80.6218\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 29s 2s/step - loss: 83633.8984 - mse: 83633.5547 - mae: 74.2011\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 27s 2s/step - loss: 94153.6172 - mse: 94153.2656 - mae: 79.8938\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 29s 2s/step - loss: 94690.8125 - mse: 94690.4609 - mae: 81.1320\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 21s 1s/step - loss: 94646.7656 - mse: 94646.4219 - mae: 80.8936\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "54953.651400345974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 24s 1s/step - loss: 83907.1016 - mse: 83906.7656 - mae: 74.9120\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 83860.9766 - mse: 83860.6328 - mae: 74.8738\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 73864.3359 - mse: 73863.9922 - mae: 69.7923\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 64233.4688 - mse: 64233.1328 - mae: 65.4096\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83917.8516 - mse: 83917.5078 - mae: 75.1855\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83167.8672 - mse: 83167.5156 - mae: 73.8650\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 73422.0156 - mse: 73421.6953 - mae: 69.3112\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 81887.0703 - mse: 81886.7422 - mae: 73.0944\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83802.7500 - mse: 83802.4141 - mae: 74.4971\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 83880.0781 - mse: 83879.7422 - mae: 74.7933\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83704.8828 - mse: 83704.5469 - mae: 74.4826\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83923.2891 - mse: 83922.9609 - mae: 75.2708\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83757.6484 - mse: 83757.3203 - mae: 74.2504\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83867.8750 - mse: 83867.5469 - mae: 74.8423\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 74749.1875 - mse: 74748.8516 - mae: 70.6786\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83882.1016 - mse: 83881.7656 - mae: 74.6873\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83893.5156 - mse: 83893.1875 - mae: 74.8704\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83919.7734 - mse: 83919.4375 - mae: 75.2754\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 83919.3594 - mse: 83919.0156 - mae: 75.2916\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83918.1797 - mse: 83917.8359 - mae: 75.1529\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83345.5469 - mse: 83345.1953 - mae: 73.7961\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 73841.6016 - mse: 73841.2656 - mae: 69.8532\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83862.9375 - mse: 83862.6016 - mae: 74.5328\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83909.5547 - mse: 83909.2344 - mae: 75.0612\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 83850.3203 - mse: 83849.9844 - mae: 74.7659\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83805.3828 - mse: 83805.0547 - mae: 74.3315\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 83900.7031 - mse: 83900.3672 - mae: 74.9462\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83910.4453 - mse: 83910.1250 - mae: 75.1019\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 83877.4297 - mse: 83877.0859 - mae: 74.8703\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 77374.6250 - mse: 77374.2891 - mae: 70.9090\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "95778.90270225292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 91124.9609 - mse: 91124.6328 - mae: 79.8462\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91127.0547 - mse: 91126.7344 - mae: 79.9013\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 89087.3672 - mse: 89087.0469 - mae: 77.7656\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 91122.8047 - mse: 91122.4844 - mae: 79.8990\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91121.1953 - mse: 91120.8672 - mae: 79.8815\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 91098.8516 - mse: 91098.5078 - mae: 79.6029\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91120.7031 - mse: 91120.3672 - mae: 79.9002\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91123.5625 - mse: 91123.2344 - mae: 79.8962\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 91122.5625 - mse: 91122.2266 - mae: 79.8923\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91124.0547 - mse: 91123.7266 - mae: 79.8988\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 74849.1172 - mse: 74848.7891 - mae: 73.8785\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 91014.6484 - mse: 91014.3203 - mae: 79.3943\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91121.5078 - mse: 91121.1797 - mae: 79.9063\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91070.1250 - mse: 91069.8047 - mae: 79.5765\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 74847.6016 - mse: 74847.2656 - mae: 73.8232\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91121.6953 - mse: 91121.3672 - mae: 79.8990\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 90118.1797 - mse: 90117.8672 - mae: 78.3540\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91120.1094 - mse: 91119.7734 - mae: 79.9026\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91114.7891 - mse: 91114.4453 - mae: 79.7823\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91111.0000 - mse: 91110.6641 - mae: 79.7609\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91063.5625 - mse: 91063.2266 - mae: 79.4976\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91105.6328 - mse: 91105.2891 - mae: 79.7045\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91119.2656 - mse: 91118.9375 - mae: 79.8857\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91120.0391 - mse: 91119.6953 - mae: 79.8622\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91111.3125 - mse: 91110.9844 - mae: 79.7793\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91121.5469 - mse: 91121.2109 - mae: 79.8875\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91100.0391 - mse: 91099.7109 - mae: 79.6240\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91107.6406 - mse: 91107.3203 - mae: 79.7606\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91120.1797 - mse: 91119.8516 - mae: 79.8808\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 91120.2891 - mse: 91119.9531 - mae: 79.9020\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "61626.328697041296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 17s 1s/step - loss: 66537.3672 - mse: 66537.0391 - mae: 64.6308\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 66145.0703 - mse: 66144.7500 - mae: 64.7364\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67162.6094 - mse: 67162.2812 - mae: 66.1627\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 64063.0859 - mse: 64062.7500 - mae: 62.1052\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67582.2812 - mse: 67581.9453 - mae: 67.2279\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67403.9219 - mse: 67403.5859 - mae: 66.3212\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67045.7422 - mse: 67045.4062 - mae: 66.0465\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 65301.2852 - mse: 65300.9453 - mae: 64.4297\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67361.7891 - mse: 67361.4531 - mae: 66.0705\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67596.7344 - mse: 67596.3906 - mae: 67.2368\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67435.5547 - mse: 67435.2188 - mae: 66.4588\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67585.9922 - mse: 67585.6641 - mae: 67.2349\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 66318.5547 - mse: 66318.2344 - mae: 63.5762\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67156.9375 - mse: 67156.6094 - mae: 65.0378\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67115.2969 - mse: 67114.9609 - mae: 65.6879\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67447.6094 - mse: 67447.2734 - mae: 66.4563\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 66297.0703 - mse: 66296.7344 - mae: 63.6386\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 16s 1s/step - loss: 67013.8438 - mse: 67013.5078 - mae: 66.0579\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 66716.8750 - mse: 66716.5312 - mae: 65.3557\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 16s 1s/step - loss: 67475.8750 - mse: 67475.5469 - mae: 66.5200\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 66356.2266 - mse: 66355.8906 - mae: 64.4766\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 66854.5234 - mse: 66854.1875 - mae: 65.6224\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 67526.0469 - mse: 67525.7109 - mae: 66.8483\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 55542.0859 - mse: 55541.7578 - mae: 60.0044\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 49957.4375 - mse: 49957.1055 - mae: 59.7493\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 67595.0938 - mse: 67594.7578 - mae: 67.3982\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 15s 1s/step - loss: 66728.3438 - mse: 66728.0312 - mae: 65.5138\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 55234.8945 - mse: 55234.5625 - mae: 59.2816\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 66548.3125 - mse: 66547.9844 - mae: 64.3790\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 14s 1s/step - loss: 67579.6406 - mse: 67579.3203 - mae: 67.2212\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "147515.73488336295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 93254.3594 - mse: 93254.0391 - mae: 75.1983\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96321.0859 - mse: 96320.7500 - mae: 78.4487\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 95751.4922 - mse: 95751.1484 - mae: 77.0816\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 95782.8750 - mse: 95782.5391 - mae: 76.9382\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96335.4375 - mse: 96335.0859 - mae: 78.4925\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 95944.7266 - mse: 95944.3828 - mae: 77.8499\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 69898.5859 - mse: 69898.2422 - mae: 66.6168\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 93096.3047 - mse: 93095.9609 - mae: 75.5733\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 95048.0781 - mse: 95047.7344 - mae: 75.8939\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96352.0547 - mse: 96351.7109 - mae: 78.7671\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 80030.1641 - mse: 80029.8203 - mae: 72.2607\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 84481.7422 - mse: 84481.4219 - mae: 71.6227\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 95779.6172 - mse: 95779.2578 - mae: 76.7732\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96343.0469 - mse: 96342.6953 - mae: 78.6896\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96327.6328 - mse: 96327.2891 - mae: 78.4940\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 85874.7109 - mse: 85874.3906 - mae: 73.3984\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 79442.7031 - mse: 79442.3672 - mae: 70.9227\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 95708.7266 - mse: 95708.3828 - mae: 77.2156\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96039.0078 - mse: 96038.6641 - mae: 77.4157\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96308.0391 - mse: 96307.6953 - mae: 78.3696\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 95416.1172 - mse: 95415.7578 - mae: 76.8742\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 96338.3125 - mse: 96337.9766 - mae: 78.6273\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 95592.2500 - mse: 95591.9141 - mae: 77.3437\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 85423.7422 - mse: 85423.3906 - mae: 73.2679\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 95425.8906 - mse: 95425.5469 - mae: 76.7643\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 87046.6875 - mse: 87046.3594 - mae: 73.5956\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 242488s 18653s/step - loss: 96344.1016 - mse: 96343.7422 - mae: 78.7896\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 33s 2s/step - loss: 96208.7266 - mse: 96208.3906 - mae: 78.0407\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 93385.4844 - mse: 93385.1406 - mae: 74.5326\n",
      "Epoch 30/30\n",
      " 1/14 [=>............................] - ETA: 22s - loss: 156793.5938 - mse: 156793.2656 - mae: 96.0767"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23208\\408661973.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                                 model = DMPNN_without_extra_features(l2_reg_conv = l2_reg_conv, l2_reg_fc = l2_reg_fc, learning_rate = learning_rate,\n\u001b[0;32m     33\u001b[0m                                               D = D, N = N, F1 = F1, F2 = F2, F= F, drop_rate = 0.0, ada_rho = rho)\n\u001b[1;32m---> 34\u001b[1;33m                                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                                 \u001b[1;31m#get test_y:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m--> 135\u001b[1;33m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\marle\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 53\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for batch_size in [32,64,96]:\n",
    "    for D in [50,100]:\n",
    "        for learning_rate in [0.01, 0.1]:\n",
    "            for epochs in [30, 50, 80]:\n",
    "                for l2_reg_fc in [0.02, 0.05, 0.08]:\n",
    "                    for l2_reg_conv in [0.02, 0.05, 0.08]:\n",
    "                        for rho in [0.9, 0.95, 0.99]:\n",
    "                            count +=1\n",
    "                            MSE = []\n",
    "\n",
    "                            for i in range(5):\n",
    "                                train_index, test_index  = CV_train_indices[i], CV_test_indices[i]\n",
    "                                train_index = [ind for ind in train_indices if int(ind.split(\"_\")[1]) in train_index]\n",
    "                                test_index = [ind for ind in train_indices if int(ind.split(\"_\")[1]) in test_index]\n",
    "\n",
    "                                train_params = {'batch_size': batch_size,\n",
    "                                          'folder' :join(datasets_dir, \"GNN_input_data\"),\n",
    "                                          'list_IDs' : np.array(train_index),\n",
    "                                          'shuffle': True}\n",
    "\n",
    "                                test_params = {'batch_size': len(test_index),\n",
    "                                          'folder' : join(datasets_dir, \"GNN_input_data\"),\n",
    "                                          'list_IDs' : np.array(test_index),\n",
    "                                          'shuffle': False}\n",
    "\n",
    "                                training_generator = DataGenerator(**train_params)\n",
    "                                test_generator = DataGenerator(**test_params)\n",
    "\n",
    "\n",
    "                                model = DMPNN_without_extra_features(l2_reg_conv = l2_reg_conv, l2_reg_fc = l2_reg_fc, learning_rate = learning_rate,\n",
    "                                              D = D, N = N, F1 = F1, F2 = F2, F= F, drop_rate = 0.0, ada_rho = rho)\n",
    "                                model.fit(training_generator, epochs= epochs, shuffle = True, verbose = 1)\n",
    "\n",
    "                                #get test_y:\n",
    "                                test_indices_y = [int(ind.split(\"_\")[1]) for ind in train_indices if ind in test_index]\n",
    "                                test_y = np.array([train_df[\"kcat\"][ind] for ind in test_indices_y])\n",
    "\n",
    "                                pred_test = model.predict(test_generator)\n",
    "                                print(np.mean(abs(pred_test - np.reshape(test_y[:len(pred_test)], (-1,1)))**2))\n",
    "                                MSE.append(np.mean(abs(pred_test - np.reshape(test_y[:len(pred_test)], (-1,1)))**2))\n",
    "\n",
    "                            df = pd.DataFrame(columns = [\"batch_size\", \"D\", \"learning_rate\", \"epochs\", \"l2_reg_fc\", \"l2_reg_conv\",\n",
    "                                                         \"rho\", \"cv_mse\"])\n",
    "                            df = df.append({\"batch_size\" : batch_size, \"D\" : D , \"learning_rate\" : learning_rate, \"epochs\" : epochs,\n",
    "                                            \"l2_reg_fc\" : l2_reg_fc, \"l2_reg_conv\" : l2_reg_conv, \"rho\" : rho, \"cv_mse\" : np.mean(MSE)},\n",
    "                                           ignore_index = True)\n",
    "                            try:\n",
    "                                os.mkdir(join(datasets_dir, \"training_results\", \"hyperparameter_optimization_GNN\"))\n",
    "                            except:\n",
    "                                None\n",
    "                            df.to_csv(join(datasets_dir, \"training_results\", \"hyperparameter_optimization_GNN\", str(count) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_results = os.listdir(join(datasets_dir, \"training_results\", \"hyperparameter_optimization_GNN\"))\n",
    "\n",
    "\n",
    "df_hyperopt = pd.DataFrame(columns = ['Unnamed: 0', 'batch_size', 'D', 'learning_rate', 'epochs', 'l2_reg_fc',\n",
    "                                      'l2_reg_conv', 'rho', 'cv_mse'])\n",
    "\n",
    "for i in range(len(hyperparameter_results)):\n",
    "    df_hyperopt = df_hyperopt.append(pd.read_csv(join(datasets_dir, \"training_results\",\n",
    "                                                      \"hyperparameter_optimization_GNN\", hyperparameter_results[i]),\n",
    "                                                 sep = \",\", encoding= \"latin-1\").loc[0], ignore_index= True)\n",
    "\n",
    "df_hyperopt.loc[df_hyperopt[\"cv_mse\"] < 0.865]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model with the best set of hyperparmeters on the whole training set and validate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "D = 50\n",
    "learning_rate = 0.05\n",
    "epochs = 50\n",
    "l2_reg_fc = 1\n",
    "l2_reg_conv = 0.01\n",
    "rho = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = os.listdir(join(datasets_dir, \"GNN_input_data\"))\n",
    "train_indices = [index[:index.rfind(\"_\")] for index in train_indices]\n",
    "train_indices = list(set([index for index in train_indices if \"train\" in index]))\n",
    "\n",
    "test_indices = os.listdir(join(datasets_dir, \"GNN_input_data\"))\n",
    "test_indices = [index[:index.rfind(\"_\")] for index in test_indices]\n",
    "test_indices = list(set([index for index in test_indices if \"test\" in index]))\n",
    "\n",
    "\n",
    "\n",
    "train_params = {'batch_size': batch_size,\n",
    "              'folder' :join(datasets_dir, \"GNN_input_data\"),\n",
    "              'list_IDs' : train_indices,\n",
    "              'shuffle': True}\n",
    "\n",
    "test_params = {'batch_size': batch_size,\n",
    "              'folder' :join(datasets_dir, \"GNN_input_data\"),\n",
    "              'list_IDs' : test_indices,\n",
    "              'shuffle': False}\n",
    "\n",
    "training_generator = DataGenerator(**train_params)\n",
    "test_generator = DataGenerator(**test_params)\n",
    "\n",
    "model = DMPNN(l2_reg_conv = l2_reg_conv, l2_reg_fc = l2_reg_fc, learning_rate = learning_rate,\n",
    "                  D = D, N = N, F1 = F1, F2 = F2, F= F, drop_rate = 0.0, ada_rho = rho)\n",
    "\n",
    "model.fit(training_generator, epochs= epochs, shuffle = True, verbose = 1)\n",
    "model.save_weights(join(datasets_dir, \"model_weights\", \"saved_model_GNN_best_hyperparameters\"))\n",
    "\n",
    "pred_test = model.predict(test_generator)\n",
    "test_indices_y = [int(ind.split(\"_\")[1]) for ind in np.array(test_indices)]\n",
    "test_y = np.array([test_df[\"log10_KM\"][ind] for ind in test_indices_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating substrate representation for every data point in training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DMPNN(l2_reg_conv = l2_reg_conv, l2_reg_fc = l2_reg_fc, learning_rate = learning_rate,\n",
    "                  D = D, N = N, F1 = F1, F2 = F2, F= F, drop_rate = 0.0, ada_rho = rho)\n",
    "model.load_weights(join(datasets_dir, \"model_weights\", \"saved_model_GNN_best_hyperparameters\"))\n",
    "\n",
    "get_fingerprint_fct = K.function([model.layers[0].input, model.layers[26].input,\n",
    "                                  model.layers[3].input, model.layers[36].input],\n",
    "                                  [model.layers[-10].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the GNN representations\n",
    "brenda_train_with_rep = get_substrate_representations(df = train_df, training_set = True, \n",
    "                                                      get_fingerprint_fct = get_fingerprint_fct)\n",
    "brenda_test_with_rep = get_substrate_representations(df = test_df, training_set = False, \n",
    "                                                     get_fingerprint_fct = get_fingerprint_fct)\n",
    "\n",
    "#Saving the DataFrames:\n",
    "brenda_train_with_rep.to_pickle(join(datasets_dir, \"splits\", \"training_data.pkl\"))\n",
    "brenda_test_with_rep.to_pickle(join(datasets_dir, \"splits\", \"test_data.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
